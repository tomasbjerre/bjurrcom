{"meta":{"exported_on":1540494777063,"version":"2.3.0"},"data":{"app_fields":[],"app_settings":[],"apps":[],"brute":[{"key":"cRPpHvdy8sfL5UFWTquKywpwNrBuEQ6gQngGed2hJr4=","firstRequest":1540494715635,"lastRequest":1540494715635,"lifetime":1540498315643,"count":1}],"invites":[],"migrations":[{"id":1,"name":"1-create-tables.js","version":"init","currentVersion":"1.0"},{"id":2,"name":"2-create-fixtures.js","version":"init","currentVersion":"1.0"},{"id":3,"name":"1-post-excerpt.js","version":"1.3","currentVersion":"1.3"},{"id":4,"name":"1-codeinjection-post.js","version":"1.4","currentVersion":"1.7"},{"id":5,"name":"1-og-twitter-post.js","version":"1.5","currentVersion":"1.7"},{"id":6,"name":"1-add-backup-client.js","version":"1.7","currentVersion":"1.7"},{"id":7,"name":"1-custom-template-post.js","version":"1.13","currentVersion":"1.14"},{"id":8,"name":"2-theme-permissions.js","version":"1.13","currentVersion":"1.14"},{"id":9,"name":"1-add-permissions-redirect.js","version":"1.9","currentVersion":"1.14"},{"id":10,"name":"1-add-webhooks-table.js","version":"1.18","currentVersion":"1.18"},{"id":11,"name":"1-webhook-permissions.js","version":"1.19","currentVersion":"1.19"},{"id":12,"name":"1-remove-settings-keys.js","version":"1.20","currentVersion":"1.21"},{"id":13,"name":"1-add-contributor-role.js","version":"1.21","currentVersion":"1.21"},{"id":14,"name":"1-multiple-authors-DDL.js","version":"1.22","currentVersion":"1.24"},{"id":15,"name":"1-multiple-authors-DML.js","version":"1.22","currentVersion":"1.24"},{"id":16,"name":"1-update-koenig-beta-html.js","version":"1.25","currentVersion":"1.25"},{"id":17,"name":"2-demo-post.js","version":"1.25","currentVersion":"1.25"},{"id":18,"name":"1-rename-amp-column.js","version":"2.0","currentVersion":"2.0"},{"id":19,"name":"2-update-posts.js","version":"2.0","currentVersion":"2.0"},{"id":20,"name":"3-remove-koenig-labs.js","version":"2.0","currentVersion":"2.0"},{"id":21,"name":"4-permalink-setting.js","version":"2.0","currentVersion":"2.0"},{"id":22,"name":"5-remove-demo-post.js","version":"2.0","currentVersion":"2.0"},{"id":23,"name":"6-replace-fixture-posts.js","version":"2.0","currentVersion":"2.0"}],"migrations_lock":[{"lock_key":"km01","locked":1,"acquired_at":"2018-10-25T19:12:57.000Z","released_at":"2018-08-22T13:36:07.000Z"}],"permissions":[{"id":"597b43301ffc934f6c0277c0","name":"Export database","object_type":"db","action_type":"exportContent","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277c1","name":"Import database","object_type":"db","action_type":"importContent","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277c2","name":"Delete all content","object_type":"db","action_type":"deleteAllContent","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277c3","name":"Send mail","object_type":"mail","action_type":"send","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277c4","name":"Browse notifications","object_type":"notification","action_type":"browse","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277c5","name":"Add notifications","object_type":"notification","action_type":"add","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277c6","name":"Delete notifications","object_type":"notification","action_type":"destroy","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277c7","name":"Browse posts","object_type":"post","action_type":"browse","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277c8","name":"Read posts","object_type":"post","action_type":"read","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277c9","name":"Edit posts","object_type":"post","action_type":"edit","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277ca","name":"Add posts","object_type":"post","action_type":"add","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277cb","name":"Delete posts","object_type":"post","action_type":"destroy","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277cc","name":"Browse settings","object_type":"setting","action_type":"browse","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277cd","name":"Read settings","object_type":"setting","action_type":"read","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277ce","name":"Edit settings","object_type":"setting","action_type":"edit","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277cf","name":"Generate slugs","object_type":"slug","action_type":"generate","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277d0","name":"Browse tags","object_type":"tag","action_type":"browse","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277d1","name":"Read tags","object_type":"tag","action_type":"read","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277d2","name":"Edit tags","object_type":"tag","action_type":"edit","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277d3","name":"Add tags","object_type":"tag","action_type":"add","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277d4","name":"Delete tags","object_type":"tag","action_type":"destroy","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277d5","name":"Browse themes","object_type":"theme","action_type":"browse","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277d6","name":"Edit themes","object_type":"theme","action_type":"edit","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277d7","name":"Activate themes","object_type":"theme","action_type":"activate","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277d8","name":"Upload themes","object_type":"theme","action_type":"add","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277d9","name":"Download themes","object_type":"theme","action_type":"read","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277da","name":"Delete themes","object_type":"theme","action_type":"destroy","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277db","name":"Browse users","object_type":"user","action_type":"browse","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277dc","name":"Read users","object_type":"user","action_type":"read","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277dd","name":"Edit users","object_type":"user","action_type":"edit","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277de","name":"Add users","object_type":"user","action_type":"add","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277df","name":"Delete users","object_type":"user","action_type":"destroy","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277e0","name":"Assign a role","object_type":"role","action_type":"assign","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277e1","name":"Browse roles","object_type":"role","action_type":"browse","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277e2","name":"Browse clients","object_type":"client","action_type":"browse","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277e3","name":"Read clients","object_type":"client","action_type":"read","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277e4","name":"Edit clients","object_type":"client","action_type":"edit","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277e5","name":"Add clients","object_type":"client","action_type":"add","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277e6","name":"Delete clients","object_type":"client","action_type":"destroy","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277e7","name":"Browse subscribers","object_type":"subscriber","action_type":"browse","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277e8","name":"Read subscribers","object_type":"subscriber","action_type":"read","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277e9","name":"Edit subscribers","object_type":"subscriber","action_type":"edit","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277ea","name":"Add subscribers","object_type":"subscriber","action_type":"add","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277eb","name":"Delete subscribers","object_type":"subscriber","action_type":"destroy","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277ec","name":"Browse invites","object_type":"invite","action_type":"browse","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277ed","name":"Read invites","object_type":"invite","action_type":"read","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277ee","name":"Edit invites","object_type":"invite","action_type":"edit","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277ef","name":"Add invites","object_type":"invite","action_type":"add","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277f0","name":"Delete invites","object_type":"invite","action_type":"destroy","object_id":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"59e30f44c4d2c41252c4c292","name":"Download redirects","object_type":"redirect","action_type":"download","object_id":null,"created_at":"2017-10-15T07:33:24.000Z","created_by":"1","updated_at":"2017-10-15T07:33:24.000Z","updated_by":"1"},{"id":"59e30f44c4d2c41252c4c293","name":"Upload redirects","object_type":"redirect","action_type":"upload","object_id":null,"created_at":"2017-10-15T07:33:24.000Z","created_by":"1","updated_at":"2017-10-15T07:33:24.000Z","updated_by":"1"},{"id":"5a3a00cceddac110132b6dac","name":"Add webhooks","object_type":"webhook","action_type":"add","object_id":null,"created_at":"2017-12-20T06:18:52.000Z","created_by":"1","updated_at":"2017-12-20T06:18:52.000Z","updated_by":"1"},{"id":"5a3a00cceddac110132b6dad","name":"Delete webhooks","object_type":"webhook","action_type":"destroy","object_id":null,"created_at":"2017-12-20T06:18:52.000Z","created_by":"1","updated_at":"2017-12-20T06:18:52.000Z","updated_by":"1"}],"permissions_apps":[],"permissions_roles":[{"id":"597b43311ffc934f6c0277f2","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277c0"},{"id":"597b43311ffc934f6c0277f3","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277c1"},{"id":"597b43311ffc934f6c0277f4","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277c2"},{"id":"597b43311ffc934f6c0277f5","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277c3"},{"id":"597b43311ffc934f6c0277f6","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277c4"},{"id":"597b43311ffc934f6c0277f7","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277c5"},{"id":"597b43311ffc934f6c0277f8","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277c6"},{"id":"597b43311ffc934f6c0277f9","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277c7"},{"id":"597b43311ffc934f6c0277fa","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277c8"},{"id":"597b43311ffc934f6c0277fb","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277c9"},{"id":"597b43311ffc934f6c0277fc","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277ca"},{"id":"597b43311ffc934f6c0277fd","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277cb"},{"id":"597b43311ffc934f6c0277fe","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277cc"},{"id":"597b43311ffc934f6c0277ff","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277cd"},{"id":"597b43311ffc934f6c027800","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277ce"},{"id":"597b43311ffc934f6c027801","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277cf"},{"id":"597b43311ffc934f6c027802","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277d0"},{"id":"597b43311ffc934f6c027803","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277d1"},{"id":"597b43311ffc934f6c027804","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277d2"},{"id":"597b43311ffc934f6c027805","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277d3"},{"id":"597b43311ffc934f6c027806","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277d4"},{"id":"597b43311ffc934f6c027807","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277d5"},{"id":"597b43311ffc934f6c027808","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277d6"},{"id":"597b43311ffc934f6c027809","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277d7"},{"id":"597b43311ffc934f6c02780a","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277d8"},{"id":"597b43311ffc934f6c02780b","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277d9"},{"id":"597b43311ffc934f6c02780c","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277da"},{"id":"597b43311ffc934f6c02780d","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277db"},{"id":"597b43311ffc934f6c02780e","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277dc"},{"id":"597b43311ffc934f6c02780f","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277dd"},{"id":"597b43311ffc934f6c027810","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277de"},{"id":"597b43311ffc934f6c027811","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277df"},{"id":"597b43311ffc934f6c027812","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277e0"},{"id":"597b43311ffc934f6c027813","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277e1"},{"id":"597b43311ffc934f6c027814","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277e2"},{"id":"597b43311ffc934f6c027815","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277e3"},{"id":"597b43311ffc934f6c027816","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277e4"},{"id":"597b43311ffc934f6c027817","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277e5"},{"id":"597b43311ffc934f6c027818","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277e6"},{"id":"597b43311ffc934f6c027819","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277e7"},{"id":"597b43311ffc934f6c02781a","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277e8"},{"id":"597b43311ffc934f6c02781b","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277e9"},{"id":"597b43311ffc934f6c02781c","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277ea"},{"id":"597b43311ffc934f6c02781d","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277eb"},{"id":"597b43311ffc934f6c02781e","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277ec"},{"id":"597b43311ffc934f6c02781f","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277ed"},{"id":"597b43311ffc934f6c027820","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277ee"},{"id":"597b43311ffc934f6c027821","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277ef"},{"id":"597b43311ffc934f6c027822","role_id":"597b43301ffc934f6c0277bc","permission_id":"597b43301ffc934f6c0277f0"},{"id":"597b43311ffc934f6c027823","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277c7"},{"id":"597b43311ffc934f6c027824","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277c8"},{"id":"597b43311ffc934f6c027825","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277c9"},{"id":"597b43311ffc934f6c027826","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277ca"},{"id":"597b43311ffc934f6c027827","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277cb"},{"id":"597b43311ffc934f6c027828","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277cc"},{"id":"597b43311ffc934f6c027829","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277cd"},{"id":"597b43311ffc934f6c02782a","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277cf"},{"id":"597b43311ffc934f6c02782b","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277d0"},{"id":"597b43311ffc934f6c02782c","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277d1"},{"id":"597b43311ffc934f6c02782d","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277d2"},{"id":"597b43311ffc934f6c02782e","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277d3"},{"id":"597b43311ffc934f6c02782f","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277d4"},{"id":"597b43311ffc934f6c027830","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277db"},{"id":"597b43311ffc934f6c027831","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277dc"},{"id":"597b43311ffc934f6c027832","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277dd"},{"id":"597b43311ffc934f6c027833","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277de"},{"id":"597b43311ffc934f6c027834","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277df"},{"id":"597b43311ffc934f6c027835","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277e0"},{"id":"597b43311ffc934f6c027836","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277e1"},{"id":"597b43311ffc934f6c027837","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277e2"},{"id":"597b43311ffc934f6c027838","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277e3"},{"id":"597b43311ffc934f6c027839","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277e4"},{"id":"597b43311ffc934f6c02783a","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277e5"},{"id":"597b43311ffc934f6c02783b","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277e6"},{"id":"597b43311ffc934f6c02783c","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277ea"},{"id":"597b43311ffc934f6c02783d","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277ec"},{"id":"597b43311ffc934f6c02783e","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277ed"},{"id":"597b43311ffc934f6c02783f","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277ee"},{"id":"597b43311ffc934f6c027840","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277ef"},{"id":"597b43311ffc934f6c027841","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277f0"},{"id":"597b43311ffc934f6c027842","role_id":"597b43301ffc934f6c0277be","permission_id":"597b43301ffc934f6c0277c7"},{"id":"597b43311ffc934f6c027843","role_id":"597b43301ffc934f6c0277be","permission_id":"597b43301ffc934f6c0277c8"},{"id":"597b43311ffc934f6c027844","role_id":"597b43301ffc934f6c0277be","permission_id":"597b43301ffc934f6c0277ca"},{"id":"597b43311ffc934f6c027845","role_id":"597b43301ffc934f6c0277be","permission_id":"597b43301ffc934f6c0277cc"},{"id":"597b43311ffc934f6c027846","role_id":"597b43301ffc934f6c0277be","permission_id":"597b43301ffc934f6c0277cd"},{"id":"597b43311ffc934f6c027847","role_id":"597b43301ffc934f6c0277be","permission_id":"597b43301ffc934f6c0277cf"},{"id":"597b43311ffc934f6c027848","role_id":"597b43301ffc934f6c0277be","permission_id":"597b43301ffc934f6c0277d0"},{"id":"597b43311ffc934f6c027849","role_id":"597b43301ffc934f6c0277be","permission_id":"597b43301ffc934f6c0277d1"},{"id":"597b43311ffc934f6c02784a","role_id":"597b43301ffc934f6c0277be","permission_id":"597b43301ffc934f6c0277d3"},{"id":"597b43311ffc934f6c02784b","role_id":"597b43301ffc934f6c0277be","permission_id":"597b43301ffc934f6c0277db"},{"id":"597b43311ffc934f6c02784c","role_id":"597b43301ffc934f6c0277be","permission_id":"597b43301ffc934f6c0277dc"},{"id":"597b43311ffc934f6c02784d","role_id":"597b43301ffc934f6c0277be","permission_id":"597b43301ffc934f6c0277e1"},{"id":"597b43311ffc934f6c02784e","role_id":"597b43301ffc934f6c0277be","permission_id":"597b43301ffc934f6c0277e2"},{"id":"597b43311ffc934f6c02784f","role_id":"597b43301ffc934f6c0277be","permission_id":"597b43301ffc934f6c0277e3"},{"id":"597b43311ffc934f6c027850","role_id":"597b43301ffc934f6c0277be","permission_id":"597b43301ffc934f6c0277e4"},{"id":"597b43311ffc934f6c027851","role_id":"597b43301ffc934f6c0277be","permission_id":"597b43301ffc934f6c0277e5"},{"id":"597b43311ffc934f6c027852","role_id":"597b43301ffc934f6c0277be","permission_id":"597b43301ffc934f6c0277e6"},{"id":"597b43311ffc934f6c027853","role_id":"597b43301ffc934f6c0277be","permission_id":"597b43301ffc934f6c0277ea"},{"id":"59e30f44c4d2c41252c4c290","role_id":"597b43301ffc934f6c0277bd","permission_id":"597b43301ffc934f6c0277d5"},{"id":"59e30f44c4d2c41252c4c291","role_id":"597b43301ffc934f6c0277be","permission_id":"597b43301ffc934f6c0277d5"},{"id":"59e30f44c4d2c41252c4c294","role_id":"597b43301ffc934f6c0277bc","permission_id":"59e30f44c4d2c41252c4c292"},{"id":"59e30f44c4d2c41252c4c295","role_id":"597b43301ffc934f6c0277bc","permission_id":"59e30f44c4d2c41252c4c293"},{"id":"5a3a00cceddac110132b6dae","role_id":"597b43301ffc934f6c0277bc","permission_id":"5a3a00cceddac110132b6dac"},{"id":"5a3a00cceddac110132b6daf","role_id":"597b43301ffc934f6c0277bc","permission_id":"5a3a00cceddac110132b6dad"},{"id":"5a9845ce6b6eb71021b13f89","role_id":"5a9845ce6b6eb71021b13f88","permission_id":"597b43301ffc934f6c0277c7"},{"id":"5a9845ce6b6eb71021b13f8a","role_id":"5a9845ce6b6eb71021b13f88","permission_id":"597b43301ffc934f6c0277c8"},{"id":"5a9845ce6b6eb71021b13f8b","role_id":"5a9845ce6b6eb71021b13f88","permission_id":"597b43301ffc934f6c0277ca"},{"id":"5a9845cf6b6eb71021b13f8c","role_id":"5a9845ce6b6eb71021b13f88","permission_id":"597b43301ffc934f6c0277cc"},{"id":"5a9845cf6b6eb71021b13f8d","role_id":"5a9845ce6b6eb71021b13f88","permission_id":"597b43301ffc934f6c0277cd"},{"id":"5a9845cf6b6eb71021b13f8e","role_id":"5a9845ce6b6eb71021b13f88","permission_id":"597b43301ffc934f6c0277cf"},{"id":"5a9845cf6b6eb71021b13f8f","role_id":"5a9845ce6b6eb71021b13f88","permission_id":"597b43301ffc934f6c0277d0"},{"id":"5a9845cf6b6eb71021b13f90","role_id":"5a9845ce6b6eb71021b13f88","permission_id":"597b43301ffc934f6c0277d1"},{"id":"5a9845cf6b6eb71021b13f91","role_id":"5a9845ce6b6eb71021b13f88","permission_id":"597b43301ffc934f6c0277db"},{"id":"5a9845cf6b6eb71021b13f92","role_id":"5a9845ce6b6eb71021b13f88","permission_id":"597b43301ffc934f6c0277dc"},{"id":"5a9845cf6b6eb71021b13f93","role_id":"5a9845ce6b6eb71021b13f88","permission_id":"597b43301ffc934f6c0277e1"},{"id":"5a9845cf6b6eb71021b13f94","role_id":"5a9845ce6b6eb71021b13f88","permission_id":"597b43301ffc934f6c0277e2"},{"id":"5a9845cf6b6eb71021b13f95","role_id":"5a9845ce6b6eb71021b13f88","permission_id":"597b43301ffc934f6c0277e3"},{"id":"5a9845cf6b6eb71021b13f96","role_id":"5a9845ce6b6eb71021b13f88","permission_id":"597b43301ffc934f6c0277e4"},{"id":"5a9845cf6b6eb71021b13f97","role_id":"5a9845ce6b6eb71021b13f88","permission_id":"597b43301ffc934f6c0277e5"},{"id":"5a9845cf6b6eb71021b13f98","role_id":"5a9845ce6b6eb71021b13f88","permission_id":"597b43301ffc934f6c0277e6"},{"id":"5a9845cf6b6eb71021b13f99","role_id":"5a9845ce6b6eb71021b13f88","permission_id":"597b43301ffc934f6c0277ea"},{"id":"5a9845cf6b6eb71021b13f9a","role_id":"5a9845ce6b6eb71021b13f88","permission_id":"597b43301ffc934f6c0277d5"}],"permissions_users":[],"posts":[{"id":"597b4433e521cb4fbd91868f","uuid":"3fdc77df-af74-493a-85e4-9e81bc7548ed","title":"Ghost blog online","slug":"ghost-blog-online","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"I just installed [Ghost blog](http://ghost.org/) and what would be a good title of the first blog post? That's right! A post about Ghost =)\\n\\n##Installation\\nMy server is running Ubuntu. Aside from this blog there are a number of websites hosted on it. Its all configured with Apache so I'll write a few notes on installing Ghost blog on Ubuntu and Apache using vhosts (Virtual Hosts).\\n\\n### Apache\\nI use mod_proxy to pass incoming requests to the Ghost application. I deny any request to /ghost/signup, this is to ensure that none can access the signup page. Right now, but that can change!, there can only be one user.\\n\\n```\\n#/etc/apache2/sites-enabled/000-default\\n\\n<VirtualHost *:80>\\n    ServerName ghost.bjurr.se\\n    ProxyPreserveHost on\\n    ProxyPass / http://localhost:2368/\\n\\n# Enable mod_proxy and uncomment to disable signup\\n#    <LocationMatch ^/ghost/signup>\\n#        Order Deny,Allow\\n#        Deny from All\\n#    </LocationMatch>\\n</VirtualHost>\\n```\\n```\\nsudo apachectl restart\\n```\\n\\n### NPM and NodeJS\\nI initially tried APT to install these packages but since those packages are to old I found another way. I used a script called [node-and-npm-in30s.sh](https://gist.github.com/dwayne/2983873).\\n\\n### Installing Ghost\\nRead about it [here](http://docs.ghost.org/installation/linux/).\\n\\n### Making it run, always\\nThere is a number of alternatives here, I went for `supervisor`.\\n```\\nsudo nano -w /etc/supervisor/conf.d/ghost.conf\\n```\\n```\\n[program:ghost]\\ncommand = /home/bjerre/local/bin/node/node /home/bjerre/sites/ghost.bjurr.se/index.js\\ndirectory = /home/bjerre/sites/ghost.bjurr.se\\nuser = bjerre\\nautostart = true\\nautorestart = true\\nstdout_logfile = /var/log/supervisor/ghost.log\\nstderr_logfile = /var/log/supervisor/ghost_err.log\\nenvironment = NODE_ENV=\\\"production\\\"\\n```\\n```\\nsudo supervisorctl restart all\\n```\\n\\n### Issues\\nDuring setup I had some issues, perhaps my solution can help someone. I installed version 0.3.2.\\n\\n* Images folder owned by root. `sudo chown ghost:ghost content/images`\\n* SQLite DB owned by root. `sudo chown ghost:ghost content/data/ghost.db`\\n* Node not found. Fixed by using absolute path to node in supervisor config.\\n* `config.js` not being found. I solved it by downloading current version of `config-loader.js` from the GitHub repository.\\n`wget https://raw.github.com/sebgie/Ghost/6ff17c78a2cb78cf9f445c7c5c41e1350c0840d8/core/config-loader.js`\\n\\nIf you have another issue, I would suggest tailing these logs:\\n\\n* `/var/log/supervisor/*.log`\\n* `/var/log/apache2/error.log`\"}]],\"sections\":[[10,0]]}","html":"<p>I just installed <a href=\"http://ghost.org/\">Ghost blog</a> and what would be a good title of the first blog post? That's right! A post about Ghost =)</p>\n<h2 id=\"installation\">Installation</h2>\n<p>My server is running Ubuntu. Aside from this blog there are a number of websites hosted on it. Its all configured with Apache so I'll write a few notes on installing Ghost blog on Ubuntu and Apache using vhosts (Virtual Hosts).</p>\n<h3 id=\"apache\">Apache</h3>\n<p>I use mod_proxy to pass incoming requests to the Ghost application. I deny any request to /ghost/signup, this is to ensure that none can access the signup page. Right now, but that can change!, there can only be one user.</p>\n<pre><code>#/etc/apache2/sites-enabled/000-default\n\n&lt;VirtualHost *:80&gt;\n    ServerName ghost.bjurr.se\n    ProxyPreserveHost on\n    ProxyPass / http://localhost:2368/\n\n# Enable mod_proxy and uncomment to disable signup\n#    &lt;LocationMatch ^/ghost/signup&gt;\n#        Order Deny,Allow\n#        Deny from All\n#    &lt;/LocationMatch&gt;\n&lt;/VirtualHost&gt;\n</code></pre>\n<pre><code>sudo apachectl restart\n</code></pre>\n<h3 id=\"npmandnodejs\">NPM and NodeJS</h3>\n<p>I initially tried APT to install these packages but since those packages are to old I found another way. I used a script called <a href=\"https://gist.github.com/dwayne/2983873\">node-and-npm-in30s.sh</a>.</p>\n<h3 id=\"installingghost\">Installing Ghost</h3>\n<p>Read about it <a href=\"http://docs.ghost.org/installation/linux/\">here</a>.</p>\n<h3 id=\"makingitrunalways\">Making it run, always</h3>\n<p>There is a number of alternatives here, I went for <code>supervisor</code>.</p>\n<pre><code>sudo nano -w /etc/supervisor/conf.d/ghost.conf\n</code></pre>\n<pre><code>[program:ghost]\ncommand = /home/bjerre/local/bin/node/node /home/bjerre/sites/ghost.bjurr.se/index.js\ndirectory = /home/bjerre/sites/ghost.bjurr.se\nuser = bjerre\nautostart = true\nautorestart = true\nstdout_logfile = /var/log/supervisor/ghost.log\nstderr_logfile = /var/log/supervisor/ghost_err.log\nenvironment = NODE_ENV=&quot;production&quot;\n</code></pre>\n<pre><code>sudo supervisorctl restart all\n</code></pre>\n<h3 id=\"issues\">Issues</h3>\n<p>During setup I had some issues, perhaps my solution can help someone. I installed version 0.3.2.</p>\n<ul>\n<li>Images folder owned by root. <code>sudo chown ghost:ghost content/images</code></li>\n<li>SQLite DB owned by root. <code>sudo chown ghost:ghost content/data/ghost.db</code></li>\n<li>Node not found. Fixed by using absolute path to node in supervisor config.</li>\n<li><code>config.js</code> not being found. I solved it by downloading current version of <code>config-loader.js</code> from the GitHub repository.<br>\n<code>wget https://raw.github.com/sebgie/Ghost/6ff17c78a2cb78cf9f445c7c5c41e1350c0840d8/core/config-loader.js</code></li>\n</ul>\n<p>If you have another issue, I would suggest tailing these logs:</p>\n<ul>\n<li><code>/var/log/supervisor/*.log</code></li>\n<li><code>/var/log/apache2/error.log</code></li>\n</ul>\n","comment_id":"2","plaintext":"I just installed Ghost blog [http://ghost.org/]  and what would be a good title\nof the first blog post? That's right! A post about Ghost =)\n\nInstallation\nMy server is running Ubuntu. Aside from this blog there are a number of websites\nhosted on it. Its all configured with Apache so I'll write a few notes on\ninstalling Ghost blog on Ubuntu and Apache using vhosts (Virtual Hosts).\n\nApache\nI use mod_proxy to pass incoming requests to the Ghost application. I deny any\nrequest to /ghost/signup, this is to ensure that none can access the signup\npage. Right now, but that can change!, there can only be one user.\n\n#/etc/apache2/sites-enabled/000-default\n\n<VirtualHost *:80>\n    ServerName ghost.bjurr.se\n    ProxyPreserveHost on\n    ProxyPass / http://localhost:2368/\n\n# Enable mod_proxy and uncomment to disable signup\n#    <LocationMatch ^/ghost/signup>\n#        Order Deny,Allow\n#        Deny from All\n#    </LocationMatch>\n</VirtualHost>\n\n\nsudo apachectl restart\n\n\nNPM and NodeJS\nI initially tried APT to install these packages but since those packages are to\nold I found another way. I used a script called node-and-npm-in30s.sh\n[https://gist.github.com/dwayne/2983873].\n\nInstalling Ghost\nRead about it here [http://docs.ghost.org/installation/linux/].\n\nMaking it run, always\nThere is a number of alternatives here, I went for supervisor.\n\nsudo nano -w /etc/supervisor/conf.d/ghost.conf\n\n\n[program:ghost]\ncommand = /home/bjerre/local/bin/node/node /home/bjerre/sites/ghost.bjurr.se/index.js\ndirectory = /home/bjerre/sites/ghost.bjurr.se\nuser = bjerre\nautostart = true\nautorestart = true\nstdout_logfile = /var/log/supervisor/ghost.log\nstderr_logfile = /var/log/supervisor/ghost_err.log\nenvironment = NODE_ENV=\"production\"\n\n\nsudo supervisorctl restart all\n\n\nIssues\nDuring setup I had some issues, perhaps my solution can help someone. I\ninstalled version 0.3.2.\n\n * Images folder owned by root. sudo chown ghost:ghost content/images\n * SQLite DB owned by root. sudo chown ghost:ghost content/data/ghost.db\n * Node not found. Fixed by using absolute path to node in supervisor config.\n * config.js  not being found. I solved it by downloading current version of \n   config-loader.js  from the GitHub repository.\n   wget\n   https://raw.github.com/sebgie/Ghost/6ff17c78a2cb78cf9f445c7c5c41e1350c0840d8/core/config-loader.js\n\nIf you have another issue, I would suggest tailing these logs:\n\n * /var/log/supervisor/*.log\n * /var/log/apache2/error.log","feature_image":null,"featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2013-10-18T17:06:59.000Z","created_by":"2","updated_at":"2014-10-04T14:03:14.000Z","updated_by":"1","published_at":"2013-10-20T10:00:00.000Z","published_by":"2","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"custom_template":null},{"id":"597b4433e521cb4fbd918692","uuid":"cf6d402a-0dbb-4872-a1f2-6f7d2d1571dc","title":"JDBC problem: ResultSet.getString returns nothing","slug":"jdbc-problem-resultset-getstring-returns-nothing","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"I recently did some database development in Java using Eclipse with JDBC and MySQL. I came across something very weird that I would like to share.\\n\\nAt first I thought the getString method of my ResultSet instance returned empty Strings but as I started analyzing the returned content I found out that it was actually null bytes. Exactly as many as the length of the expected string.\\n\\nAs always I Googled the phenomena and found people with similar problem, but no solution. I found that this is actually an Eclipse thing and when I tried to run my code outside Eclipse it worked perfectly.\\n\\nI finally came up with a solution, a replacement for getString that uses getAsciiStream insted.\\n```\\npublic String getString(ResultSet result, String column) {\\nString str = new String();\\ntry {\\nInputStreamReader in = new InputStreamReader(result\\n.getAsciiStream(column));\\nwhile (in.ready())\\nstr = str + (char) in.read();\\n} catch (SQLException e) {\\ne.printStackTrace();\\n} catch (IOException e) {\\ne.printStackTrace();\\n} finally {\\nreturn str;\\n}\\n}\\n```\"}]],\"sections\":[[10,0]]}","html":"<p>I recently did some database development in Java using Eclipse with JDBC and MySQL. I came across something very weird that I would like to share.</p>\n<p>At first I thought the getString method of my ResultSet instance returned empty Strings but as I started analyzing the returned content I found out that it was actually null bytes. Exactly as many as the length of the expected string.</p>\n<p>As always I Googled the phenomena and found people with similar problem, but no solution. I found that this is actually an Eclipse thing and when I tried to run my code outside Eclipse it worked perfectly.</p>\n<p>I finally came up with a solution, a replacement for getString that uses getAsciiStream insted.</p>\n<pre><code>public String getString(ResultSet result, String column) {\nString str = new String();\ntry {\nInputStreamReader in = new InputStreamReader(result\n.getAsciiStream(column));\nwhile (in.ready())\nstr = str + (char) in.read();\n} catch (SQLException e) {\ne.printStackTrace();\n} catch (IOException e) {\ne.printStackTrace();\n} finally {\nreturn str;\n}\n}\n</code></pre>\n","comment_id":"5","plaintext":"I recently did some database development in Java using Eclipse with JDBC and\nMySQL. I came across something very weird that I would like to share.\n\nAt first I thought the getString method of my ResultSet instance returned empty\nStrings but as I started analyzing the returned content I found out that it was\nactually null bytes. Exactly as many as the length of the expected string.\n\nAs always I Googled the phenomena and found people with similar problem, but no\nsolution. I found that this is actually an Eclipse thing and when I tried to run\nmy code outside Eclipse it worked perfectly.\n\nI finally came up with a solution, a replacement for getString that uses\ngetAsciiStream insted.\n\npublic String getString(ResultSet result, String column) {\nString str = new String();\ntry {\nInputStreamReader in = new InputStreamReader(result\n.getAsciiStream(column));\nwhile (in.ready())\nstr = str + (char) in.read();\n} catch (SQLException e) {\ne.printStackTrace();\n} catch (IOException e) {\ne.printStackTrace();\n} finally {\nreturn str;\n}\n}","feature_image":null,"featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2013-10-19T09:00:52.000Z","created_by":"2","updated_at":"2014-10-04T14:06:25.000Z","updated_by":"1","published_at":"2013-10-19T09:00:52.000Z","published_by":"2","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"custom_template":null},{"id":"597b4433e521cb4fbd918693","uuid":"d98a892f-fb6e-4276-b733-b48b467f2ba9","title":"Runtime.exec hangs, a complete solution","slug":"runtime-exec-hangs-a-complete-solution","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"If you Google \\\"Runtime.exec hangs\\\" you will get alot of results. Executing external commands from Java seems very easy but it is actually very complicated. I was stuck at this problem for a long time before I finally got it. I never found a complete solution so I tought a post like this may boost my user count =)\\n\\nIf you execute a command using Runtime.exec on Windows and wait for it to complete, like follows, your program may hang on waitFor.\\n```\\nProcess p = Runtime.getRuntime().exec(\\\"myCommand\\\");\\np.waitFor();\\n```\\n\\nThe reason for the hanging is the communication between Java and the external operating system process. And more specifically the communication buffers. The buffers for STDERR and STDOUT has to be flushed for the program not to hang.\\n\\nFlushing these buffers are very easy, but! You can not flush them one by one, you have to do it simultaniously for the program not to hang while flushing! So you have to start at least one new thread to succeed.\\n\\nI have made a complete class that executes a command and serves the content of STDOUT and STDERR. It also provides functionality for sending data to STDIN.\\n```\\nimport java.io.BufferedReader;\\nimport java.io.IOException;\\nimport java.io.InputStreamReader;\\nimport java.io.PrintWriter;\\nimport java.util.ArrayList;\\nimport java.util.concurrent.Semaphore;\\n\\npublic class ExecCommand {\\nprivate Semaphore outputSem;\\nprivate String output;\\nprivate Semaphore errorSem;\\nprivate String error;\\nprivate Process p;\\n\\nprivate class InputWriter extends Thread {\\nprivate String input;\\n\\npublic InputWriter(String input) {\\nthis.input = input;\\n}\\n\\npublic void run() {\\nPrintWriter pw = new PrintWriter(p.getOutputStream());\\npw.println(input);\\npw.flush();\\n}\\n}\\n\\nprivate class OutputReader extends Thread {\\npublic OutputReader() {\\ntry {\\noutputSem = new Semaphore(1);\\noutputSem.acquire();\\n} catch (InterruptedException e) {\\ne.printStackTrace();\\n}\\n}\\n\\npublic void run() {\\ntry {\\nStringBuffer readBuffer = new StringBuffer();\\nBufferedReader isr = new BufferedReader(new InputStreamReader(p\\n.getInputStream()));\\nString buff = new String();\\nwhile ((buff = isr.readLine()) != null) {\\nreadBuffer.append(buff);\\nSystem.out.println(buff);\\n}\\noutput = readBuffer.toString();\\noutputSem.release();\\n} catch (IOException e) {\\ne.printStackTrace();\\n}\\n}\\n}\\n\\nprivate class ErrorReader extends Thread {\\npublic ErrorReader() {\\ntry {\\nerrorSem = new Semaphore(1);\\nerrorSem.acquire();\\n} catch (InterruptedException e) {\\ne.printStackTrace();\\n}\\n}\\n\\npublic void run() {\\ntry {\\nStringBuffer readBuffer = new StringBuffer();\\nBufferedReader isr = new BufferedReader(new InputStreamReader(p\\n.getErrorStream()));\\nString buff = new String();\\nwhile ((buff = isr.readLine()) != null) {\\nreadBuffer.append(buff);\\n}\\nerror = readBuffer.toString();\\nerrorSem.release();\\n} catch (IOException e) {\\ne.printStackTrace();\\n}\\nif (error.length() > 0)\\nSystem.out.println(error);\\n}\\n}\\n\\npublic ExecCommand(String command, String input) {\\ntry {\\np = Runtime.getRuntime().exec(makeArray(command));\\nnew InputWriter(input).start();\\nnew OutputReader().start();\\nnew ErrorReader().start();\\np.waitFor();\\n} catch (IOException e) {\\ne.printStackTrace();\\n} catch (InterruptedException e) {\\ne.printStackTrace();\\n}\\n}\\n\\npublic ExecCommand(String command) {\\ntry {\\np = Runtime.getRuntime().exec(makeArray(command));\\nnew OutputReader().start();\\nnew ErrorReader().start();\\np.waitFor();\\n} catch (IOException e) {\\ne.printStackTrace();\\n} catch (InterruptedException e) {\\ne.printStackTrace();\\n}\\n}\\n\\npublic String getOutput() {\\ntry {\\noutputSem.acquire();\\n} catch (InterruptedException e) {\\ne.printStackTrace();\\n}\\nString value = output;\\noutputSem.release();\\nreturn value;\\n}\\n\\npublic String getError() {\\ntry {\\nerrorSem.acquire();\\n} catch (InterruptedException e) {\\ne.printStackTrace();\\n}\\nString value = error;\\nerrorSem.release();\\nreturn value;\\n}\\n\\nprivate String[] makeArray(String command) {\\nArrayList<String> commandArray = new ArrayList<String>();\\nString buff = \\\"\\\";\\nboolean lookForEnd = false;\\nfor (int i = 0; i < command.length(); i++) {\\nif (lookForEnd) {\\nif (command.charAt(i) == '\\\\\\\"') {\\nif (buff.length() > 0)\\ncommandArray.add(buff);\\nbuff = \\\"\\\";\\nlookForEnd = false;\\n} else {\\nbuff += command.charAt(i);\\n}\\n} else {\\nif (command.charAt(i) == '\\\\\\\"') {\\nlookForEnd = true;\\n} else if (command.charAt(i) == ' ') {\\nif (buff.length() > 0)\\ncommandArray.add(buff);\\nbuff = \\\"\\\";\\n} else {\\nbuff += command.charAt(i);\\n}\\n}\\n}\\nif (buff.length() > 0)\\ncommandArray.add(buff);\\n\\nString[] array = new String[commandArray.size()];\\nfor (int i = 0; i < commandArray.size(); i++) {\\narray[i] = commandArray.get(i);\\n}\\n\\nreturn array;\\n}\\n}\\n```\"}]],\"sections\":[[10,0]]}","html":"<p>If you Google &quot;Runtime.exec hangs&quot; you will get alot of results. Executing external commands from Java seems very easy but it is actually very complicated. I was stuck at this problem for a long time before I finally got it. I never found a complete solution so I tought a post like this may boost my user count =)</p>\n<p>If you execute a command using Runtime.exec on Windows and wait for it to complete, like follows, your program may hang on waitFor.</p>\n<pre><code>Process p = Runtime.getRuntime().exec(&quot;myCommand&quot;);\np.waitFor();\n</code></pre>\n<p>The reason for the hanging is the communication between Java and the external operating system process. And more specifically the communication buffers. The buffers for STDERR and STDOUT has to be flushed for the program not to hang.</p>\n<p>Flushing these buffers are very easy, but! You can not flush them one by one, you have to do it simultaniously for the program not to hang while flushing! So you have to start at least one new thread to succeed.</p>\n<p>I have made a complete class that executes a command and serves the content of STDOUT and STDERR. It also provides functionality for sending data to STDIN.</p>\n<pre><code>import java.io.BufferedReader;\nimport java.io.IOException;\nimport java.io.InputStreamReader;\nimport java.io.PrintWriter;\nimport java.util.ArrayList;\nimport java.util.concurrent.Semaphore;\n\npublic class ExecCommand {\nprivate Semaphore outputSem;\nprivate String output;\nprivate Semaphore errorSem;\nprivate String error;\nprivate Process p;\n\nprivate class InputWriter extends Thread {\nprivate String input;\n\npublic InputWriter(String input) {\nthis.input = input;\n}\n\npublic void run() {\nPrintWriter pw = new PrintWriter(p.getOutputStream());\npw.println(input);\npw.flush();\n}\n}\n\nprivate class OutputReader extends Thread {\npublic OutputReader() {\ntry {\noutputSem = new Semaphore(1);\noutputSem.acquire();\n} catch (InterruptedException e) {\ne.printStackTrace();\n}\n}\n\npublic void run() {\ntry {\nStringBuffer readBuffer = new StringBuffer();\nBufferedReader isr = new BufferedReader(new InputStreamReader(p\n.getInputStream()));\nString buff = new String();\nwhile ((buff = isr.readLine()) != null) {\nreadBuffer.append(buff);\nSystem.out.println(buff);\n}\noutput = readBuffer.toString();\noutputSem.release();\n} catch (IOException e) {\ne.printStackTrace();\n}\n}\n}\n\nprivate class ErrorReader extends Thread {\npublic ErrorReader() {\ntry {\nerrorSem = new Semaphore(1);\nerrorSem.acquire();\n} catch (InterruptedException e) {\ne.printStackTrace();\n}\n}\n\npublic void run() {\ntry {\nStringBuffer readBuffer = new StringBuffer();\nBufferedReader isr = new BufferedReader(new InputStreamReader(p\n.getErrorStream()));\nString buff = new String();\nwhile ((buff = isr.readLine()) != null) {\nreadBuffer.append(buff);\n}\nerror = readBuffer.toString();\nerrorSem.release();\n} catch (IOException e) {\ne.printStackTrace();\n}\nif (error.length() &gt; 0)\nSystem.out.println(error);\n}\n}\n\npublic ExecCommand(String command, String input) {\ntry {\np = Runtime.getRuntime().exec(makeArray(command));\nnew InputWriter(input).start();\nnew OutputReader().start();\nnew ErrorReader().start();\np.waitFor();\n} catch (IOException e) {\ne.printStackTrace();\n} catch (InterruptedException e) {\ne.printStackTrace();\n}\n}\n\npublic ExecCommand(String command) {\ntry {\np = Runtime.getRuntime().exec(makeArray(command));\nnew OutputReader().start();\nnew ErrorReader().start();\np.waitFor();\n} catch (IOException e) {\ne.printStackTrace();\n} catch (InterruptedException e) {\ne.printStackTrace();\n}\n}\n\npublic String getOutput() {\ntry {\noutputSem.acquire();\n} catch (InterruptedException e) {\ne.printStackTrace();\n}\nString value = output;\noutputSem.release();\nreturn value;\n}\n\npublic String getError() {\ntry {\nerrorSem.acquire();\n} catch (InterruptedException e) {\ne.printStackTrace();\n}\nString value = error;\nerrorSem.release();\nreturn value;\n}\n\nprivate String[] makeArray(String command) {\nArrayList&lt;String&gt; commandArray = new ArrayList&lt;String&gt;();\nString buff = &quot;&quot;;\nboolean lookForEnd = false;\nfor (int i = 0; i &lt; command.length(); i++) {\nif (lookForEnd) {\nif (command.charAt(i) == '\\&quot;') {\nif (buff.length() &gt; 0)\ncommandArray.add(buff);\nbuff = &quot;&quot;;\nlookForEnd = false;\n} else {\nbuff += command.charAt(i);\n}\n} else {\nif (command.charAt(i) == '\\&quot;') {\nlookForEnd = true;\n} else if (command.charAt(i) == ' ') {\nif (buff.length() &gt; 0)\ncommandArray.add(buff);\nbuff = &quot;&quot;;\n} else {\nbuff += command.charAt(i);\n}\n}\n}\nif (buff.length() &gt; 0)\ncommandArray.add(buff);\n\nString[] array = new String[commandArray.size()];\nfor (int i = 0; i &lt; commandArray.size(); i++) {\narray[i] = commandArray.get(i);\n}\n\nreturn array;\n}\n}\n</code></pre>\n","comment_id":"6","plaintext":"If you Google \"Runtime.exec hangs\" you will get alot of results. Executing\nexternal commands from Java seems very easy but it is actually very complicated.\nI was stuck at this problem for a long time before I finally got it. I never\nfound a complete solution so I tought a post like this may boost my user count\n=)\n\nIf you execute a command using Runtime.exec on Windows and wait for it to\ncomplete, like follows, your program may hang on waitFor.\n\nProcess p = Runtime.getRuntime().exec(\"myCommand\");\np.waitFor();\n\n\nThe reason for the hanging is the communication between Java and the external\noperating system process. And more specifically the communication buffers. The\nbuffers for STDERR and STDOUT has to be flushed for the program not to hang.\n\nFlushing these buffers are very easy, but! You can not flush them one by one,\nyou have to do it simultaniously for the program not to hang while flushing! So\nyou have to start at least one new thread to succeed.\n\nI have made a complete class that executes a command and serves the content of\nSTDOUT and STDERR. It also provides functionality for sending data to STDIN.\n\nimport java.io.BufferedReader;\nimport java.io.IOException;\nimport java.io.InputStreamReader;\nimport java.io.PrintWriter;\nimport java.util.ArrayList;\nimport java.util.concurrent.Semaphore;\n\npublic class ExecCommand {\nprivate Semaphore outputSem;\nprivate String output;\nprivate Semaphore errorSem;\nprivate String error;\nprivate Process p;\n\nprivate class InputWriter extends Thread {\nprivate String input;\n\npublic InputWriter(String input) {\nthis.input = input;\n}\n\npublic void run() {\nPrintWriter pw = new PrintWriter(p.getOutputStream());\npw.println(input);\npw.flush();\n}\n}\n\nprivate class OutputReader extends Thread {\npublic OutputReader() {\ntry {\noutputSem = new Semaphore(1);\noutputSem.acquire();\n} catch (InterruptedException e) {\ne.printStackTrace();\n}\n}\n\npublic void run() {\ntry {\nStringBuffer readBuffer = new StringBuffer();\nBufferedReader isr = new BufferedReader(new InputStreamReader(p\n.getInputStream()));\nString buff = new String();\nwhile ((buff = isr.readLine()) != null) {\nreadBuffer.append(buff);\nSystem.out.println(buff);\n}\noutput = readBuffer.toString();\noutputSem.release();\n} catch (IOException e) {\ne.printStackTrace();\n}\n}\n}\n\nprivate class ErrorReader extends Thread {\npublic ErrorReader() {\ntry {\nerrorSem = new Semaphore(1);\nerrorSem.acquire();\n} catch (InterruptedException e) {\ne.printStackTrace();\n}\n}\n\npublic void run() {\ntry {\nStringBuffer readBuffer = new StringBuffer();\nBufferedReader isr = new BufferedReader(new InputStreamReader(p\n.getErrorStream()));\nString buff = new String();\nwhile ((buff = isr.readLine()) != null) {\nreadBuffer.append(buff);\n}\nerror = readBuffer.toString();\nerrorSem.release();\n} catch (IOException e) {\ne.printStackTrace();\n}\nif (error.length() > 0)\nSystem.out.println(error);\n}\n}\n\npublic ExecCommand(String command, String input) {\ntry {\np = Runtime.getRuntime().exec(makeArray(command));\nnew InputWriter(input).start();\nnew OutputReader().start();\nnew ErrorReader().start();\np.waitFor();\n} catch (IOException e) {\ne.printStackTrace();\n} catch (InterruptedException e) {\ne.printStackTrace();\n}\n}\n\npublic ExecCommand(String command) {\ntry {\np = Runtime.getRuntime().exec(makeArray(command));\nnew OutputReader().start();\nnew ErrorReader().start();\np.waitFor();\n} catch (IOException e) {\ne.printStackTrace();\n} catch (InterruptedException e) {\ne.printStackTrace();\n}\n}\n\npublic String getOutput() {\ntry {\noutputSem.acquire();\n} catch (InterruptedException e) {\ne.printStackTrace();\n}\nString value = output;\noutputSem.release();\nreturn value;\n}\n\npublic String getError() {\ntry {\nerrorSem.acquire();\n} catch (InterruptedException e) {\ne.printStackTrace();\n}\nString value = error;\nerrorSem.release();\nreturn value;\n}\n\nprivate String[] makeArray(String command) {\nArrayList<String> commandArray = new ArrayList<String>();\nString buff = \"\";\nboolean lookForEnd = false;\nfor (int i = 0; i < command.length(); i++) {\nif (lookForEnd) {\nif (command.charAt(i) == '\\\"') {\nif (buff.length() > 0)\ncommandArray.add(buff);\nbuff = \"\";\nlookForEnd = false;\n} else {\nbuff += command.charAt(i);\n}\n} else {\nif (command.charAt(i) == '\\\"') {\nlookForEnd = true;\n} else if (command.charAt(i) == ' ') {\nif (buff.length() > 0)\ncommandArray.add(buff);\nbuff = \"\";\n} else {\nbuff += command.charAt(i);\n}\n}\n}\nif (buff.length() > 0)\ncommandArray.add(buff);\n\nString[] array = new String[commandArray.size()];\nfor (int i = 0; i < commandArray.size(); i++) {\narray[i] = commandArray.get(i);\n}\n\nreturn array;\n}\n}","feature_image":null,"featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2013-10-19T09:02:28.000Z","created_by":"2","updated_at":"2014-10-04T14:06:09.000Z","updated_by":"1","published_at":"2013-10-19T09:02:28.000Z","published_by":"2","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"custom_template":null},{"id":"597b4433e521cb4fbd918694","uuid":"46517bb8-933d-4c44-a99d-0dfe8081301a","title":"Introducing HTMLUnitGenerator","slug":"introducing-htmlunitgenerator","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"I strongly support software testing. If you don't produce test cases that cover the requirements you implement, then you are not developing anything. It is impossible to reach sustainability, produce new functionality fast and with high quality or even cooperate with other developers, unless you work with automated test cases!\\n\\nBeing a web developer I've been faced with problem of testing front end of web applications. When it comes to GUI and making sure its look and feel is as it should, the testing is done by a human resource. But when it comes to making sure flows can be executed without JavaScripts, CSS or backend crashes, or just making sure a text actually appears on a webpage, I want automated testing.\\nHTMLUnit\\n\\nHTMLUnit is a really nice tool. It is a head less web browser. This is perfect for creating test cases that clicks on different elements and does asserts on, for example, different attributes and values.\\n\\nThe problem is, we don't want to write those test cases in Java. Java is a general purpose programming language. The test cases will get messy and hard to read. They don't have to but the chances are they will.\\n\\nAnother problem is documentation of test cases. If we write test cases in Java we need to document them to make sure what flows are covered. This is extra important with front end testing, since these test can be very time consuming when testing a large web site.\\nHTMLUnitGenrerator\\n\\nI created an open source project to deal with these problems. I have created a domain specific language, DSL. You may say the test cases are automatically generated from the documentation, since the DSL is so easy to read and understand, it could just as well be documentation to a test case written in Java.\\n\\nHere is a sneak peak, check out GitHub for more examples.\\n```\\nSee testcases/BBBSeePaths.flow\\nSee testcases/BBBSeeUrls.flow\\nGo to baspaket and wait 2 seconds\\nFind a with attribute href set to /servlet/orderflow/search/search-flow?Id=tcm:142-23371 in campaignmodule\\nClick on campaignModuleChoose and wait 10 seconds\\nFind input with attribute id set to _eventId_search in searchpopup\\nFill in locationForm with _eventId as search and phoneNumber.fullNumber as 0768966787\\nClick on _eventId_search and wait 10 seconds\\nFind input with attribute id set to _eventId_search in searchpopup\\nFill in locationForm with address.floor as 3\\nClick on _eventId_search and wait 10 seconds\\nFind a with attribute href set to /orderflow/index.html?Id=tcm:142-23381&fromSearch&page=new in searchpopup\\n```\"}]],\"sections\":[[10,0]]}","html":"<p>I strongly support software testing. If you don't produce test cases that cover the requirements you implement, then you are not developing anything. It is impossible to reach sustainability, produce new functionality fast and with high quality or even cooperate with other developers, unless you work with automated test cases!</p>\n<p>Being a web developer I've been faced with problem of testing front end of web applications. When it comes to GUI and making sure its look and feel is as it should, the testing is done by a human resource. But when it comes to making sure flows can be executed without JavaScripts, CSS or backend crashes, or just making sure a text actually appears on a webpage, I want automated testing.<br>\nHTMLUnit</p>\n<p>HTMLUnit is a really nice tool. It is a head less web browser. This is perfect for creating test cases that clicks on different elements and does asserts on, for example, different attributes and values.</p>\n<p>The problem is, we don't want to write those test cases in Java. Java is a general purpose programming language. The test cases will get messy and hard to read. They don't have to but the chances are they will.</p>\n<p>Another problem is documentation of test cases. If we write test cases in Java we need to document them to make sure what flows are covered. This is extra important with front end testing, since these test can be very time consuming when testing a large web site.<br>\nHTMLUnitGenrerator</p>\n<p>I created an open source project to deal with these problems. I have created a domain specific language, DSL. You may say the test cases are automatically generated from the documentation, since the DSL is so easy to read and understand, it could just as well be documentation to a test case written in Java.</p>\n<p>Here is a sneak peak, check out GitHub for more examples.</p>\n<pre><code>See testcases/BBBSeePaths.flow\nSee testcases/BBBSeeUrls.flow\nGo to baspaket and wait 2 seconds\nFind a with attribute href set to /servlet/orderflow/search/search-flow?Id=tcm:142-23371 in campaignmodule\nClick on campaignModuleChoose and wait 10 seconds\nFind input with attribute id set to _eventId_search in searchpopup\nFill in locationForm with _eventId as search and phoneNumber.fullNumber as 0768966787\nClick on _eventId_search and wait 10 seconds\nFind input with attribute id set to _eventId_search in searchpopup\nFill in locationForm with address.floor as 3\nClick on _eventId_search and wait 10 seconds\nFind a with attribute href set to /orderflow/index.html?Id=tcm:142-23381&amp;fromSearch&amp;page=new in searchpopup\n</code></pre>\n","comment_id":"7","plaintext":"I strongly support software testing. If you don't produce test cases that cover\nthe requirements you implement, then you are not developing anything. It is\nimpossible to reach sustainability, produce new functionality fast and with high\nquality or even cooperate with other developers, unless you work with automated\ntest cases!\n\nBeing a web developer I've been faced with problem of testing front end of web\napplications. When it comes to GUI and making sure its look and feel is as it\nshould, the testing is done by a human resource. But when it comes to making\nsure flows can be executed without JavaScripts, CSS or backend crashes, or just\nmaking sure a text actually appears on a webpage, I want automated testing.\nHTMLUnit\n\nHTMLUnit is a really nice tool. It is a head less web browser. This is perfect\nfor creating test cases that clicks on different elements and does asserts on,\nfor example, different attributes and values.\n\nThe problem is, we don't want to write those test cases in Java. Java is a\ngeneral purpose programming language. The test cases will get messy and hard to\nread. They don't have to but the chances are they will.\n\nAnother problem is documentation of test cases. If we write test cases in Java\nwe need to document them to make sure what flows are covered. This is extra\nimportant with front end testing, since these test can be very time consuming\nwhen testing a large web site.\nHTMLUnitGenrerator\n\nI created an open source project to deal with these problems. I have created a\ndomain specific language, DSL. You may say the test cases are automatically\ngenerated from the documentation, since the DSL is so easy to read and\nunderstand, it could just as well be documentation to a test case written in\nJava.\n\nHere is a sneak peak, check out GitHub for more examples.\n\nSee testcases/BBBSeePaths.flow\nSee testcases/BBBSeeUrls.flow\nGo to baspaket and wait 2 seconds\nFind a with attribute href set to /servlet/orderflow/search/search-flow?Id=tcm:142-23371 in campaignmodule\nClick on campaignModuleChoose and wait 10 seconds\nFind input with attribute id set to _eventId_search in searchpopup\nFill in locationForm with _eventId as search and phoneNumber.fullNumber as 0768966787\nClick on _eventId_search and wait 10 seconds\nFind input with attribute id set to _eventId_search in searchpopup\nFill in locationForm with address.floor as 3\nClick on _eventId_search and wait 10 seconds\nFind a with attribute href set to /orderflow/index.html?Id=tcm:142-23381&fromSearch&page=new in searchpopup","feature_image":null,"featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2013-10-19T09:03:22.000Z","created_by":"2","updated_at":"2014-10-04T14:05:47.000Z","updated_by":"1","published_at":"2013-10-19T09:03:22.000Z","published_by":"2","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"custom_template":null},{"id":"597b4433e521cb4fbd918696","uuid":"88f69eb1-256c-40a9-8eab-8133b22f0fa9","title":"Owncloud 5 Server with Lighttpd, Sqlite on ArchLinux","slug":"owncloud-5-server-with-lighttpd-sqlite-on-archlinux","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"I just installed Owncloud Server on my Raspberry PI. It was a bit harder then I had expected so I'll summarize how I did it and the issues I had. I'm using Raspberry PI (512Mb model), ArchLinux, Lighttpd 1.4.32, SQLite 3.7.17.\\n##Lighttpd\\n\\nFirst, install it.\\n```\\npacman -S lighttpd\\n```\\n\\nThe Lighttpd config file exists in `/etc/lighttpd/lighttpd.conf`. I made alot of changes here it's probably easiest just to show the whole file.\\n```\\nserver.port = 80\\nserver.username = \\\"http\\\"\\nserver.groupname = \\\"http\\\"\\nserver.document-root = \\\"/srv/http\\\"\\nserver.errorlog = \\\"/var/log/lighttpd/error.log\\\"\\ndir-listing.activate = \\\"enable\\\"\\nindex-file.names = ( \\\"index.html\\\", \\\"index.php\\\" )\\nstatic-file.exclude-extensions = (\\\".php\\\", \\\".pl\\\", \\\".fcgi\\\")\\nmimetype.assign = ( \\\".html\\\" => \\\"text/html\\\", \\\".txt\\\" => \\\"text/plain\\\", \\\".jpg\\\" => \\\"image/jpeg\\\", \\\".png\\\" => \\\"image/png\\\", \\\"\\\" => \\\"application/octet-stream\\\" )\\n#ssl.engine = \\\"enable\\\"\\n\\nssl.pemfile = \\\"/etc/ssl/owncloud/server.pem\\\"\\n\\nserver.modules = (\\n\\\"mod_access\\\",\\n\\\"mod_fastcgi\\\",\\n\\\"mod_cgi\\\"\\n)\\n\\n$HTTP[\\\"url\\\"] =~ \\\"^/owncloud/data/\\\" {\\nurl.access-deny = (\\\"\\\")\\n}\\n$HTTP[\\\"url\\\"] =~ \\\"^/owncloud($|/)\\\" {\\ndir-listing.activate = \\\"disable\\\"\\n}\\n\\nfastcgi.server = (\\n\\\".php\\\" => ((\\n\\\"bin-path\\\" => \\\"/usr/bin/php-cgi\\\",\\n\\\"socket\\\" => \\\"/tmp/php.socket\\\",\\n\\\"max-procs\\\" => 4\\n))\\n)\\n```\\n\\nYou can test the Lighttpd configuration like this.\\n```\\nlighttpd -t -f /etc/lighttpd/lighttpd.conf\\n```\\n##PHP\\n\\nInstall like this.\\n```\\npacman -S php-cgi\\n```\\n\\nThe configuration exists in `/etc/php/php.ini`. There are a number of settings to change here. Here are the extensions I found was neccessary for Owncloud.\\n```\\nextension=curl.so\\nextension=gd.so\\nextension=iconv.so\\nextension=openssl.so\\nextension=pdo_sqlite.so\\nextension=sqlite3.so\\nextension=zip.so\\n```\\n\\nThe document root has to be set.\\n```\\ndoc_root = /srv/http\\n```\\n\\nI don't know exactly what this is, but it is needed =)\\n```\\ncgi.fix_pathinfo=1\\n```\\n##OpenSSL\\n```\\npacman -S openssl\\nmkdir /etc/ssl/owncloud\\ncd /etc/ssl/owncloud\\nopenssl req -new -x509 -keyout server.pem -out server.pem -days 365 -nodes\\nchmod 0600 /etc/ssl/owncloud\\n```\\n##Install Owncloud\\n\\nInstall and link the application to make it available in webserver. I like this solution better then copying the files. Now it's easier to keep it updated with Pacman.\\n```\\npacman -S owncloud\\nln -s /usr/share/webapps/owncloud /srv/http/owncloud\\n```\\n\\nTime to start the webserver!\\n```\\nlighttpd -t -f /etc/lighttpd/lighttpd.conf #This test can save you some time!\\nsystemctl restart lighttpd.service\\n```\\n\\nNow you can surf into /owncloud and the application should be running. You will most likely get a response similar to this.\\nNo database drivers (sqlite, mysql, or postgresql) installed.\\nPHP module zip not installed.\\n\\n```\\nPlease ask your server administrator to install the module.\\nPHP module GD is not installed.\\n\\nPlease ask your server administrator to install the module.\\nPHP module iconv is not installed.\\n\\nPlease ask your server administrator to install the module.\\n```\\n\\nI installed them one by one, and then restarted Lighttpd to see that they got installed correctly. Like php-sqlite for example.\\n```\\npacman -Ss sqlite #search for sqlite\\npacman -S extra/php-sqlite #install php-sqlite\\n```\\n\\nIt may be that they are just not enabled in `php.ini` extensions section, and/or that they are not even intalled. Like I had PHP-GD installed but had missed `;extension=gd.so` in `php.ini`.\\n\\nWhen all extensions are in place, you will see two input fields where you input admin user and password. Once entered it will take a very long time to submit the form! I actually gave up and did a restart of Lighttpd. After that it loaded faster.\\nIssues\\n\\nIf you have issues, there are helpful logs.\\n```\\ntail -f /srv/http/owncloud/data/owncloud.log\\ntail -f /var/log/lighttpd/error.log\\n```\\n\\nFirst issue I had was that the first page got stuck hanging on \\\"Upgrading filesystem cache\\\". Looking at the log I found.\\n```\\n2013-07-22 18:28:35: (mod_fastcgi.c.2676) FastCGI-stderr: PHP Fatal error: Call to a member function raiseError() on a non-object in /usr/share/webapps/owncloud/lib/MDB2/Driver/sqlite3.php on line 898\\n```\\n\\nThis is very easy to solve, just uncomment \\n```\\n\\\"extension=pdo_sqlite.so\\\" in php.ini.\\nextension=pdo_sqlite.so\\n```\\n\\nSecond problem was admin got stuck. I got a tip that it could be PHP not being able to lookup `apps.owncloud.com` so I tried this.\\n```\\necho \\\"<?php echo gethostbyname('apps.owncloud.com'); ?&rt;\\\" > /srv/http/dns.php\\n```\\n\\nAnd the dns.php page also got stuck. I added the entry in `/etc/hosts` like this, not nice but it works for now.\\n```\\n188.138.118.86 apps.owncloud.com apps.owncloud.com\\n```\\n\\nHowever, the admin page was not accessble, it also hang. In the `owncloud.log` I saw.\\n```\\n{\\\"app\\\":\\\"PHP\\\",\\\"message\\\":\\\"curl_setopt_array(): CURLOPT_FOLLOWLOCATION cannot be activated when an open_basedir is set at \\\\/usr\\\\/share\\\\/webapps\\\\/owncloud\\\\/3rdparty\\\\/Sabre\\\\/DAV\\\\/Client.php#462\\\",\\\"level\\\":2,\\\"time\\\":814}\\n```\\n\\nI fixed that by commenting out open_basedir in php.ini.\\n```\\n;open_basedir = ...\\n```\\n\\nThe third thing, that definitly finally did the trick, was `max-procs` parameter in Lighttpd config. I had it set to `1` and I changed it to `4`.\\n\\nLast I recommend looking at https://forum.owncloud.org/viewtopic.php?f=8&t=10692 for performance tips.\\n\\n\"}]],\"sections\":[[10,0]]}","html":"<p>I just installed Owncloud Server on my Raspberry PI. It was a bit harder then I had expected so I'll summarize how I did it and the issues I had. I'm using Raspberry PI (512Mb model), ArchLinux, Lighttpd 1.4.32, SQLite 3.7.17.</p>\n<h2 id=\"lighttpd\">Lighttpd</h2>\n<p>First, install it.</p>\n<pre><code>pacman -S lighttpd\n</code></pre>\n<p>The Lighttpd config file exists in <code>/etc/lighttpd/lighttpd.conf</code>. I made alot of changes here it's probably easiest just to show the whole file.</p>\n<pre><code>server.port = 80\nserver.username = &quot;http&quot;\nserver.groupname = &quot;http&quot;\nserver.document-root = &quot;/srv/http&quot;\nserver.errorlog = &quot;/var/log/lighttpd/error.log&quot;\ndir-listing.activate = &quot;enable&quot;\nindex-file.names = ( &quot;index.html&quot;, &quot;index.php&quot; )\nstatic-file.exclude-extensions = (&quot;.php&quot;, &quot;.pl&quot;, &quot;.fcgi&quot;)\nmimetype.assign = ( &quot;.html&quot; =&gt; &quot;text/html&quot;, &quot;.txt&quot; =&gt; &quot;text/plain&quot;, &quot;.jpg&quot; =&gt; &quot;image/jpeg&quot;, &quot;.png&quot; =&gt; &quot;image/png&quot;, &quot;&quot; =&gt; &quot;application/octet-stream&quot; )\n#ssl.engine = &quot;enable&quot;\n\nssl.pemfile = &quot;/etc/ssl/owncloud/server.pem&quot;\n\nserver.modules = (\n&quot;mod_access&quot;,\n&quot;mod_fastcgi&quot;,\n&quot;mod_cgi&quot;\n)\n\n$HTTP[&quot;url&quot;] =~ &quot;^/owncloud/data/&quot; {\nurl.access-deny = (&quot;&quot;)\n}\n$HTTP[&quot;url&quot;] =~ &quot;^/owncloud($|/)&quot; {\ndir-listing.activate = &quot;disable&quot;\n}\n\nfastcgi.server = (\n&quot;.php&quot; =&gt; ((\n&quot;bin-path&quot; =&gt; &quot;/usr/bin/php-cgi&quot;,\n&quot;socket&quot; =&gt; &quot;/tmp/php.socket&quot;,\n&quot;max-procs&quot; =&gt; 4\n))\n)\n</code></pre>\n<p>You can test the Lighttpd configuration like this.</p>\n<pre><code>lighttpd -t -f /etc/lighttpd/lighttpd.conf\n</code></pre>\n<h2 id=\"php\">PHP</h2>\n<p>Install like this.</p>\n<pre><code>pacman -S php-cgi\n</code></pre>\n<p>The configuration exists in <code>/etc/php/php.ini</code>. There are a number of settings to change here. Here are the extensions I found was neccessary for Owncloud.</p>\n<pre><code>extension=curl.so\nextension=gd.so\nextension=iconv.so\nextension=openssl.so\nextension=pdo_sqlite.so\nextension=sqlite3.so\nextension=zip.so\n</code></pre>\n<p>The document root has to be set.</p>\n<pre><code>doc_root = /srv/http\n</code></pre>\n<p>I don't know exactly what this is, but it is needed =)</p>\n<pre><code>cgi.fix_pathinfo=1\n</code></pre>\n<h2 id=\"openssl\">OpenSSL</h2>\n<pre><code>pacman -S openssl\nmkdir /etc/ssl/owncloud\ncd /etc/ssl/owncloud\nopenssl req -new -x509 -keyout server.pem -out server.pem -days 365 -nodes\nchmod 0600 /etc/ssl/owncloud\n</code></pre>\n<h2 id=\"installowncloud\">Install Owncloud</h2>\n<p>Install and link the application to make it available in webserver. I like this solution better then copying the files. Now it's easier to keep it updated with Pacman.</p>\n<pre><code>pacman -S owncloud\nln -s /usr/share/webapps/owncloud /srv/http/owncloud\n</code></pre>\n<p>Time to start the webserver!</p>\n<pre><code>lighttpd -t -f /etc/lighttpd/lighttpd.conf #This test can save you some time!\nsystemctl restart lighttpd.service\n</code></pre>\n<p>Now you can surf into /owncloud and the application should be running. You will most likely get a response similar to this.<br>\nNo database drivers (sqlite, mysql, or postgresql) installed.<br>\nPHP module zip not installed.</p>\n<pre><code>Please ask your server administrator to install the module.\nPHP module GD is not installed.\n\nPlease ask your server administrator to install the module.\nPHP module iconv is not installed.\n\nPlease ask your server administrator to install the module.\n</code></pre>\n<p>I installed them one by one, and then restarted Lighttpd to see that they got installed correctly. Like php-sqlite for example.</p>\n<pre><code>pacman -Ss sqlite #search for sqlite\npacman -S extra/php-sqlite #install php-sqlite\n</code></pre>\n<p>It may be that they are just not enabled in <code>php.ini</code> extensions section, and/or that they are not even intalled. Like I had PHP-GD installed but had missed <code>;extension=gd.so</code> in <code>php.ini</code>.</p>\n<p>When all extensions are in place, you will see two input fields where you input admin user and password. Once entered it will take a very long time to submit the form! I actually gave up and did a restart of Lighttpd. After that it loaded faster.<br>\nIssues</p>\n<p>If you have issues, there are helpful logs.</p>\n<pre><code>tail -f /srv/http/owncloud/data/owncloud.log\ntail -f /var/log/lighttpd/error.log\n</code></pre>\n<p>First issue I had was that the first page got stuck hanging on &quot;Upgrading filesystem cache&quot;. Looking at the log I found.</p>\n<pre><code>2013-07-22 18:28:35: (mod_fastcgi.c.2676) FastCGI-stderr: PHP Fatal error: Call to a member function raiseError() on a non-object in /usr/share/webapps/owncloud/lib/MDB2/Driver/sqlite3.php on line 898\n</code></pre>\n<p>This is very easy to solve, just uncomment</p>\n<pre><code>&quot;extension=pdo_sqlite.so&quot; in php.ini.\nextension=pdo_sqlite.so\n</code></pre>\n<p>Second problem was admin got stuck. I got a tip that it could be PHP not being able to lookup <code>apps.owncloud.com</code> so I tried this.</p>\n<pre><code>echo &quot;&lt;?php echo gethostbyname('apps.owncloud.com'); ?&amp;rt;&quot; &gt; /srv/http/dns.php\n</code></pre>\n<p>And the dns.php page also got stuck. I added the entry in <code>/etc/hosts</code> like this, not nice but it works for now.</p>\n<pre><code>188.138.118.86 apps.owncloud.com apps.owncloud.com\n</code></pre>\n<p>However, the admin page was not accessble, it also hang. In the <code>owncloud.log</code> I saw.</p>\n<pre><code>{&quot;app&quot;:&quot;PHP&quot;,&quot;message&quot;:&quot;curl_setopt_array(): CURLOPT_FOLLOWLOCATION cannot be activated when an open_basedir is set at \\/usr\\/share\\/webapps\\/owncloud\\/3rdparty\\/Sabre\\/DAV\\/Client.php#462&quot;,&quot;level&quot;:2,&quot;time&quot;:814}\n</code></pre>\n<p>I fixed that by commenting out open_basedir in php.ini.</p>\n<pre><code>;open_basedir = ...\n</code></pre>\n<p>The third thing, that definitly finally did the trick, was <code>max-procs</code> parameter in Lighttpd config. I had it set to <code>1</code> and I changed it to <code>4</code>.</p>\n<p>Last I recommend looking at <a href=\"https://forum.owncloud.org/viewtopic.php?f=8&amp;t=10692\">https://forum.owncloud.org/viewtopic.php?f=8&amp;t=10692</a> for performance tips.</p>\n","comment_id":"9","plaintext":"I just installed Owncloud Server on my Raspberry PI. It was a bit harder then I\nhad expected so I'll summarize how I did it and the issues I had. I'm using\nRaspberry PI (512Mb model), ArchLinux, Lighttpd 1.4.32, SQLite 3.7.17.\n\nLighttpd\nFirst, install it.\n\npacman -S lighttpd\n\n\nThe Lighttpd config file exists in /etc/lighttpd/lighttpd.conf. I made alot of\nchanges here it's probably easiest just to show the whole file.\n\nserver.port = 80\nserver.username = \"http\"\nserver.groupname = \"http\"\nserver.document-root = \"/srv/http\"\nserver.errorlog = \"/var/log/lighttpd/error.log\"\ndir-listing.activate = \"enable\"\nindex-file.names = ( \"index.html\", \"index.php\" )\nstatic-file.exclude-extensions = (\".php\", \".pl\", \".fcgi\")\nmimetype.assign = ( \".html\" => \"text/html\", \".txt\" => \"text/plain\", \".jpg\" => \"image/jpeg\", \".png\" => \"image/png\", \"\" => \"application/octet-stream\" )\n#ssl.engine = \"enable\"\n\nssl.pemfile = \"/etc/ssl/owncloud/server.pem\"\n\nserver.modules = (\n\"mod_access\",\n\"mod_fastcgi\",\n\"mod_cgi\"\n)\n\n$HTTP[\"url\"] =~ \"^/owncloud/data/\" {\nurl.access-deny = (\"\")\n}\n$HTTP[\"url\"] =~ \"^/owncloud($|/)\" {\ndir-listing.activate = \"disable\"\n}\n\nfastcgi.server = (\n\".php\" => ((\n\"bin-path\" => \"/usr/bin/php-cgi\",\n\"socket\" => \"/tmp/php.socket\",\n\"max-procs\" => 4\n))\n)\n\n\nYou can test the Lighttpd configuration like this.\n\nlighttpd -t -f /etc/lighttpd/lighttpd.conf\n\n\nPHP\nInstall like this.\n\npacman -S php-cgi\n\n\nThe configuration exists in /etc/php/php.ini. There are a number of settings to\nchange here. Here are the extensions I found was neccessary for Owncloud.\n\nextension=curl.so\nextension=gd.so\nextension=iconv.so\nextension=openssl.so\nextension=pdo_sqlite.so\nextension=sqlite3.so\nextension=zip.so\n\n\nThe document root has to be set.\n\ndoc_root = /srv/http\n\n\nI don't know exactly what this is, but it is needed =)\n\ncgi.fix_pathinfo=1\n\n\nOpenSSL\npacman -S openssl\nmkdir /etc/ssl/owncloud\ncd /etc/ssl/owncloud\nopenssl req -new -x509 -keyout server.pem -out server.pem -days 365 -nodes\nchmod 0600 /etc/ssl/owncloud\n\n\nInstall Owncloud\nInstall and link the application to make it available in webserver. I like this\nsolution better then copying the files. Now it's easier to keep it updated with\nPacman.\n\npacman -S owncloud\nln -s /usr/share/webapps/owncloud /srv/http/owncloud\n\n\nTime to start the webserver!\n\nlighttpd -t -f /etc/lighttpd/lighttpd.conf #This test can save you some time!\nsystemctl restart lighttpd.service\n\n\nNow you can surf into /owncloud and the application should be running. You will\nmost likely get a response similar to this.\nNo database drivers (sqlite, mysql, or postgresql) installed.\nPHP module zip not installed.\n\nPlease ask your server administrator to install the module.\nPHP module GD is not installed.\n\nPlease ask your server administrator to install the module.\nPHP module iconv is not installed.\n\nPlease ask your server administrator to install the module.\n\n\nI installed them one by one, and then restarted Lighttpd to see that they got\ninstalled correctly. Like php-sqlite for example.\n\npacman -Ss sqlite #search for sqlite\npacman -S extra/php-sqlite #install php-sqlite\n\n\nIt may be that they are just not enabled in php.ini  extensions section, and/or\nthat they are not even intalled. Like I had PHP-GD installed but had missed \n;extension=gd.so  in php.ini.\n\nWhen all extensions are in place, you will see two input fields where you input\nadmin user and password. Once entered it will take a very long time to submit\nthe form! I actually gave up and did a restart of Lighttpd. After that it loaded\nfaster.\nIssues\n\nIf you have issues, there are helpful logs.\n\ntail -f /srv/http/owncloud/data/owncloud.log\ntail -f /var/log/lighttpd/error.log\n\n\nFirst issue I had was that the first page got stuck hanging on \"Upgrading\nfilesystem cache\". Looking at the log I found.\n\n2013-07-22 18:28:35: (mod_fastcgi.c.2676) FastCGI-stderr: PHP Fatal error: Call to a member function raiseError() on a non-object in /usr/share/webapps/owncloud/lib/MDB2/Driver/sqlite3.php on line 898\n\n\nThis is very easy to solve, just uncomment\n\n\"extension=pdo_sqlite.so\" in php.ini.\nextension=pdo_sqlite.so\n\n\nSecond problem was admin got stuck. I got a tip that it could be PHP not being\nable to lookup apps.owncloud.com  so I tried this.\n\necho \"<?php echo gethostbyname('apps.owncloud.com'); ?&rt;\" > /srv/http/dns.php\n\n\nAnd the dns.php page also got stuck. I added the entry in /etc/hosts  like this,\nnot nice but it works for now.\n\n188.138.118.86 apps.owncloud.com apps.owncloud.com\n\n\nHowever, the admin page was not accessble, it also hang. In the owncloud.log  I\nsaw.\n\n{\"app\":\"PHP\",\"message\":\"curl_setopt_array(): CURLOPT_FOLLOWLOCATION cannot be activated when an open_basedir is set at \\/usr\\/share\\/webapps\\/owncloud\\/3rdparty\\/Sabre\\/DAV\\/Client.php#462\",\"level\":2,\"time\":814}\n\n\nI fixed that by commenting out open_basedir in php.ini.\n\n;open_basedir = ...\n\n\nThe third thing, that definitly finally did the trick, was max-procs  parameter\nin Lighttpd config. I had it set to 1  and I changed it to 4.\n\nLast I recommend looking at https://forum.owncloud.org/viewtopic.php?f=8&t=10692\n[https://forum.owncloud.org/viewtopic.php?f=8&t=10692]  for performance tips.","feature_image":null,"featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2013-10-19T09:09:54.000Z","created_by":"2","updated_at":"2014-10-04T14:04:45.000Z","updated_by":"1","published_at":"2013-10-19T09:09:54.000Z","published_by":"2","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"custom_template":null},{"id":"597b4433e521cb4fbd918697","uuid":"be4ce0c2-9ae0-489e-a6fd-fb2d6586fa7d","title":"Raspberry PI with Camera Module and ArchLinux","slug":"raspberry-pi-with-camera-module-and-archlinux","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"I reccently bought a Raspberry PI. I am new to ArchLinux so I thought I'd make some notes of the initial setup. This is the hardware used to build the camera:\\n\\n* Raspberry Pi Model B 512MB RAM\\n* Camera Module for Raspberry Pi\\n* WiFi USB Nano\\n* OpenBox Sky Case\\n* 16GB SD\\n\\n##Partitioning SD card\\n\\nI added the ArchLinux image to a 16GB card. The images creates a 2GB parition so you need to either extend it before booting or create a new partition after boot. I choose to create a new partition after boot, and use it for `/home`.\\n```\\nfdisk /dev/disk/by-id/mmc-*\\nn add partition\\nw save and exit\\n```\\n\\n##Create file system.\\n```\\nmkfs.ext4 /dev/mmcblk0p3\\n```\\n\\nRemove everything in `/home`. I am assuming you have nothing important here yet.\\n```\\nrm -rf /home/*\\n```\\n\\nMount the device at boot.\\n```\\n/dev/mmcblk0p3 /home ext4 defaults 0 2\\n```\\n##Package manager\\n\\nI had never heard of Pacman package manager before. But its just as easy. To search for packages do this.\\n```\\npacman -Ss partOfPackageName\\n```\\n\\nTo install a package do this.\\n```\\npacman -S packageName\\n```\\n\\nUpgrade all packages.\\n```\\npacman -Syu\\n```\\n\\nInitiallly I had some problems when installing packages. I got this.\\n```\\n\\\"from mirror.archlinuxarm.org : The requested URL returned error: 404 Not Found\\\"\\n```\\n\\nJust perform a full uppgrade and it should be resolved.\\n##Network setup\\n\\nTo list available devices do.\\n```\\nip link\\n```\\n\\nTo get the wireless network running I installed these.\\n```\\npacman -S wpa_supplicant\\npacman -S wpa_actiond\\npacman -S ifplugd\\npacman -S dhclient\\npacman -S openntpd\\n```\\n\\nThere is a very nice setup wizard, just do this.\\n```\\nwifi-menu -o\\n```\\n\\nNetwork configuration exists in profile files. I had some problems with the DHCP client not setting IP:s after network loss. I added `DHPClient` to the profiles to make it reconnect.\\n```\\n#/etc/netctl/ethernet-dhcp\\nDescription='A basic dhcp ethernet connection'\\nInterface=eth0\\nConnection=ethernet\\nIP=dhcp\\nDHCPClient='dhclient'\\nTimeoutDHCP=30\\nExecUpPost=\\\"ntpd -s &\\\"\\n```\\n\\n```\\n#/etc/netctl/wlan0-tallefjantlinksys\\nDescription='Automatically generated profile by wifi-menu'\\nInterface=wlan0\\nConnection=wireless\\nSecurity=wpa\\nESSID=MYNETWORKNAME\\nIP=dhcp\\nKey=12312312312313123132\\nDHCPClient='dhclient'\\nTimeoutDHCP=30\\nExecUpPost=\\\"ntpd -s &\\\"\\n```\\n\\nTo make WLAN connect when available, and Ethernet connect when plugged, do this.\\n```\\nsystemctl enable netctl-auto@wlan0.service\\nsystemctl enable netctl-ifplugd@eth00.service\\n```\\n\\nTo make WLAN and Ethernet use DHCP at boot, do this.\\n```\\nsystemctl enable dhcpcd@eth0\\nsystemctl enable dhcpcd@wlan0\\n```\\n\\nI noted that the network setup was not working after the first initual upgrade with Pacman. To solve it I just disabled the enabled services and enabled them again.\\n```\\nsystemctl status --failed\\nsystemctl disable FAILEDSERVICE\\n```\\nI had problems with DHCP timeouts so I added the `TimeoutDHCP` parameter and set it to 30. Default is 10 seconds. Also the `ExecUpPost` will set time from NTP when connected.\\n##Time and date\\n\\nIn my case, Sweden.\\n```\\nrm /etc/timezone\\nln -s /usr/share/zoneinfo/Europe/Stockholm /etc/timezone\\n```\\nAlso, the Raspberry Pi has no battery. The time will be 1970 on every reboot. You can use NTP to set the date from a time server on startup.\\n```\\npacman -S openntpd\\n```\\n\\nTo start ntpd when a network interface is connected, add `ExecUpPost` to your interface profile. Here is an example of my eth0.\\n```\\nDescription='A basic dhcp ethernet connection'\\nInterface=eth0\\nConnection=ethernet\\nIP=dhcp\\nExecUpPost=\\\"ntpd -s &\\\"\\nRaspberry Camera\\n```\\n\\n##Camera module software in PATH\\nIn `~/.bashrc` I added.\\n```\\nexport PATH=$PATH:/opt/vc/bin\\n```\\n\\n##Tweak camera memory usage\\nIn `/boot/config.txt` I added.\\n```\\ngpu_mem=128\\nstart_file=start_x.elf\\nfixup_file=fixup_x.dat\\n```\\n\\n##Speed up camera\\nThe camera may seem slow. There is a default delay of 5 seconds before it takes the picture. You can change this with `-t 0`.\\nI've noticed the device hangs when storing larger videos. It's a good idea to record video directly to RAM, that works much better for me. By default `/tmp` is mounted as `tmpfs`.\\n```\\n/opt/vc/bin/raspistill -t 0 -o /tmp/test.png\\n/opt/vc/bin/raspivid -o /tmp/out.h264 -t 5000\\n/opt/vc/bin/raspivid -o /tmp/out.h264 -t 20000\\n/opt/vc/bin/raspivid -o /tmp/out.h264 -t 60000\\n```\"}]],\"sections\":[[10,0]]}","html":"<p>I reccently bought a Raspberry PI. I am new to ArchLinux so I thought I'd make some notes of the initial setup. This is the hardware used to build the camera:</p>\n<ul>\n<li>Raspberry Pi Model B 512MB RAM</li>\n<li>Camera Module for Raspberry Pi</li>\n<li>WiFi USB Nano</li>\n<li>OpenBox Sky Case</li>\n<li>16GB SD</li>\n</ul>\n<h2 id=\"partitioningsdcard\">Partitioning SD card</h2>\n<p>I added the ArchLinux image to a 16GB card. The images creates a 2GB parition so you need to either extend it before booting or create a new partition after boot. I choose to create a new partition after boot, and use it for <code>/home</code>.</p>\n<pre><code>fdisk /dev/disk/by-id/mmc-*\nn add partition\nw save and exit\n</code></pre>\n<h2 id=\"createfilesystem\">Create file system.</h2>\n<pre><code>mkfs.ext4 /dev/mmcblk0p3\n</code></pre>\n<p>Remove everything in <code>/home</code>. I am assuming you have nothing important here yet.</p>\n<pre><code>rm -rf /home/*\n</code></pre>\n<p>Mount the device at boot.</p>\n<pre><code>/dev/mmcblk0p3 /home ext4 defaults 0 2\n</code></pre>\n<h2 id=\"packagemanager\">Package manager</h2>\n<p>I had never heard of Pacman package manager before. But its just as easy. To search for packages do this.</p>\n<pre><code>pacman -Ss partOfPackageName\n</code></pre>\n<p>To install a package do this.</p>\n<pre><code>pacman -S packageName\n</code></pre>\n<p>Upgrade all packages.</p>\n<pre><code>pacman -Syu\n</code></pre>\n<p>Initiallly I had some problems when installing packages. I got this.</p>\n<pre><code>&quot;from mirror.archlinuxarm.org : The requested URL returned error: 404 Not Found&quot;\n</code></pre>\n<p>Just perform a full uppgrade and it should be resolved.</p>\n<h2 id=\"networksetup\">Network setup</h2>\n<p>To list available devices do.</p>\n<pre><code>ip link\n</code></pre>\n<p>To get the wireless network running I installed these.</p>\n<pre><code>pacman -S wpa_supplicant\npacman -S wpa_actiond\npacman -S ifplugd\npacman -S dhclient\npacman -S openntpd\n</code></pre>\n<p>There is a very nice setup wizard, just do this.</p>\n<pre><code>wifi-menu -o\n</code></pre>\n<p>Network configuration exists in profile files. I had some problems with the DHCP client not setting IP:s after network loss. I added <code>DHPClient</code> to the profiles to make it reconnect.</p>\n<pre><code>#/etc/netctl/ethernet-dhcp\nDescription='A basic dhcp ethernet connection'\nInterface=eth0\nConnection=ethernet\nIP=dhcp\nDHCPClient='dhclient'\nTimeoutDHCP=30\nExecUpPost=&quot;ntpd -s &amp;&quot;\n</code></pre>\n<pre><code>#/etc/netctl/wlan0-tallefjantlinksys\nDescription='Automatically generated profile by wifi-menu'\nInterface=wlan0\nConnection=wireless\nSecurity=wpa\nESSID=MYNETWORKNAME\nIP=dhcp\nKey=12312312312313123132\nDHCPClient='dhclient'\nTimeoutDHCP=30\nExecUpPost=&quot;ntpd -s &amp;&quot;\n</code></pre>\n<p>To make WLAN connect when available, and Ethernet connect when plugged, do this.</p>\n<pre><code>systemctl enable netctl-auto@wlan0.service\nsystemctl enable netctl-ifplugd@eth00.service\n</code></pre>\n<p>To make WLAN and Ethernet use DHCP at boot, do this.</p>\n<pre><code>systemctl enable dhcpcd@eth0\nsystemctl enable dhcpcd@wlan0\n</code></pre>\n<p>I noted that the network setup was not working after the first initual upgrade with Pacman. To solve it I just disabled the enabled services and enabled them again.</p>\n<pre><code>systemctl status --failed\nsystemctl disable FAILEDSERVICE\n</code></pre>\n<p>I had problems with DHCP timeouts so I added the <code>TimeoutDHCP</code> parameter and set it to 30. Default is 10 seconds. Also the <code>ExecUpPost</code> will set time from NTP when connected.</p>\n<h2 id=\"timeanddate\">Time and date</h2>\n<p>In my case, Sweden.</p>\n<pre><code>rm /etc/timezone\nln -s /usr/share/zoneinfo/Europe/Stockholm /etc/timezone\n</code></pre>\n<p>Also, the Raspberry Pi has no battery. The time will be 1970 on every reboot. You can use NTP to set the date from a time server on startup.</p>\n<pre><code>pacman -S openntpd\n</code></pre>\n<p>To start ntpd when a network interface is connected, add <code>ExecUpPost</code> to your interface profile. Here is an example of my eth0.</p>\n<pre><code>Description='A basic dhcp ethernet connection'\nInterface=eth0\nConnection=ethernet\nIP=dhcp\nExecUpPost=&quot;ntpd -s &amp;&quot;\nRaspberry Camera\n</code></pre>\n<h2 id=\"cameramodulesoftwareinpath\">Camera module software in PATH</h2>\n<p>In <code>~/.bashrc</code> I added.</p>\n<pre><code>export PATH=$PATH:/opt/vc/bin\n</code></pre>\n<h2 id=\"tweakcameramemoryusage\">Tweak camera memory usage</h2>\n<p>In <code>/boot/config.txt</code> I added.</p>\n<pre><code>gpu_mem=128\nstart_file=start_x.elf\nfixup_file=fixup_x.dat\n</code></pre>\n<h2 id=\"speedupcamera\">Speed up camera</h2>\n<p>The camera may seem slow. There is a default delay of 5 seconds before it takes the picture. You can change this with <code>-t 0</code>.<br>\nI've noticed the device hangs when storing larger videos. It's a good idea to record video directly to RAM, that works much better for me. By default <code>/tmp</code> is mounted as <code>tmpfs</code>.</p>\n<pre><code>/opt/vc/bin/raspistill -t 0 -o /tmp/test.png\n/opt/vc/bin/raspivid -o /tmp/out.h264 -t 5000\n/opt/vc/bin/raspivid -o /tmp/out.h264 -t 20000\n/opt/vc/bin/raspivid -o /tmp/out.h264 -t 60000\n</code></pre>\n","comment_id":"10","plaintext":"I reccently bought a Raspberry PI. I am new to ArchLinux so I thought I'd make\nsome notes of the initial setup. This is the hardware used to build the camera:\n\n * Raspberry Pi Model B 512MB RAM\n * Camera Module for Raspberry Pi\n * WiFi USB Nano\n * OpenBox Sky Case\n * 16GB SD\n\nPartitioning SD card\nI added the ArchLinux image to a 16GB card. The images creates a 2GB parition so\nyou need to either extend it before booting or create a new partition after\nboot. I choose to create a new partition after boot, and use it for /home.\n\nfdisk /dev/disk/by-id/mmc-*\nn add partition\nw save and exit\n\n\nCreate file system.\nmkfs.ext4 /dev/mmcblk0p3\n\n\nRemove everything in /home. I am assuming you have nothing important here yet.\n\nrm -rf /home/*\n\n\nMount the device at boot.\n\n/dev/mmcblk0p3 /home ext4 defaults 0 2\n\n\nPackage manager\nI had never heard of Pacman package manager before. But its just as easy. To\nsearch for packages do this.\n\npacman -Ss partOfPackageName\n\n\nTo install a package do this.\n\npacman -S packageName\n\n\nUpgrade all packages.\n\npacman -Syu\n\n\nInitiallly I had some problems when installing packages. I got this.\n\n\"from mirror.archlinuxarm.org : The requested URL returned error: 404 Not Found\"\n\n\nJust perform a full uppgrade and it should be resolved.\n\nNetwork setup\nTo list available devices do.\n\nip link\n\n\nTo get the wireless network running I installed these.\n\npacman -S wpa_supplicant\npacman -S wpa_actiond\npacman -S ifplugd\npacman -S dhclient\npacman -S openntpd\n\n\nThere is a very nice setup wizard, just do this.\n\nwifi-menu -o\n\n\nNetwork configuration exists in profile files. I had some problems with the DHCP\nclient not setting IP:s after network loss. I added DHPClient  to the profiles\nto make it reconnect.\n\n#/etc/netctl/ethernet-dhcp\nDescription='A basic dhcp ethernet connection'\nInterface=eth0\nConnection=ethernet\nIP=dhcp\nDHCPClient='dhclient'\nTimeoutDHCP=30\nExecUpPost=\"ntpd -s &\"\n\n\n#/etc/netctl/wlan0-tallefjantlinksys\nDescription='Automatically generated profile by wifi-menu'\nInterface=wlan0\nConnection=wireless\nSecurity=wpa\nESSID=MYNETWORKNAME\nIP=dhcp\nKey=12312312312313123132\nDHCPClient='dhclient'\nTimeoutDHCP=30\nExecUpPost=\"ntpd -s &\"\n\n\nTo make WLAN connect when available, and Ethernet connect when plugged, do this.\n\nsystemctl enable netctl-auto@wlan0.service\nsystemctl enable netctl-ifplugd@eth00.service\n\n\nTo make WLAN and Ethernet use DHCP at boot, do this.\n\nsystemctl enable dhcpcd@eth0\nsystemctl enable dhcpcd@wlan0\n\n\nI noted that the network setup was not working after the first initual upgrade\nwith Pacman. To solve it I just disabled the enabled services and enabled them\nagain.\n\nsystemctl status --failed\nsystemctl disable FAILEDSERVICE\n\n\nI had problems with DHCP timeouts so I added the TimeoutDHCP  parameter and set\nit to 30. Default is 10 seconds. Also the ExecUpPost  will set time from NTP\nwhen connected.\n\nTime and date\nIn my case, Sweden.\n\nrm /etc/timezone\nln -s /usr/share/zoneinfo/Europe/Stockholm /etc/timezone\n\n\nAlso, the Raspberry Pi has no battery. The time will be 1970 on every reboot.\nYou can use NTP to set the date from a time server on startup.\n\npacman -S openntpd\n\n\nTo start ntpd when a network interface is connected, add ExecUpPost  to your\ninterface profile. Here is an example of my eth0.\n\nDescription='A basic dhcp ethernet connection'\nInterface=eth0\nConnection=ethernet\nIP=dhcp\nExecUpPost=\"ntpd -s &\"\nRaspberry Camera\n\n\nCamera module software in PATH\nIn ~/.bashrc  I added.\n\nexport PATH=$PATH:/opt/vc/bin\n\n\nTweak camera memory usage\nIn /boot/config.txt  I added.\n\ngpu_mem=128\nstart_file=start_x.elf\nfixup_file=fixup_x.dat\n\n\nSpeed up camera\nThe camera may seem slow. There is a default delay of 5 seconds before it takes\nthe picture. You can change this with -t 0.\nI've noticed the device hangs when storing larger videos. It's a good idea to\nrecord video directly to RAM, that works much better for me. By default /tmp  is\nmounted as tmpfs.\n\n/opt/vc/bin/raspistill -t 0 -o /tmp/test.png\n/opt/vc/bin/raspivid -o /tmp/out.h264 -t 5000\n/opt/vc/bin/raspivid -o /tmp/out.h264 -t 20000\n/opt/vc/bin/raspivid -o /tmp/out.h264 -t 60000","feature_image":null,"featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2013-10-19T09:14:09.000Z","created_by":"2","updated_at":"2014-10-04T14:04:18.000Z","updated_by":"1","published_at":"2013-10-19T09:14:09.000Z","published_by":"2","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"custom_template":null},{"id":"597b4433e521cb4fbd918698","uuid":"9967d65f-d8fd-403e-82b2-c564aabfc6c3","title":"Raspberry Surveillance","slug":"raspberry-surveillance","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"I reccently bought a Raspberry PI. The main reason was that I had an idea of making some video surveillance software. I have made 2 previous blog posts regarding the Raspberry Pi and both of them are sort of related this one. One where I wrote some notes on the initial setup of the hardware and basic software. One where I wrote about how to setup Owncloud. This post is about https://github.com/tomasbjerre/RaspberrySurveillance. It is project where I've developed, mainly, a [web interface](http://files.bjurr.se/blog/rbs.png) that can:\\n\\n* Show snapshot of camera\\n* Setup motion triggering\\n* Start and stop motion triggering\\n* Save captured videos to disk\\n* Save captured videos to Webdav (Supported by Owncloud)\\n\\nThis means you can start and stop motion triggering from a web interface. Whenever a video is captured you can have it uploaded to Owncloud and have it automatically synced to you Windows PC.\\n\\nWhen camera triggers it will store pictures and/or vieos, it is configurable. Here is a very small example of a captured event.\\n\\n* [Picture that detected change](http://files.bjurr.se/blog/00003-image.jpg)\\n* [Video recorded on trigger](http://files.bjurr.se/blog/00003-2013-08-06_10-03-30-video.h264)\\n* [Picture showing what was changed in picture](http://files.bjurr.se/blog/00003-image-diff.jpg)\\n\"}]],\"sections\":[[10,0]]}","html":"<p>I reccently bought a Raspberry PI. The main reason was that I had an idea of making some video surveillance software. I have made 2 previous blog posts regarding the Raspberry Pi and both of them are sort of related this one. One where I wrote some notes on the initial setup of the hardware and basic software. One where I wrote about how to setup Owncloud. This post is about <a href=\"https://github.com/tomasbjerre/RaspberrySurveillance\">https://github.com/tomasbjerre/RaspberrySurveillance</a>. It is project where I've developed, mainly, a <a href=\"http://files.bjurr.se/blog/rbs.png\">web interface</a> that can:</p>\n<ul>\n<li>Show snapshot of camera</li>\n<li>Setup motion triggering</li>\n<li>Start and stop motion triggering</li>\n<li>Save captured videos to disk</li>\n<li>Save captured videos to Webdav (Supported by Owncloud)</li>\n</ul>\n<p>This means you can start and stop motion triggering from a web interface. Whenever a video is captured you can have it uploaded to Owncloud and have it automatically synced to you Windows PC.</p>\n<p>When camera triggers it will store pictures and/or vieos, it is configurable. Here is a very small example of a captured event.</p>\n<ul>\n<li><a href=\"http://files.bjurr.se/blog/00003-image.jpg\">Picture that detected change</a></li>\n<li><a href=\"http://files.bjurr.se/blog/00003-2013-08-06_10-03-30-video.h264\">Video recorded on trigger</a></li>\n<li><a href=\"http://files.bjurr.se/blog/00003-image-diff.jpg\">Picture showing what was changed in picture</a></li>\n</ul>\n","comment_id":"11","plaintext":"I reccently bought a Raspberry PI. The main reason was that I had an idea of\nmaking some video surveillance software. I have made 2 previous blog posts\nregarding the Raspberry Pi and both of them are sort of related this one. One\nwhere I wrote some notes on the initial setup of the hardware and basic\nsoftware. One where I wrote about how to setup Owncloud. This post is about \nhttps://github.com/tomasbjerre/RaspberrySurveillance. It is project where I've\ndeveloped, mainly, a web interface [http://files.bjurr.se/blog/rbs.png]  that\ncan:\n\n * Show snapshot of camera\n * Setup motion triggering\n * Start and stop motion triggering\n * Save captured videos to disk\n * Save captured videos to Webdav (Supported by Owncloud)\n\nThis means you can start and stop motion triggering from a web interface.\nWhenever a video is captured you can have it uploaded to Owncloud and have it\nautomatically synced to you Windows PC.\n\nWhen camera triggers it will store pictures and/or vieos, it is configurable.\nHere is a very small example of a captured event.\n\n * Picture that detected change [http://files.bjurr.se/blog/00003-image.jpg]\n * Video recorded on trigger\n   [http://files.bjurr.se/blog/00003-2013-08-06_10-03-30-video.h264]\n * Picture showing what was changed in picture\n   [http://files.bjurr.se/blog/00003-image-diff.jpg]","feature_image":null,"featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2013-10-19T09:15:05.000Z","created_by":"2","updated_at":"2014-10-04T14:03:54.000Z","updated_by":"1","published_at":"2013-10-19T09:15:09.000Z","published_by":"2","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"custom_template":null},{"id":"597b4433e521cb4fbd918699","uuid":"5420692e-0deb-47ce-ad83-c1d7c168b1c4","title":"Dummy camera made smart with Raspberry Pi","slug":"dummy-camera-made-smart-with-raspberry-pi","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"I'd like to share how I build my camera using Raspberry Pi. I used a dummy camera and turned into a smart camera! The total cost is about 100 / 1000 SEK / $150 =)\\n\\nI have also developed software to help use the Raspberry Camera for surveillance. Check out these blog posts for further information.\\n\\n* [Raspberry Surveillance](/raspberry-surveillance)\\n* [Raspberry PI with Camera Module and ArchLinux](/raspberry-pi-with-camera-module-and-archlinux)\\n* [Owncloud 5 Server with Lighttpd, Sqlite on ArchLinux](/owncloud-5-server-with-lighttpd-sqlite-on-archlinux)\\n\\n##Camera\\n\\nI found these parts on Amazon.co.uk.\\n\\n* Raspberry PI Starter Kit - Power, SD-card, Raspberry 512MB\\n* USB Wifi Adapter\\n* Byron - CS11D Dummy CCTV Camera Unit\\n\"}]],\"sections\":[[10,0]]}","html":"<p>I'd like to share how I build my camera using Raspberry Pi. I used a dummy camera and turned into a smart camera! The total cost is about 100 / 1000 SEK / $150 =)</p>\n<p>I have also developed software to help use the Raspberry Camera for surveillance. Check out these blog posts for further information.</p>\n<ul>\n<li><a href=\"/raspberry-surveillance\">Raspberry Surveillance</a></li>\n<li><a href=\"/raspberry-pi-with-camera-module-and-archlinux\">Raspberry PI with Camera Module and ArchLinux</a></li>\n<li><a href=\"/owncloud-5-server-with-lighttpd-sqlite-on-archlinux\">Owncloud 5 Server with Lighttpd, Sqlite on ArchLinux</a></li>\n</ul>\n<h2 id=\"camera\">Camera</h2>\n<p>I found these parts on Amazon.co.uk.</p>\n<ul>\n<li>Raspberry PI Starter Kit - Power, SD-card, Raspberry 512MB</li>\n<li>USB Wifi Adapter</li>\n<li>Byron - CS11D Dummy CCTV Camera Unit</li>\n</ul>\n","comment_id":"12","plaintext":"I'd like to share how I build my camera using Raspberry Pi. I used a dummy\ncamera and turned into a smart camera! The total cost is about 100 / 1000 SEK /\n$150 =)\n\nI have also developed software to help use the Raspberry Camera for\nsurveillance. Check out these blog posts for further information.\n\n * Raspberry Surveillance [/raspberry-surveillance]\n * Raspberry PI with Camera Module and ArchLinux\n   [/raspberry-pi-with-camera-module-and-archlinux]\n * Owncloud 5 Server with Lighttpd, Sqlite on ArchLinux\n   [/owncloud-5-server-with-lighttpd-sqlite-on-archlinux]\n\nCamera\nI found these parts on Amazon.co.uk.\n\n * Raspberry PI Starter Kit - Power, SD-card, Raspberry 512MB\n * USB Wifi Adapter\n * Byron - CS11D Dummy CCTV Camera Unit","feature_image":null,"featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2013-10-19T09:15:39.000Z","created_by":"2","updated_at":"2014-10-05T20:09:01.000Z","updated_by":"1","published_at":"2013-10-19T09:15:39.000Z","published_by":"2","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"custom_template":null},{"id":"597b4433e521cb4fbd91869b","uuid":"9366cb09-05cb-4207-806a-f0651b83dde1","title":"FindFilm.se -  Netflix from A to Z, and more =)","slug":"findfilm-se-netflix-from-a-to-z-and-more","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"I grew tired of the way Netflix is categorizing movies. I wanted to browse them alphabetically. I also wanted to find the movies that were recently added to Netflix. So I created [Findfilm.se](http://findfilm.se/), it has these features and it also includes movies from HeadWeb and ViaPlay. Enjoy =) And by the way: det r bara p Svenska =)\"}]],\"sections\":[[10,0]]}","html":"<p>I grew tired of the way Netflix is categorizing movies. I wanted to browse them alphabetically. I also wanted to find the movies that were recently added to Netflix. So I created <a href=\"http://findfilm.se/\">Findfilm.se</a>, it has these features and it also includes movies from HeadWeb and ViaPlay. Enjoy =) And by the way: det r bara p Svenska =)</p>\n","comment_id":"14","plaintext":"I grew tired of the way Netflix is categorizing movies. I wanted to browse them\nalphabetically. I also wanted to find the movies that were recently added to\nNetflix. So I created Findfilm.se [http://findfilm.se/], it has these features\nand it also includes movies from HeadWeb and ViaPlay. Enjoy =) And by the way:\ndet r bara p Svenska =)","feature_image":null,"featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2014-10-04T13:38:48.000Z","created_by":"2","updated_at":"2014-10-05T23:58:28.000Z","updated_by":"1","published_at":"2014-10-04T13:38:48.000Z","published_by":"2","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"custom_template":null},{"id":"597b4433e521cb4fbd91869c","uuid":"e6587c5b-340f-4f25-b7d5-335ecf507e55","title":"Nu Validator offline implementation","slug":"nu-validator-offline-implementation","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"I struggled alot before I got this working. In my case I want to validate a webpage, as HTML5, using a Jenkins job. I dont want to have to deploy anything to do the validation, just use a library and do it all offline.\\n\\nI found [Nu Validator](https://validator.nu/) which seems to be working great. Started looking for its implementation, its Java, great! =)\\n\\nStarted looking into the code, trying to figure out how to use it... It is very unclear and after some googling I found out that I'm definitly not alone with that opinion.\\n\\nI came up with a great solution that I'd like to share.\\n\\nThere is a WAR in the release. It contains an API. Basically I am using Jetty to start a tiny webserver, deploying the WAR in it, invoking the API and stopping the server.\\n\\nCheck it out at [GitHub](https://github.com/tomasbjerre/validatortest)!\"}]],\"sections\":[[10,0]]}","html":"<p>I struggled alot before I got this working. In my case I want to validate a webpage, as HTML5, using a Jenkins job. I dont want to have to deploy anything to do the validation, just use a library and do it all offline.</p>\n<p>I found <a href=\"https://validator.nu/\">Nu Validator</a> which seems to be working great. Started looking for its implementation, its Java, great! =)</p>\n<p>Started looking into the code, trying to figure out how to use it... It is very unclear and after some googling I found out that I'm definitly not alone with that opinion.</p>\n<p>I came up with a great solution that I'd like to share.</p>\n<p>There is a WAR in the release. It contains an API. Basically I am using Jetty to start a tiny webserver, deploying the WAR in it, invoking the API and stopping the server.</p>\n<p>Check it out at <a href=\"https://github.com/tomasbjerre/validatortest\">GitHub</a>!</p>\n","comment_id":"15","plaintext":"I struggled alot before I got this working. In my case I want to validate a\nwebpage, as HTML5, using a Jenkins job. I dont want to have to deploy anything\nto do the validation, just use a library and do it all offline.\n\nI found Nu Validator [https://validator.nu/]  which seems to be working great.\nStarted looking for its implementation, its Java, great! =)\n\nStarted looking into the code, trying to figure out how to use it... It is very\nunclear and after some googling I found out that I'm definitly not alone with\nthat opinion.\n\nI came up with a great solution that I'd like to share.\n\nThere is a WAR in the release. It contains an API. Basically I am using Jetty to\nstart a tiny webserver, deploying the WAR in it, invoking the API and stopping\nthe server.\n\nCheck it out at GitHub [https://github.com/tomasbjerre/validatortest]!","feature_image":null,"featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2014-11-20T22:48:30.000Z","created_by":"1","updated_at":"2014-11-22T07:31:46.000Z","updated_by":"1","published_at":"2014-11-20T22:48:30.000Z","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"custom_template":null},{"id":"597b4433e521cb4fbd91869e","uuid":"1086957f-b0ba-40eb-bac3-978cec5a4923","title":"Building Atlassian Stash pull requests in Jenkins","slug":"building-atlassian-stash-pull-requests-in-jenkins","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"Update 160912: There is a [new post here](http://bjurr.com/continuous-integration-with-bitbucket-server-and-jenkins/).\\n\\nWe are just about to introduce pull requests at my current position. We are using Git with Atlassian Stash and Jenkins. We want to verify that the pull requests:\\n\\n* Compile\\n* Does not break any test cases\\n* Can be merged to target branch\\n* Compiles after merge\\n* Does not break test cases after merge\\n\\nAfter some Googling around the issue I found no solution, so I tought I'd make a post about how I solved it.\\n\\n# Verifying source of the pull request\\nThere is a really nice plugin for Jenkins [Stash Notifier Plugin](https://wiki.jenkins-ci.org/display/JENKINS/StashNotifier+Plugin) that can be used to notify Stash of the status of a build. Enable it on any Jenkins job that builds the branch you are merging from. It will add an icon and a link to Jenkins in the pull request view of Stash.\\n\\n# Discovering new pull requests\\nI initially solved this with a Jenkins job that is polling Stash for new pull requests. But polling is never good so I created a Stash plugin that will notify Jenkins about new pull requests.\\n\\n## Pull Request Notifier Plugin for Stash\\nThe plugin is available in [Atlassian Marketplace](https://marketplace.atlassian.com/plugins/se.bjurr.prnfs.pull-request-notifier-for-stash) and at [GitHub](https://github.com/tomasbjerre/pull-request-notifier-for-stash). When installed, you will have this configuration GUI.\\n\\n![pull-request-notifier-for-stash](/content/images/2015/04/variables.png)\\n\\nThe features include:\\n\\n* Trigger on one, or several, event(s) regarding pull requests.\\n* Invoke one, or several, URL(s) when event(s) are triggered.\\n * Optionally with *basic authentication* headers.\\n * Completely custom URL supporting variable parameters\\n     * ${PULL\\\\_REQUEST\\\\_ID} Example: 1\\n     * ${PULL\\\\_REQUEST\\\\_ACTION} Example: OPENED\\n     * ${PULL\\\\_REQUEST\\\\_AUTHOR\\\\_DISPLAY\\\\_NAME} Example: Administrator\\n     * ${PULL\\\\_REQUEST\\\\_AUTHOR\\\\_EMAIL} Example: admin@example.com\\n     * ${PULL\\\\_REQUEST\\\\_AUTHOR\\\\_ID} Example: 1\\n     * ${PULL\\\\_REQUEST\\\\_AUTHOR\\\\_NAME} Example: admin\\n     * ${PULL\\\\_REQUEST\\\\_AUTHOR\\\\_SLUG} Example: admin\\n     * ${PULL\\\\_REQUEST\\\\_FROM\\\\_HASH} Example: 6053a1eaa1c009dd11092d09a72f3c41af1b59ad\\n     * ${PULL\\\\_REQUEST\\\\_FROM\\\\_ID} Example: refs/heads/branch_mod_merge\\n     * ${PULL\\\\_REQUEST\\\\_FROM\\\\_REPO\\\\_ID} Example: 1\\n     * ${PULL\\\\_REQUEST\\\\_FROM\\\\_REPO\\\\_NAME} Example: rep\\\\_1\\n     * ${PULL\\\\_REQUEST\\\\_FROM\\\\_REPO\\\\_PROJECT\\\\_ID} Example: 1\\n     * ${PULL\\\\_REQUEST\\\\_FROM\\\\_REPO\\\\_PROJECT\\\\_KEY} Example: PROJECT\\\\_1\\n     * ${PULL\\\\_REQUEST\\\\_FROM\\\\_REPO\\\\_SLUG} Example: rep\\\\_1\\n     * And same variables for TO, like: ${PULL\\\\_REQUEST\\\\_TO\\\\_HASH}\\n\\nYou can have several notifications and have them trigger different URL:s. If you trigger Jenkins builds, you may want each repo to have its own build job in Jenkins. The filtering functionality is highly configurable. Create a string with the variables and then a regexp that should match that string.\\n![pull-request-notifier-for-stash-filter](/content/images/2015/04/filter_branch_crop.png)\\n\\n## Polling Jenkins with Groovy script\\nNote that you should only do it this way if you cannot use the plugin described above! For example, uou may not have enaugh access to Stash to install plugins.\\n\\nStash has really nice [REST API:s](https://developer.atlassian.com/static/rest/stash/3.6.1/stash-rest.html). I created a scheduled job in Jenkins that runs every 5 minutes. I implemented it in Groovy using the [Groovy plugin](https://wiki.jenkins-ci.org/display/JENKINS/Groovy+plugin).\\n\\n* Find all repos: http://stash/rest/api/1.0/projects/PROJECTS/repos/\\n* Find all pull requests in a repo: http://stash/rest/api/1.0/projects/PROJECTS/repos/\\\"+repo.slug+\\\"/pull-requests?base&details&filterText&orderBy\\n\\n```\\nString summary = \\\"\\\"\\nint newPullRequests = 0;\\nFile previousPullRequests = new File(\\\"/ci/lib/jenkins/workspace/Pull Request Poller/previousPullRequests.txt\\\")\\n\\nString getJson(String addr) {\\n manager.listener.logger.println(\\\"Getting URL: \\\"+addr)\\n def authString = \\\"user:pass\\\".getBytes().encodeBase64().toString()\\n java.net.URLConnection conn = addr.toURL().openConnection()\\n conn.setRequestProperty( \\\"Authorization\\\", \\\"Basic ${authString}\\\" )\\n conn.connect()\\n def reader = new BufferedReader(new InputStreamReader(conn.getInputStream()))\\n def stringBuilder = new StringBuilder()\\n String line = null\\n while ((line = reader.readLine()) != null) {\\n  stringBuilder.append(line + \\\"\\\\n\\\")\\n }\\n String json = groovy.json.JsonOutput.prettyPrint(stringBuilder.toString())\\n manager.listener.logger.println(\\\"Got response:\\\\n\\\"+json)\\n return json\\n}\\n\\nnew groovy.json.JsonSlurper().parseText(getJson(\\\"http://stash/rest/api/1.0/projects/PROJECTS/repos/\\\")).values.each { repo ->\\n manager.listener.logger.println(\\\"Repo: \\\"+repo.slug)\\n\\n String prettyJSON = getJson(\\\"http://stash/rest/api/1.0/projects/PROJECTS/repos/\\\"+repo.slug+\\\"/pull-requests?base&details&filterText&orderBy\\\")\\n def jsonData = new groovy.json.JsonSlurper().parseText(prettyJSON);\\n jsonData.values.each { value ->\\n  String title = value.title\\n  String from = value.fromRef.latestChangeset\\n  String fromRepo = value.fromRef.repository.links.clone.find { it.name == \\\"ssh\\\" }.href\\n  String to = value.toRef.latestChangeset\\n  String toRepo = value.toRef.repository.links.clone.find { it.name == \\\"ssh\\\" }.href\\n  String repositorySlug = repo.slug\\n  String pullRequestId = value.id\\n  String requestUrl =  \\\"http://stash/projects/PROJECTS/repos/\\\"+repositorySlug+\\\"/pull-requests/\\\"+pullRequestId+\\\"/overview\\\"\\n\\n  //Remember that this request has been triggered, and avoid triggering it again\\n  String identifier = from+\\\" \\\"+to\\n  if (previousPullRequests.text.contains(identifier)) {\\n   manager.listener.logger.println(\\\"Ignoring: \\\"+identifier)\\n   return;\\n  }\\n  previousPullRequests.append(identifier+\\\"\\\\n\\\")\\n\\n  //Trigger a jenkins job that will verify the pull request\\n  String invokeBuildUrl = \\\"http://jenkins/job/Pull%20Request%20Builder/buildWithParameters?token=SECRET_CONFIGURED_IN_BUILD&FROM=\\\"+from+\\\"&TO=\\\"+to+\\\"&FROMREPO=\\\"+fromRepo+\\\"&TOREPO=\\\"+toRepo+\\\"&REPOSITORY_SLUG=\\\"+repositorySlug+\\\"&PULL_REQUEST_ID=\\\"+pullRequestId\\n  manager.listener.logger.println(invokeBuildUrl)\\n  new URL(invokeBuildUrl).getText()\\n\\n  summary += \\\"<h1>\\\"+title+\\\"</h1><br><a href='\\\"+requestUrl+\\\"'>\\\"+requestUrl+\\\"</a><br>From: \\\"+jsonData.values[0].fromRef.id+\\\" (\\\"+from+\\\") in \\\"+fromRepo+\\\"<br>To: \\\"+jsonData.values[0].toRef.id+\\\" (\\\"+to+\\\") in \\\"+toRepo+\\\"<br><a href='\\\"+invokeBuildUrl+\\\"'>\\\"+invokeBuildUrl+\\\"</a><hr>\\\"\\n  newPullRequests++;\\n }\\n}\\n\\n//Add some info to the build\\nif (newPullRequests == 0) {\\n manager.createSummary(\\\"gear2.gif\\\").appendText(\\\"<h1>No new pull requests found!</h1>\\\" , false)\\n} else {\\n manager.addShortText(\\\"+\\\"+newPullRequests, \\\"grey\\\", \\\"white\\\", \\\"0px\\\", \\\"white\\\")\\n manager.createSummary(\\\"gear2.gif\\\").appendText(summary , false)\\n}\\n```\\n\\n# Merging and building the pull request\\nI created a parameterized job to merge the pull request from source branch to target branch. It takes *FROM_HASH*, *FROM_REPO*, *TO_HASH*, *TO_REPO*, *REPOSITORY_SLUG* and *PULL_REQUEST_ID* as parameters.\\n\\nThe job has a build step *execute shell* that does the actual verification.\\n\\n```\\ngit clone $TO_REPO\\ncd *\\ngit reset --hard $TO_HASH\\ngit status\\ngit remote add from $FROM_REPO\\ngit fetch from\\ngit merge $FROM_HASH\\ngit --no-pager log --max-count=10 --graph --abbrev-commit\\n\\n#compile command here ...\\n```\\n\\nThe job uses the [Stash Notifier Plugin](https://wiki.jenkins-ci.org/display/JENKINS/StashNotifier+Plugin) to record result in the pull request in Stash. Use the ${FROM_HASH} variable to get the build status reported correctly in the pull request in Stash.\\n\\nIt adds a comment to the pull request, like this.\\n\\n```\\ncurl -D- -u user:pass -X POST -H \\\"Content-Type: application/json\\\"  --data \\\"{ \\\\\\\"text\\\\\\\": \\\\\\\"Looking good :) http://jenkins/job/Pull%20Request%20Builder/${BUILD_NUMBER}/\\\\\\\" }\\\" http://stash/rest/api/1.0/projects/PROJECT/repos/$REPOSITORY_SLUG/pull-requests/$PULL_REQUEST_ID/comments\\n```\\n\\n# Static code analyzers\\nIf you are using static code analyzers you may want to have a look at [Jenkins Violation Comments to Stash Plugin](https://github.com/jenkinsci/jenkins-violation-comments-to-stash-plugin) for Jenkins.\\n\\nIt is configured like this.\\n\\n![alt](/content/images/2015/05/screenshot-config.png)\\n\\nAnd will comment the pull requests like this.\\n\\n![alt](/content/images/2015/05/screenshot-stash.png)\\n\"}]],\"sections\":[[10,0]]}","html":"<p>Update 160912: There is a <a href=\"http://bjurr.com/continuous-integration-with-bitbucket-server-and-jenkins/\">new post here</a>.</p>\n<p>We are just about to introduce pull requests at my current position. We are using Git with Atlassian Stash and Jenkins. We want to verify that the pull requests:</p>\n<ul>\n<li>Compile</li>\n<li>Does not break any test cases</li>\n<li>Can be merged to target branch</li>\n<li>Compiles after merge</li>\n<li>Does not break test cases after merge</li>\n</ul>\n<p>After some Googling around the issue I found no solution, so I tought I'd make a post about how I solved it.</p>\n<h1 id=\"verifyingsourceofthepullrequest\">Verifying source of the pull request</h1>\n<p>There is a really nice plugin for Jenkins <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/StashNotifier+Plugin\">Stash Notifier Plugin</a> that can be used to notify Stash of the status of a build. Enable it on any Jenkins job that builds the branch you are merging from. It will add an icon and a link to Jenkins in the pull request view of Stash.</p>\n<h1 id=\"discoveringnewpullrequests\">Discovering new pull requests</h1>\n<p>I initially solved this with a Jenkins job that is polling Stash for new pull requests. But polling is never good so I created a Stash plugin that will notify Jenkins about new pull requests.</p>\n<h2 id=\"pullrequestnotifierpluginforstash\">Pull Request Notifier Plugin for Stash</h2>\n<p>The plugin is available in <a href=\"https://marketplace.atlassian.com/plugins/se.bjurr.prnfs.pull-request-notifier-for-stash\">Atlassian Marketplace</a> and at <a href=\"https://github.com/tomasbjerre/pull-request-notifier-for-stash\">GitHub</a>. When installed, you will have this configuration GUI.</p>\n<p><img src=\"/content/images/2015/04/variables.png\" alt=\"pull-request-notifier-for-stash\"></p>\n<p>The features include:</p>\n<ul>\n<li>Trigger on one, or several, event(s) regarding pull requests.</li>\n<li>Invoke one, or several, URL(s) when event(s) are triggered.</li>\n<li>Optionally with <em>basic authentication</em> headers.</li>\n<li>Completely custom URL supporting variable parameters\n<ul>\n<li>${PULL_REQUEST_ID} Example: 1</li>\n<li>${PULL_REQUEST_ACTION} Example: OPENED</li>\n<li>${PULL_REQUEST_AUTHOR_DISPLAY_NAME} Example: Administrator</li>\n<li>${PULL_REQUEST_AUTHOR_EMAIL} Example: <a href=\"mailto:admin@example.com\">admin@example.com</a></li>\n<li>${PULL_REQUEST_AUTHOR_ID} Example: 1</li>\n<li>${PULL_REQUEST_AUTHOR_NAME} Example: admin</li>\n<li>${PULL_REQUEST_AUTHOR_SLUG} Example: admin</li>\n<li>${PULL_REQUEST_FROM_HASH} Example: 6053a1eaa1c009dd11092d09a72f3c41af1b59ad</li>\n<li>${PULL_REQUEST_FROM_ID} Example: refs/heads/branch_mod_merge</li>\n<li>${PULL_REQUEST_FROM_REPO_ID} Example: 1</li>\n<li>${PULL_REQUEST_FROM_REPO_NAME} Example: rep_1</li>\n<li>${PULL_REQUEST_FROM_REPO_PROJECT_ID} Example: 1</li>\n<li>${PULL_REQUEST_FROM_REPO_PROJECT_KEY} Example: PROJECT_1</li>\n<li>${PULL_REQUEST_FROM_REPO_SLUG} Example: rep_1</li>\n<li>And same variables for TO, like: ${PULL_REQUEST_TO_HASH}</li>\n</ul>\n</li>\n</ul>\n<p>You can have several notifications and have them trigger different URL:s. If you trigger Jenkins builds, you may want each repo to have its own build job in Jenkins. The filtering functionality is highly configurable. Create a string with the variables and then a regexp that should match that string.<br>\n<img src=\"/content/images/2015/04/filter_branch_crop.png\" alt=\"pull-request-notifier-for-stash-filter\"></p>\n<h2 id=\"pollingjenkinswithgroovyscript\">Polling Jenkins with Groovy script</h2>\n<p>Note that you should only do it this way if you cannot use the plugin described above! For example, uou may not have enaugh access to Stash to install plugins.</p>\n<p>Stash has really nice <a href=\"https://developer.atlassian.com/static/rest/stash/3.6.1/stash-rest.html\">REST API:s</a>. I created a scheduled job in Jenkins that runs every 5 minutes. I implemented it in Groovy using the <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/Groovy+plugin\">Groovy plugin</a>.</p>\n<ul>\n<li>Find all repos: <a href=\"http://stash/rest/api/1.0/projects/PROJECTS/repos/\">http://stash/rest/api/1.0/projects/PROJECTS/repos/</a></li>\n<li>Find all pull requests in a repo: <a href=\"http://stash/rest/api/1.0/projects/PROJECTS/repos/%22+repo.slug+%22/pull-requests?base&amp;details&amp;filterText&amp;orderBy\">http://stash/rest/api/1.0/projects/PROJECTS/repos/&quot;+repo.slug+&quot;/pull-requests?base&amp;details&amp;filterText&amp;orderBy</a></li>\n</ul>\n<pre><code>String summary = &quot;&quot;\nint newPullRequests = 0;\nFile previousPullRequests = new File(&quot;/ci/lib/jenkins/workspace/Pull Request Poller/previousPullRequests.txt&quot;)\n\nString getJson(String addr) {\n manager.listener.logger.println(&quot;Getting URL: &quot;+addr)\n def authString = &quot;user:pass&quot;.getBytes().encodeBase64().toString()\n java.net.URLConnection conn = addr.toURL().openConnection()\n conn.setRequestProperty( &quot;Authorization&quot;, &quot;Basic ${authString}&quot; )\n conn.connect()\n def reader = new BufferedReader(new InputStreamReader(conn.getInputStream()))\n def stringBuilder = new StringBuilder()\n String line = null\n while ((line = reader.readLine()) != null) {\n  stringBuilder.append(line + &quot;\\n&quot;)\n }\n String json = groovy.json.JsonOutput.prettyPrint(stringBuilder.toString())\n manager.listener.logger.println(&quot;Got response:\\n&quot;+json)\n return json\n}\n\nnew groovy.json.JsonSlurper().parseText(getJson(&quot;http://stash/rest/api/1.0/projects/PROJECTS/repos/&quot;)).values.each { repo -&gt;\n manager.listener.logger.println(&quot;Repo: &quot;+repo.slug)\n\n String prettyJSON = getJson(&quot;http://stash/rest/api/1.0/projects/PROJECTS/repos/&quot;+repo.slug+&quot;/pull-requests?base&amp;details&amp;filterText&amp;orderBy&quot;)\n def jsonData = new groovy.json.JsonSlurper().parseText(prettyJSON);\n jsonData.values.each { value -&gt;\n  String title = value.title\n  String from = value.fromRef.latestChangeset\n  String fromRepo = value.fromRef.repository.links.clone.find { it.name == &quot;ssh&quot; }.href\n  String to = value.toRef.latestChangeset\n  String toRepo = value.toRef.repository.links.clone.find { it.name == &quot;ssh&quot; }.href\n  String repositorySlug = repo.slug\n  String pullRequestId = value.id\n  String requestUrl =  &quot;http://stash/projects/PROJECTS/repos/&quot;+repositorySlug+&quot;/pull-requests/&quot;+pullRequestId+&quot;/overview&quot;\n\n  //Remember that this request has been triggered, and avoid triggering it again\n  String identifier = from+&quot; &quot;+to\n  if (previousPullRequests.text.contains(identifier)) {\n   manager.listener.logger.println(&quot;Ignoring: &quot;+identifier)\n   return;\n  }\n  previousPullRequests.append(identifier+&quot;\\n&quot;)\n\n  //Trigger a jenkins job that will verify the pull request\n  String invokeBuildUrl = &quot;http://jenkins/job/Pull%20Request%20Builder/buildWithParameters?token=SECRET_CONFIGURED_IN_BUILD&amp;FROM=&quot;+from+&quot;&amp;TO=&quot;+to+&quot;&amp;FROMREPO=&quot;+fromRepo+&quot;&amp;TOREPO=&quot;+toRepo+&quot;&amp;REPOSITORY_SLUG=&quot;+repositorySlug+&quot;&amp;PULL_REQUEST_ID=&quot;+pullRequestId\n  manager.listener.logger.println(invokeBuildUrl)\n  new URL(invokeBuildUrl).getText()\n\n  summary += &quot;&lt;h1&gt;&quot;+title+&quot;&lt;/h1&gt;&lt;br&gt;&lt;a href='&quot;+requestUrl+&quot;'&gt;&quot;+requestUrl+&quot;&lt;/a&gt;&lt;br&gt;From: &quot;+jsonData.values[0].fromRef.id+&quot; (&quot;+from+&quot;) in &quot;+fromRepo+&quot;&lt;br&gt;To: &quot;+jsonData.values[0].toRef.id+&quot; (&quot;+to+&quot;) in &quot;+toRepo+&quot;&lt;br&gt;&lt;a href='&quot;+invokeBuildUrl+&quot;'&gt;&quot;+invokeBuildUrl+&quot;&lt;/a&gt;&lt;hr&gt;&quot;\n  newPullRequests++;\n }\n}\n\n//Add some info to the build\nif (newPullRequests == 0) {\n manager.createSummary(&quot;gear2.gif&quot;).appendText(&quot;&lt;h1&gt;No new pull requests found!&lt;/h1&gt;&quot; , false)\n} else {\n manager.addShortText(&quot;+&quot;+newPullRequests, &quot;grey&quot;, &quot;white&quot;, &quot;0px&quot;, &quot;white&quot;)\n manager.createSummary(&quot;gear2.gif&quot;).appendText(summary , false)\n}\n</code></pre>\n<h1 id=\"mergingandbuildingthepullrequest\">Merging and building the pull request</h1>\n<p>I created a parameterized job to merge the pull request from source branch to target branch. It takes <em>FROM_HASH</em>, <em>FROM_REPO</em>, <em>TO_HASH</em>, <em>TO_REPO</em>, <em>REPOSITORY_SLUG</em> and <em>PULL_REQUEST_ID</em> as parameters.</p>\n<p>The job has a build step <em>execute shell</em> that does the actual verification.</p>\n<pre><code>git clone $TO_REPO\ncd *\ngit reset --hard $TO_HASH\ngit status\ngit remote add from $FROM_REPO\ngit fetch from\ngit merge $FROM_HASH\ngit --no-pager log --max-count=10 --graph --abbrev-commit\n\n#compile command here ...\n</code></pre>\n<p>The job uses the <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/StashNotifier+Plugin\">Stash Notifier Plugin</a> to record result in the pull request in Stash. Use the ${FROM_HASH} variable to get the build status reported correctly in the pull request in Stash.</p>\n<p>It adds a comment to the pull request, like this.</p>\n<pre><code>curl -D- -u user:pass -X POST -H &quot;Content-Type: application/json&quot;  --data &quot;{ \\&quot;text\\&quot;: \\&quot;Looking good :) http://jenkins/job/Pull%20Request%20Builder/${BUILD_NUMBER}/\\&quot; }&quot; http://stash/rest/api/1.0/projects/PROJECT/repos/$REPOSITORY_SLUG/pull-requests/$PULL_REQUEST_ID/comments\n</code></pre>\n<h1 id=\"staticcodeanalyzers\">Static code analyzers</h1>\n<p>If you are using static code analyzers you may want to have a look at <a href=\"https://github.com/jenkinsci/jenkins-violation-comments-to-stash-plugin\">Jenkins Violation Comments to Stash Plugin</a> for Jenkins.</p>\n<p>It is configured like this.</p>\n<p><img src=\"/content/images/2015/05/screenshot-config.png\" alt=\"alt\"></p>\n<p>And will comment the pull requests like this.</p>\n<p><img src=\"/content/images/2015/05/screenshot-stash.png\" alt=\"alt\"></p>\n","comment_id":"18","plaintext":"Update 160912: There is a new post here\n[http://bjurr.com/continuous-integration-with-bitbucket-server-and-jenkins/].\n\nWe are just about to introduce pull requests at my current position. We are\nusing Git with Atlassian Stash and Jenkins. We want to verify that the pull\nrequests:\n\n * Compile\n * Does not break any test cases\n * Can be merged to target branch\n * Compiles after merge\n * Does not break test cases after merge\n\nAfter some Googling around the issue I found no solution, so I tought I'd make a\npost about how I solved it.\n\nVerifying source of the pull request\nThere is a really nice plugin for Jenkins Stash Notifier Plugin\n[https://wiki.jenkins-ci.org/display/JENKINS/StashNotifier+Plugin]  that can be\nused to notify Stash of the status of a build. Enable it on any Jenkins job that\nbuilds the branch you are merging from. It will add an icon and a link to\nJenkins in the pull request view of Stash.\n\nDiscovering new pull requests\nI initially solved this with a Jenkins job that is polling Stash for new pull\nrequests. But polling is never good so I created a Stash plugin that will notify\nJenkins about new pull requests.\n\nPull Request Notifier Plugin for Stash\nThe plugin is available in Atlassian Marketplace\n[https://marketplace.atlassian.com/plugins/se.bjurr.prnfs.pull-request-notifier-for-stash] \n and at GitHub [https://github.com/tomasbjerre/pull-request-notifier-for-stash].\nWhen installed, you will have this configuration GUI.\n\n\n\nThe features include:\n\n * Trigger on one, or several, event(s) regarding pull requests.\n * Invoke one, or several, URL(s) when event(s) are triggered.\n * Optionally with basic authentication  headers.\n * Completely custom URL supporting variable parameters * ${PULL_REQUEST_ID}\n      Example: 1\n    * ${PULL_REQUEST_ACTION}\n      Example: OPENED\n    * \n      ${PULL_REQUEST_AUTHOR_DISPLAY_NAME} Example: Administrator\n    * \n      ${PULL_REQUEST_AUTHOR_EMAIL} Example: admin@example.com\n    * \n      ${PULL_REQUEST_AUTHOR_ID} Example: 1\n    * \n      ${PULL_REQUEST_AUTHOR_NAME} Example: admin\n    * \n      ${PULL_REQUEST_AUTHOR_SLUG} Example: admin\n    * \n      ${PULL_REQUEST_FROM_HASH} Example:\n      6053a1eaa1c009dd11092d09a72f3c41af1b59ad\n    * \n      ${PULL_REQUEST_FROM_ID} Example: refs/heads/branch_mod_merge\n    * \n      ${PULL_REQUEST_FROM_REPO_ID} Example: 1\n    * \n      ${PULL_REQUEST_FROM_REPO_NAME} Example: rep_1\n    * \n      ${PULL_REQUEST_FROM_REPO_PROJECT_ID} Example: 1\n    * \n      ${PULL_REQUEST_FROM_REPO_PROJECT_KEY} Example: PROJECT_1\n    * \n      ${PULL_REQUEST_FROM_REPO_SLUG} Example: rep_1\n    * And same variables for\n      TO, like: ${PULL_REQUEST_TO_HASH}\n   \n   \n\nYou can have several notifications and have them trigger different URL:s. If you\ntrigger Jenkins builds, you may want each repo to have its own build job in\nJenkins. The filtering functionality is highly configurable. Create a string\nwith the variables and then a regexp that should match that string.\n\n\nPolling Jenkins with Groovy script\nNote that you should only do it this way if you cannot use the plugin described\nabove! For example, uou may not have enaugh access to Stash to install plugins.\n\nStash has really nice REST API:s\n[https://developer.atlassian.com/static/rest/stash/3.6.1/stash-rest.html]. I\ncreated a scheduled job in Jenkins that runs every 5 minutes. I implemented it\nin Groovy using the Groovy plugin\n[https://wiki.jenkins-ci.org/display/JENKINS/Groovy+plugin].\n\n * Find all repos: http://stash/rest/api/1.0/projects/PROJECTS/repos/\n * Find all pull requests in a repo: \n   http://stash/rest/api/1.0/projects/PROJECTS/repos/\"+repo.slug+\"/pull-requests?base&details&filterText&orderBy\n   [http://stash/rest/api/1.0/projects/PROJECTS/repos/%22+repo.slug+%22/pull-requests?base&details&filterText&orderBy]\n\nString summary = \"\"\nint newPullRequests = 0;\nFile previousPullRequests = new File(\"/ci/lib/jenkins/workspace/Pull Request Poller/previousPullRequests.txt\")\n\nString getJson(String addr) {\n manager.listener.logger.println(\"Getting URL: \"+addr)\n def authString = \"user:pass\".getBytes().encodeBase64().toString()\n java.net.URLConnection conn = addr.toURL().openConnection()\n conn.setRequestProperty( \"Authorization\", \"Basic ${authString}\" )\n conn.connect()\n def reader = new BufferedReader(new InputStreamReader(conn.getInputStream()))\n def stringBuilder = new StringBuilder()\n String line = null\n while ((line = reader.readLine()) != null) {\n  stringBuilder.append(line + \"\\n\")\n }\n String json = groovy.json.JsonOutput.prettyPrint(stringBuilder.toString())\n manager.listener.logger.println(\"Got response:\\n\"+json)\n return json\n}\n\nnew groovy.json.JsonSlurper().parseText(getJson(\"http://stash/rest/api/1.0/projects/PROJECTS/repos/\")).values.each { repo ->\n manager.listener.logger.println(\"Repo: \"+repo.slug)\n\n String prettyJSON = getJson(\"http://stash/rest/api/1.0/projects/PROJECTS/repos/\"+repo.slug+\"/pull-requests?base&details&filterText&orderBy\")\n def jsonData = new groovy.json.JsonSlurper().parseText(prettyJSON);\n jsonData.values.each { value ->\n  String title = value.title\n  String from = value.fromRef.latestChangeset\n  String fromRepo = value.fromRef.repository.links.clone.find { it.name == \"ssh\" }.href\n  String to = value.toRef.latestChangeset\n  String toRepo = value.toRef.repository.links.clone.find { it.name == \"ssh\" }.href\n  String repositorySlug = repo.slug\n  String pullRequestId = value.id\n  String requestUrl =  \"http://stash/projects/PROJECTS/repos/\"+repositorySlug+\"/pull-requests/\"+pullRequestId+\"/overview\"\n\n  //Remember that this request has been triggered, and avoid triggering it again\n  String identifier = from+\" \"+to\n  if (previousPullRequests.text.contains(identifier)) {\n   manager.listener.logger.println(\"Ignoring: \"+identifier)\n   return;\n  }\n  previousPullRequests.append(identifier+\"\\n\")\n\n  //Trigger a jenkins job that will verify the pull request\n  String invokeBuildUrl = \"http://jenkins/job/Pull%20Request%20Builder/buildWithParameters?token=SECRET_CONFIGURED_IN_BUILD&FROM=\"+from+\"&TO=\"+to+\"&FROMREPO=\"+fromRepo+\"&TOREPO=\"+toRepo+\"&REPOSITORY_SLUG=\"+repositorySlug+\"&PULL_REQUEST_ID=\"+pullRequestId\n  manager.listener.logger.println(invokeBuildUrl)\n  new URL(invokeBuildUrl).getText()\n\n  summary += \"<h1>\"+title+\"</h1><br><a href='\"+requestUrl+\"'>\"+requestUrl+\"</a><br>From: \"+jsonData.values[0].fromRef.id+\" (\"+from+\") in \"+fromRepo+\"<br>To: \"+jsonData.values[0].toRef.id+\" (\"+to+\") in \"+toRepo+\"<br><a href='\"+invokeBuildUrl+\"'>\"+invokeBuildUrl+\"</a><hr>\"\n  newPullRequests++;\n }\n}\n\n//Add some info to the build\nif (newPullRequests == 0) {\n manager.createSummary(\"gear2.gif\").appendText(\"<h1>No new pull requests found!</h1>\" , false)\n} else {\n manager.addShortText(\"+\"+newPullRequests, \"grey\", \"white\", \"0px\", \"white\")\n manager.createSummary(\"gear2.gif\").appendText(summary , false)\n}\n\n\nMerging and building the pull request\nI created a parameterized job to merge the pull request from source branch to\ntarget branch. It takes FROM_HASH, FROM_REPO, TO_HASH, TO_REPO, REPOSITORY_SLUG \nand PULL_REQUEST_ID  as parameters.\n\nThe job has a build step execute shell  that does the actual verification.\n\ngit clone $TO_REPO\ncd *\ngit reset --hard $TO_HASH\ngit status\ngit remote add from $FROM_REPO\ngit fetch from\ngit merge $FROM_HASH\ngit --no-pager log --max-count=10 --graph --abbrev-commit\n\n#compile command here ...\n\n\nThe job uses the Stash Notifier Plugin\n[https://wiki.jenkins-ci.org/display/JENKINS/StashNotifier+Plugin]  to record\nresult in the pull request in Stash. Use the ${FROM_HASH} variable to get the\nbuild status reported correctly in the pull request in Stash.\n\nIt adds a comment to the pull request, like this.\n\ncurl -D- -u user:pass -X POST -H \"Content-Type: application/json\"  --data \"{ \\\"text\\\": \\\"Looking good :) http://jenkins/job/Pull%20Request%20Builder/${BUILD_NUMBER}/\\\" }\" http://stash/rest/api/1.0/projects/PROJECT/repos/$REPOSITORY_SLUG/pull-requests/$PULL_REQUEST_ID/comments\n\n\nStatic code analyzers\nIf you are using static code analyzers you may want to have a look at Jenkins\nViolation Comments to Stash Plugin\n[https://github.com/jenkinsci/jenkins-violation-comments-to-stash-plugin]  for\nJenkins.\n\nIt is configured like this.\n\n\n\nAnd will comment the pull requests like this.","feature_image":null,"featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2015-02-18T16:25:34.000Z","created_by":"1","updated_at":"2017-03-18T19:18:18.000Z","updated_by":"1","published_at":"2015-02-18T16:25:34.000Z","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"custom_template":null},{"id":"597b4433e521cb4fbd91869f","uuid":"a29e716c-e305-4ad2-9a10-00bb44a0a545","title":"Simple Stash Commit Checker","slug":"simple-stash-commit-checker","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"Update 160912: There is a [new post here](http://bjurr.com/continuous-integration-with-bitbucket-server-and-jenkins/).\\n\\nI'm currently working with a customer that has around 30 comitters working on the same code base. We are using Git with Atlassian Stash.\\n\\nReccently some code were released to production earlier then planned. Because of a faulty merge about 10 weeks earlier. This brings up the subject of commit comments. I started looking around for a good commit checker for Stash. I found mainly one problem with the existing hooks. It was not possible to customize messages shown to comitters when rejected.\\n\\nSo I created [Simple Stash Commit Checker](https://marketplace.atlassian.com/plugins/se.bjurr.sscc.sscc). The code is available [here](https://github.com/tomasbjerre/simple-stash-commit-checker). It is highly configurable. For any rejection reason, there is a configurable response.\\n\\n![Config Email](/content/images/2015/03/config_and_reject.png)\\n\\nEmail and author can be checked against corresponding value in Stash.\\n\\n![Config Email](/content/images/2015/03/config.png)\\n\\nIf you enable this kind of plugin, the developers may need some time to adjust. Thats why I added a *dry run* mode. Where rejection messages are shown but no commits are actually rejected.\\n![Dry run](/content/images/2015/03/dry.png)\\n\\nIt is possible to add groups of restrictions. A group could be *Issues*. And rules in the groups. A rule could be, for example, *Jira* and/or *Incident*. And the group could state that at least one issue should be mentioned in the commit.\\n\\n![Groups](/content/images/2015/03/rules.png)\\n\\nThe group could also accept commits that does not contain some specific word. Some people like to write *fixing review comments* or *fixing sonar errors*. There could be a rule rejecting commits containing *sonar* or *review*. With a rejection reason like: *It is not relevant to mention that the changes were suggested by Sonar or from a review. It is relevant to mention what is actually changed and how that improves the code.*\"}]],\"sections\":[[10,0]]}","html":"<p>Update 160912: There is a <a href=\"http://bjurr.com/continuous-integration-with-bitbucket-server-and-jenkins/\">new post here</a>.</p>\n<p>I'm currently working with a customer that has around 30 comitters working on the same code base. We are using Git with Atlassian Stash.</p>\n<p>Reccently some code were released to production earlier then planned. Because of a faulty merge about 10 weeks earlier. This brings up the subject of commit comments. I started looking around for a good commit checker for Stash. I found mainly one problem with the existing hooks. It was not possible to customize messages shown to comitters when rejected.</p>\n<p>So I created <a href=\"https://marketplace.atlassian.com/plugins/se.bjurr.sscc.sscc\">Simple Stash Commit Checker</a>. The code is available <a href=\"https://github.com/tomasbjerre/simple-stash-commit-checker\">here</a>. It is highly configurable. For any rejection reason, there is a configurable response.</p>\n<p><img src=\"/content/images/2015/03/config_and_reject.png\" alt=\"Config Email\"></p>\n<p>Email and author can be checked against corresponding value in Stash.</p>\n<p><img src=\"/content/images/2015/03/config.png\" alt=\"Config Email\"></p>\n<p>If you enable this kind of plugin, the developers may need some time to adjust. Thats why I added a <em>dry run</em> mode. Where rejection messages are shown but no commits are actually rejected.<br>\n<img src=\"/content/images/2015/03/dry.png\" alt=\"Dry run\"></p>\n<p>It is possible to add groups of restrictions. A group could be <em>Issues</em>. And rules in the groups. A rule could be, for example, <em>Jira</em> and/or <em>Incident</em>. And the group could state that at least one issue should be mentioned in the commit.</p>\n<p><img src=\"/content/images/2015/03/rules.png\" alt=\"Groups\"></p>\n<p>The group could also accept commits that does not contain some specific word. Some people like to write <em>fixing review comments</em> or <em>fixing sonar errors</em>. There could be a rule rejecting commits containing <em>sonar</em> or <em>review</em>. With a rejection reason like: <em>It is not relevant to mention that the changes were suggested by Sonar or from a review. It is relevant to mention what is actually changed and how that improves the code.</em></p>\n","comment_id":"19","plaintext":"Update 160912: There is a new post here\n[http://bjurr.com/continuous-integration-with-bitbucket-server-and-jenkins/].\n\nI'm currently working with a customer that has around 30 comitters working on\nthe same code base. We are using Git with Atlassian Stash.\n\nReccently some code were released to production earlier then planned. Because of\na faulty merge about 10 weeks earlier. This brings up the subject of commit\ncomments. I started looking around for a good commit checker for Stash. I found\nmainly one problem with the existing hooks. It was not possible to customize\nmessages shown to comitters when rejected.\n\nSo I created Simple Stash Commit Checker\n[https://marketplace.atlassian.com/plugins/se.bjurr.sscc.sscc]. The code is\navailable here [https://github.com/tomasbjerre/simple-stash-commit-checker]. It\nis highly configurable. For any rejection reason, there is a configurable\nresponse.\n\n\n\nEmail and author can be checked against corresponding value in Stash.\n\n\n\nIf you enable this kind of plugin, the developers may need some time to adjust.\nThats why I added a dry run  mode. Where rejection messages are shown but no\ncommits are actually rejected.\n\n\nIt is possible to add groups of restrictions. A group could be Issues. And rules\nin the groups. A rule could be, for example, Jira  and/or Incident. And the\ngroup could state that at least one issue should be mentioned in the commit.\n\n\n\nThe group could also accept commits that does not contain some specific word.\nSome people like to write fixing review comments  or fixing sonar errors. There\ncould be a rule rejecting commits containing sonar  or review. With a rejection\nreason like: It is not relevant to mention that the changes were suggested by\nSonar or from a review. It is relevant to mention what is actually changed and\nhow that improves the code.","feature_image":"/content/images/2018/02/0722.sdt-atlassian-1.png","featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2015-03-01T21:35:13.000Z","created_by":"1","updated_at":"2018-02-24T09:12:56.000Z","updated_by":"1","published_at":"2015-03-01T21:35:29.000Z","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"custom_template":null},{"id":"597b4433e521cb4fbd9186a0","uuid":"8a156015-0dbe-49c2-b057-0c84319a9da7","title":"Ghost blog on GitHub pages","slug":"ghost-blog-on-github-pages","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"**Updated version here: https://bjurr.com/ghost-1-0-free-hosting-with-https/**\\n\\nI just moved this blog from a Raspberry PI to GitHub pages. I was inspired by [this](https://stefanscherer.github.io/setup-ghost-for-github-pages/) article. I am also using [Buster](https://pypi.python.org/pypi/buster/) but I am doing it a bit different. The repository is [here](https://github.com/tomasbjerre/tomasbjerre.github.io/).\\n\\nI get HTTPS with custom domain as described in [this](https://www.jonathan-petitcolas.com/2017/01/13/using-https-with-custom-domain-name-on-github-pages.html) blog post.\\n\\nI put together some [scripts](https://github.com/tomasbjerre/tomasbjerre.github.io/tree/tools) to ease the blogging.\\n\\n * **install.sh** Downloads Ghost blogging platform and installs it in the current directory.\\n * **run.sh** Starts Ghost blogging platform on *localhost*. So that it can be edited.\\n * **commit.sh** Saves the blog and commits it to *master*. The **run.sh** script must be running when this script is invoked.\\n\\n**commit.sh** will create the *CNAME* file required if you want to use [your own domain name](https://help.github.com/articles/tips-for-configuring-an-a-record-with-your-dns-provider/).\\n\\nThere will be 3 commits in the repo. The scripts will amend to these when changes are made. This is important to keep the repo small, it may grow very big, very fast if you don't amend.\\n```\\n*       (tools)  Blog maintenance\\n| *     (master)  Static blog content\\n|/  \\n*       Initial commit\\n```\\n\"}]],\"sections\":[[10,0]]}","html":"<p><strong>Updated version here: <a href=\"https://bjurr.com/ghost-1-0-free-hosting-with-https/\">https://bjurr.com/ghost-1-0-free-hosting-with-https/</a></strong></p>\n<p>I just moved this blog from a Raspberry PI to GitHub pages. I was inspired by <a href=\"https://stefanscherer.github.io/setup-ghost-for-github-pages/\">this</a> article. I am also using <a href=\"https://pypi.python.org/pypi/buster/\">Buster</a> but I am doing it a bit different. The repository is <a href=\"https://github.com/tomasbjerre/tomasbjerre.github.io/\">here</a>.</p>\n<p>I get HTTPS with custom domain as described in <a href=\"https://www.jonathan-petitcolas.com/2017/01/13/using-https-with-custom-domain-name-on-github-pages.html\">this</a> blog post.</p>\n<p>I put together some <a href=\"https://github.com/tomasbjerre/tomasbjerre.github.io/tree/tools\">scripts</a> to ease the blogging.</p>\n<ul>\n<li><strong>install.sh</strong> Downloads Ghost blogging platform and installs it in the current directory.</li>\n<li><strong>run.sh</strong> Starts Ghost blogging platform on <em>localhost</em>. So that it can be edited.</li>\n<li><strong>commit.sh</strong> Saves the blog and commits it to <em>master</em>. The <strong>run.sh</strong> script must be running when this script is invoked.</li>\n</ul>\n<p><strong>commit.sh</strong> will create the <em>CNAME</em> file required if you want to use <a href=\"https://help.github.com/articles/tips-for-configuring-an-a-record-with-your-dns-provider/\">your own domain name</a>.</p>\n<p>There will be 3 commits in the repo. The scripts will amend to these when changes are made. This is important to keep the repo small, it may grow very big, very fast if you don't amend.</p>\n<pre><code>*       (tools)  Blog maintenance\n| *     (master)  Static blog content\n|/  \n*       Initial commit\n</code></pre>\n","comment_id":"22","plaintext":"Updated version here: https://bjurr.com/ghost-1-0-free-hosting-with-https/\n\nI just moved this blog from a Raspberry PI to GitHub pages. I was inspired by \nthis [https://stefanscherer.github.io/setup-ghost-for-github-pages/]  article. I\nam also using Buster [https://pypi.python.org/pypi/buster/]  but I am doing it a\nbit different. The repository is here\n[https://github.com/tomasbjerre/tomasbjerre.github.io/].\n\nI get HTTPS with custom domain as described in this\n[https://www.jonathan-petitcolas.com/2017/01/13/using-https-with-custom-domain-name-on-github-pages.html] \n blog post.\n\nI put together some scripts\n[https://github.com/tomasbjerre/tomasbjerre.github.io/tree/tools]  to ease the\nblogging.\n\n * install.sh  Downloads Ghost blogging platform and installs it in the current\n   directory.\n * run.sh  Starts Ghost blogging platform on localhost. So that it can be\n   edited.\n * commit.sh  Saves the blog and commits it to master. The run.sh  script must\n   be running when this script is invoked.\n\ncommit.sh  will create the CNAME  file required if you want to use your own\ndomain name\n[https://help.github.com/articles/tips-for-configuring-an-a-record-with-your-dns-provider/]\n.\n\nThere will be 3 commits in the repo. The scripts will amend to these when\nchanges are made. This is important to keep the repo small, it may grow very\nbig, very fast if you don't amend.\n\n*       (tools)  Blog maintenance\n| *     (master)  Static blog content\n|/  \n*       Initial commit","feature_image":null,"featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2015-12-18T12:58:58.000Z","created_by":"1","updated_at":"2017-07-28T16:44:50.000Z","updated_by":"1","published_at":"2015-12-18T13:10:28.000Z","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"custom_template":null},{"id":"597b4433e521cb4fbd9186a1","uuid":"d5ae9f56-dcc8-41d7-9b44-f46607fb0875","title":"Git Changelog Lib - Changelog, or releasenotes, from template","slug":"git-changelog","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"I define a **changelog** as a document that, for every release, contains a section describing the changes in that release. I define **releasenotes** as the changes made in a specific release. Most notes below can be applied to both, but I'm just going to talk about changelogs. To keep it simple.\\n\\n#The problem\\n\\nChangelogs are important! But there are some problems that comes with having a changelog.\\n\\n * **Boring** Keeping the changelog updated is boring!\\n * **Availability** You may be required to make the changelog available to people who are not developers.\\n * **Reliability** Some change may not be in the changelog, or some change may be there but not in the actual release.\\n * **Formatting** Very few developers enjoy fiddling with text formatting!\\n\\n#Other solutions\\n\\nThere are some solutions, if you [google it](http://lmgtfy.com/?q=git+changelog). What I was missing in the solutions that I found was:\\n\\n * **Templating** Companies may have very specific requirements on the formatting of the changelog.\\n * **Wiki integration** I needed to publish the changelog in MediaWiki.\\n\\n#My solution\\n\\nIs [Git Changelog Lib](https://github.com/tomasbjerre/git-changelog-lib). A library, Java, that create a changelog for you, using the information that is already in the GIT repository. The lib can be used:\\n\\n * With a [Gradle plugin](https://github.com/tomasbjerre/git-changelog-gradle-plugin).\\n * With a [Maven plugin](https://github.com/tomasbjerre/git-changelog-maven-plugin).\\n * With a [Jenkins plugin](https://github.com/jenkinsci/git-changelog-plugin).\\n * With a [Bitbucket Server plugin](https://github.com/tomasbjerre/git-changelog-bitbucket-plugin).\\n * From [command line](https://github.com/tomasbjerre/git-changelog-command-line).\\n\\nThe basic idea is to have library that gathers a data structure and supplies it to a Mustache template so that the changelog becomes completely customizable.\\n\\n```\\n# Git Changelog changelog\\n\\nChangelog of Git Changelog.\\n{{#tags}}\\n## {{name}}\\n {{#issues}}\\n  {{#hasLink}}\\n### {{name}} [{{issue}}]({{link}}) {{title}}\\n  {{/hasLink}}\\n  {{^hasLink}}\\n### {{name}} {{title}}\\n  {{/hasLink}}\\n  {{#authors}}\\n* {{authorName}}\\n   {{#commits}}\\n[{{hash}}](https://server/{{hash}}) *{{commitTime}}*\\n{{{message}}}\\n\\n   {{/commits}}\\n\\n  {{/authors}}\\n {{/issues}}\\n{{/tags}}\\n```\\n\\nSome of the features included are:\\n\\n * **Templating** Using Mustache templates.\\n * **MediaWiki** Integrated with MediaWiki to publish changelogs.\\n * **[Jenkins plugin](https://github.com/jenkinsci/git-changelog-plugin)** To publish the changelog on Jenkins summary page. Or let Jenkins create MediaWiki page or file in workspace.\\n * **[Bitbucket Server plugin](https://github.com/tomasbjerre/git-changelog-bitbucket-plugin)** Adds a changelog in the repository page.\\n * **[Gradle plugin](https://github.com/tomasbjerre/git-changelog-gradle-plugin)** To add a changelog task to the Gradle build.\\n * **[Maven plugin](https://github.com/tomasbjerre/git-changelog-maven-plugin)** To add a changelog task to the Maven build.\"}]],\"sections\":[[10,0]]}","html":"<p>I define a <strong>changelog</strong> as a document that, for every release, contains a section describing the changes in that release. I define <strong>releasenotes</strong> as the changes made in a specific release. Most notes below can be applied to both, but I'm just going to talk about changelogs. To keep it simple.</p>\n<h1 id=\"theproblem\">The problem</h1>\n<p>Changelogs are important! But there are some problems that comes with having a changelog.</p>\n<ul>\n<li><strong>Boring</strong> Keeping the changelog updated is boring!</li>\n<li><strong>Availability</strong> You may be required to make the changelog available to people who are not developers.</li>\n<li><strong>Reliability</strong> Some change may not be in the changelog, or some change may be there but not in the actual release.</li>\n<li><strong>Formatting</strong> Very few developers enjoy fiddling with text formatting!</li>\n</ul>\n<h1 id=\"othersolutions\">Other solutions</h1>\n<p>There are some solutions, if you <a href=\"http://lmgtfy.com/?q=git+changelog\">google it</a>. What I was missing in the solutions that I found was:</p>\n<ul>\n<li><strong>Templating</strong> Companies may have very specific requirements on the formatting of the changelog.</li>\n<li><strong>Wiki integration</strong> I needed to publish the changelog in MediaWiki.</li>\n</ul>\n<h1 id=\"mysolution\">My solution</h1>\n<p>Is <a href=\"https://github.com/tomasbjerre/git-changelog-lib\">Git Changelog Lib</a>. A library, Java, that create a changelog for you, using the information that is already in the GIT repository. The lib can be used:</p>\n<ul>\n<li>With a <a href=\"https://github.com/tomasbjerre/git-changelog-gradle-plugin\">Gradle plugin</a>.</li>\n<li>With a <a href=\"https://github.com/tomasbjerre/git-changelog-maven-plugin\">Maven plugin</a>.</li>\n<li>With a <a href=\"https://github.com/jenkinsci/git-changelog-plugin\">Jenkins plugin</a>.</li>\n<li>With a <a href=\"https://github.com/tomasbjerre/git-changelog-bitbucket-plugin\">Bitbucket Server plugin</a>.</li>\n<li>From <a href=\"https://github.com/tomasbjerre/git-changelog-command-line\">command line</a>.</li>\n</ul>\n<p>The basic idea is to have library that gathers a data structure and supplies it to a Mustache template so that the changelog becomes completely customizable.</p>\n<pre><code># Git Changelog changelog\n\nChangelog of Git Changelog.\n{{#tags}}\n## {{name}}\n {{#issues}}\n  {{#hasLink}}\n### {{name}} [{{issue}}]({{link}}) {{title}}\n  {{/hasLink}}\n  {{^hasLink}}\n### {{name}} {{title}}\n  {{/hasLink}}\n  {{#authors}}\n* {{authorName}}\n   {{#commits}}\n[{{hash}}](https://server/{{hash}}) *{{commitTime}}*\n{{{message}}}\n\n   {{/commits}}\n\n  {{/authors}}\n {{/issues}}\n{{/tags}}\n</code></pre>\n<p>Some of the features included are:</p>\n<ul>\n<li><strong>Templating</strong> Using Mustache templates.</li>\n<li><strong>MediaWiki</strong> Integrated with MediaWiki to publish changelogs.</li>\n<li><strong><a href=\"https://github.com/jenkinsci/git-changelog-plugin\">Jenkins plugin</a></strong> To publish the changelog on Jenkins summary page. Or let Jenkins create MediaWiki page or file in workspace.</li>\n<li><strong><a href=\"https://github.com/tomasbjerre/git-changelog-bitbucket-plugin\">Bitbucket Server plugin</a></strong> Adds a changelog in the repository page.</li>\n<li><strong><a href=\"https://github.com/tomasbjerre/git-changelog-gradle-plugin\">Gradle plugin</a></strong> To add a changelog task to the Gradle build.</li>\n<li><strong><a href=\"https://github.com/tomasbjerre/git-changelog-maven-plugin\">Maven plugin</a></strong> To add a changelog task to the Maven build.</li>\n</ul>\n","comment_id":"23","plaintext":"I define a changelog  as a document that, for every release, contains a section\ndescribing the changes in that release. I define releasenotes  as the changes\nmade in a specific release. Most notes below can be applied to both, but I'm\njust going to talk about changelogs. To keep it simple.\n\nThe problem\nChangelogs are important! But there are some problems that comes with having a\nchangelog.\n\n * Boring  Keeping the changelog updated is boring!\n * Availability  You may be required to make the changelog available to people\n   who are not developers.\n * Reliability  Some change may not be in the changelog, or some change may be\n   there but not in the actual release.\n * Formatting  Very few developers enjoy fiddling with text formatting!\n\nOther solutions\nThere are some solutions, if you google it [http://lmgtfy.com/?q=git+changelog].\nWhat I was missing in the solutions that I found was:\n\n * Templating  Companies may have very specific requirements on the formatting\n   of the changelog.\n * Wiki integration  I needed to publish the changelog in MediaWiki.\n\nMy solution\nIs Git Changelog Lib [https://github.com/tomasbjerre/git-changelog-lib]. A\nlibrary, Java, that create a changelog for you, using the information that is\nalready in the GIT repository. The lib can be used:\n\n * With a Gradle plugin\n   [https://github.com/tomasbjerre/git-changelog-gradle-plugin].\n * With a Maven plugin\n   [https://github.com/tomasbjerre/git-changelog-maven-plugin].\n * With a Jenkins plugin [https://github.com/jenkinsci/git-changelog-plugin].\n * With a Bitbucket Server plugin\n   [https://github.com/tomasbjerre/git-changelog-bitbucket-plugin].\n * From command line [https://github.com/tomasbjerre/git-changelog-command-line]\n   .\n\nThe basic idea is to have library that gathers a data structure and supplies it\nto a Mustache template so that the changelog becomes completely customizable.\n\n# Git Changelog changelog\n\nChangelog of Git Changelog.\n{{#tags}}\n## {{name}}\n {{#issues}}\n  {{#hasLink}}\n### {{name}} [{{issue}}]({{link}}) {{title}}\n  {{/hasLink}}\n  {{^hasLink}}\n### {{name}} {{title}}\n  {{/hasLink}}\n  {{#authors}}\n* {{authorName}}\n   {{#commits}}\n[{{hash}}](https://server/{{hash}}) *{{commitTime}}*\n{{{message}}}\n\n   {{/commits}}\n\n  {{/authors}}\n {{/issues}}\n{{/tags}}\n\n\nSome of the features included are:\n\n * Templating  Using Mustache templates.\n * MediaWiki  Integrated with MediaWiki to publish changelogs.\n * Jenkins plugin [https://github.com/jenkinsci/git-changelog-plugin]  To\n   publish the changelog on Jenkins summary page. Or let Jenkins create\n   MediaWiki page or file in workspace.\n * Bitbucket Server plugin\n   [https://github.com/tomasbjerre/git-changelog-bitbucket-plugin]  Adds a\n   changelog in the repository page.\n * Gradle plugin [https://github.com/tomasbjerre/git-changelog-gradle-plugin] \n   To add a changelog task to the Gradle build.\n * Maven plugin [https://github.com/tomasbjerre/git-changelog-maven-plugin]  To\n   add a changelog task to the Maven build.","feature_image":"/content/images/2018/02/Git-logo-black.svg.png","featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2015-12-19T09:00:06.000Z","created_by":"1","updated_at":"2018-02-24T09:11:54.000Z","updated_by":"1","published_at":"2015-12-19T09:24:55.000Z","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"custom_template":null},{"id":"597b4433e521cb4fbd9186a2","uuid":"120ed7f4-df28-4658-819f-f1e42b1b843c","title":"Static code analysis with GitHub","slug":"static-code-analysis-with-github","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"I previously wrote about [Violation Comments to Bitbucket Server](https://wiki.jenkins-ci.org/display/JENKINS/Violation+Comments+to+Bitbucket+Server+Plugin) plugin for Jenkins. I wanted to do the same thing with GitHub and Travis, here is the result.\\n\\n![Violation comment in GitHub pull request](/content/images/2016/03/findbugs-github-pr-file-comment.png)\\n\\nYou may also have a look at [violations-test](https://github.com/tomasbjerre/violations-test/pull/2) repo where I have a live demo of this.\\n\\nEvery time I push to a pull request, or its target branch, Travis will perform static code analysis and report back to GitHub. I created a [Maven plugin](https://github.com/tomasbjerre/violation-comments-to-github-maven-plugin) and [Gradle plugin](https://github.com/tomasbjerre/violation-comments-to-github-gradle-plugin) to make this possible. I also created a [Jenkins plugin](https://github.com/jenkinsci/violation-comments-to-github-jenkins-plugin).\\n\\nIt supports same format as [violations-lib](https://github.com/tomasbjerre/violations-lib):\\n  \\n * [**Checkstyle**](http://checkstyle.sourceforge.net/)\\n * [**CPPLint**](https://github.com/theandrewdavis/cpplint)\\n * [**CPPCheck**](http://cppcheck.sourceforge.net/)\\n * [**CSSLint**](https://github.com/CSSLint/csslint)\\n * [**Findbugs**](http://findbugs.sourceforge.net/)\\n * [**Flake8**](http://flake8.readthedocs.org/en/latest/) ([_PyLint_](https://www.pylint.org/), [_Pep8_](https://github.com/PyCQA/pycodestyle))\\n * [**JSHint**](http://jshint.com/)\\n * **Lint** A common XML format, used by different linters.\\n * [**PerlCritic**](https://github.com/Perl-Critic)\\n * [**PMD**](https://pmd.github.io/)\\n * [**ReSharper**](https://www.jetbrains.com/resharper/)\\n * [**XMLLint**](http://xmlsoft.org/xmllint.html)\\n\\nMany more formats are planned and [pull requests](https://github.com/tomasbjerre/violations-lib) are very welcome!\\n\\nThis will **not work in Travis for pull requests from forked repositories**. But **will work great with Travis for internal pull requests**. But that is a **limitation in Travis, not in the plugins** used for reporting. So if you want to do this on pull requests from forked repos you can use a private hosted build server. I created a **[Jenkins plugin](https://github.com/tomasbjerre/violation-comments-to-github-jenkins-plugin) that can be used for building pull requests from forked repositories**. You may also use the [Maven plugin](https://github.com/tomasbjerre/violation-comments-to-github-maven-plugin) or [Gradle plugin](https://github.com/tomasbjerre/violation-comments-to-github-gradle-plugin) for that.\\n\\nHere is how to set it up in Travis.\\n\\n# Travis setup\\nYou need to have a user that is allowed to post comments on the pull request. You may use the users username and password, or an OAuth2 token. I will use OAuth2 token in this example. Here is how to create it:\\n\\n`curl -u 'yourgithubuser' -d '{\\\"note\\\":\\\"Violation comments\\\"}' https://api.github.com/authorizations\\n`\\n\\nIt will prompt for you password and give you back the token.\\n\\nYou need to add it to `.travis.yml`. Travis provides a nice tool for encrypting the token:\\n```\\nsudo apt-get install ruby-dev\\ngem install travis\\ntravis encrypt export GITHUB_OAUTH2TOKEN=YOUR TOKEN HERE\\n```\\nAdd the encrypted token to your `.travis.yml` under env. I'm including the Gradle task here also:\\n```\\nsudo: false\\nlanguage: java\\nenv:\\n  - secure: \\\"YOUR ENCRYPTED TOKEN HERE\\\"\\njdk:\\n  - oraclejdk7\\nscript:\\n  - ./gradlew build violationCommentsToGitHub -DGITHUB_PULLREQUESTID=$TRAVIS_PULL_REQUEST -DGITHUB_OAUTH2TOKEN=$GITHUB_OAUTH2TOKEN -i --stacktrace\\nnotifications:\\n  email: false\\n```\\n\\nNow you need to edit your `build.gradle` to include the plugin. As mentioned above, there is also a [Maven plugin](https://github.com/tomasbjerre/violation-comments-to-github-maven-plugin) with the exact same functionality. This blog post may not be up to date, so best is to check [Gradle plugin](https://github.com/tomasbjerre/violation-comments-to-github-gradle-plugin) for latest version and config. But here is an example:\\n\\n```\\n  buildscript {\\n    repositories {\\n      maven {\\n        url \\\"https://plugins.gradle.org/m2/\\\"\\n      }\\n    }\\n    dependencies {\\n      classpath \\\"se.bjurr.violations:violation-comments-to-github-gradle-plugin:1.1\\\"\\n    }\\n  }\\n\\n  apply plugin: \\\"se.bjurr.violations.violation-comments-to-github-gradle-plugin\\\"\\n\\n  task violationCommentsToGitHub(type: se.bjurr.violations.comments.github.plugin.gradle.ViolationCommentsToGitHubTask) {\\n   repositoryOwner = \\\"tomasbjerre\\\";\\n   repositoryName = \\\"violations-test\\\"\\n   pullRequestId = System.properties['GITHUB_PULLREQUESTID']\\n   username = System.properties['GITHUB_USERNAME']\\n   password = System.properties['GITHUB_PASSWORD']\\n   oAuth2Token = System.properties['GITHUB_OAUTH2TOKEN']\\n   gitHubUrl = \\\"https://api.github.com/\\\"\\n   createCommentWithAllSingleFileComments = false\\n   createSingleFileComments = true\\n   violations = [\\n    [\\\"FINDBUGS\\\",   \\\".\\\", \\\".*/findbugs/.*\\\\\\\\.xml\\\\$\\\"],\\n    [\\\"PMD\\\",        \\\".\\\", \\\".*/pmd/.*\\\\\\\\.xml\\\\$\\\"],\\n    [\\\"CHECKSTYLE\\\", \\\".\\\", \\\".*/checkstyle/.*\\\\\\\\.xml\\\\$\\\"],\\n    [\\\"JSHINT\\\",     \\\".\\\", \\\".*/jshint/.*\\\\\\\\.xml\\\\$\\\"],\\n    [\\\"CSSLINT\\\",    \\\".\\\", \\\".*/csslint/.*\\\\\\\\.xml\\\\$\\\"]\\n   ]\\n  }\\n```\\n\\nNow all you need to do is to add the task to the build script, as you saw above, you need this:\\n```\\n script:\\n  - ./gradlew build violationCommentsToGitHub -DGITHUB_PULLREQUESTID=$TRAVIS_PULL_REQUEST -DGITHUB_OAUTH2TOKEN=$GITHUB_OAUTH2TOKEN -i\\n```\"}]],\"sections\":[[10,0]]}","html":"<p>I previously wrote about <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/Violation+Comments+to+Bitbucket+Server+Plugin\">Violation Comments to Bitbucket Server</a> plugin for Jenkins. I wanted to do the same thing with GitHub and Travis, here is the result.</p>\n<p><img src=\"/content/images/2016/03/findbugs-github-pr-file-comment.png\" alt=\"Violation comment in GitHub pull request\"></p>\n<p>You may also have a look at <a href=\"https://github.com/tomasbjerre/violations-test/pull/2\">violations-test</a> repo where I have a live demo of this.</p>\n<p>Every time I push to a pull request, or its target branch, Travis will perform static code analysis and report back to GitHub. I created a <a href=\"https://github.com/tomasbjerre/violation-comments-to-github-maven-plugin\">Maven plugin</a> and <a href=\"https://github.com/tomasbjerre/violation-comments-to-github-gradle-plugin\">Gradle plugin</a> to make this possible. I also created a <a href=\"https://github.com/jenkinsci/violation-comments-to-github-jenkins-plugin\">Jenkins plugin</a>.</p>\n<p>It supports same format as <a href=\"https://github.com/tomasbjerre/violations-lib\">violations-lib</a>:</p>\n<ul>\n<li><a href=\"http://checkstyle.sourceforge.net/\"><strong>Checkstyle</strong></a></li>\n<li><a href=\"https://github.com/theandrewdavis/cpplint\"><strong>CPPLint</strong></a></li>\n<li><a href=\"http://cppcheck.sourceforge.net/\"><strong>CPPCheck</strong></a></li>\n<li><a href=\"https://github.com/CSSLint/csslint\"><strong>CSSLint</strong></a></li>\n<li><a href=\"http://findbugs.sourceforge.net/\"><strong>Findbugs</strong></a></li>\n<li><a href=\"http://flake8.readthedocs.org/en/latest/\"><strong>Flake8</strong></a> (<a href=\"https://www.pylint.org/\"><em>PyLint</em></a>, <a href=\"https://github.com/PyCQA/pycodestyle\"><em>Pep8</em></a>)</li>\n<li><a href=\"http://jshint.com/\"><strong>JSHint</strong></a></li>\n<li><strong>Lint</strong> A common XML format, used by different linters.</li>\n<li><a href=\"https://github.com/Perl-Critic\"><strong>PerlCritic</strong></a></li>\n<li><a href=\"https://pmd.github.io/\"><strong>PMD</strong></a></li>\n<li><a href=\"https://www.jetbrains.com/resharper/\"><strong>ReSharper</strong></a></li>\n<li><a href=\"http://xmlsoft.org/xmllint.html\"><strong>XMLLint</strong></a></li>\n</ul>\n<p>Many more formats are planned and <a href=\"https://github.com/tomasbjerre/violations-lib\">pull requests</a> are very welcome!</p>\n<p>This will <strong>not work in Travis for pull requests from forked repositories</strong>. But <strong>will work great with Travis for internal pull requests</strong>. But that is a <strong>limitation in Travis, not in the plugins</strong> used for reporting. So if you want to do this on pull requests from forked repos you can use a private hosted build server. I created a <strong><a href=\"https://github.com/tomasbjerre/violation-comments-to-github-jenkins-plugin\">Jenkins plugin</a> that can be used for building pull requests from forked repositories</strong>. You may also use the <a href=\"https://github.com/tomasbjerre/violation-comments-to-github-maven-plugin\">Maven plugin</a> or <a href=\"https://github.com/tomasbjerre/violation-comments-to-github-gradle-plugin\">Gradle plugin</a> for that.</p>\n<p>Here is how to set it up in Travis.</p>\n<h1 id=\"travissetup\">Travis setup</h1>\n<p>You need to have a user that is allowed to post comments on the pull request. You may use the users username and password, or an OAuth2 token. I will use OAuth2 token in this example. Here is how to create it:</p>\n<p><code>curl -u 'yourgithubuser' -d '{&quot;note&quot;:&quot;Violation comments&quot;}' https://api.github.com/authorizations</code></p>\n<p>It will prompt for you password and give you back the token.</p>\n<p>You need to add it to <code>.travis.yml</code>. Travis provides a nice tool for encrypting the token:</p>\n<pre><code>sudo apt-get install ruby-dev\ngem install travis\ntravis encrypt export GITHUB_OAUTH2TOKEN=YOUR TOKEN HERE\n</code></pre>\n<p>Add the encrypted token to your <code>.travis.yml</code> under env. I'm including the Gradle task here also:</p>\n<pre><code>sudo: false\nlanguage: java\nenv:\n  - secure: &quot;YOUR ENCRYPTED TOKEN HERE&quot;\njdk:\n  - oraclejdk7\nscript:\n  - ./gradlew build violationCommentsToGitHub -DGITHUB_PULLREQUESTID=$TRAVIS_PULL_REQUEST -DGITHUB_OAUTH2TOKEN=$GITHUB_OAUTH2TOKEN -i --stacktrace\nnotifications:\n  email: false\n</code></pre>\n<p>Now you need to edit your <code>build.gradle</code> to include the plugin. As mentioned above, there is also a <a href=\"https://github.com/tomasbjerre/violation-comments-to-github-maven-plugin\">Maven plugin</a> with the exact same functionality. This blog post may not be up to date, so best is to check <a href=\"https://github.com/tomasbjerre/violation-comments-to-github-gradle-plugin\">Gradle plugin</a> for latest version and config. But here is an example:</p>\n<pre><code>  buildscript {\n    repositories {\n      maven {\n        url &quot;https://plugins.gradle.org/m2/&quot;\n      }\n    }\n    dependencies {\n      classpath &quot;se.bjurr.violations:violation-comments-to-github-gradle-plugin:1.1&quot;\n    }\n  }\n\n  apply plugin: &quot;se.bjurr.violations.violation-comments-to-github-gradle-plugin&quot;\n\n  task violationCommentsToGitHub(type: se.bjurr.violations.comments.github.plugin.gradle.ViolationCommentsToGitHubTask) {\n   repositoryOwner = &quot;tomasbjerre&quot;;\n   repositoryName = &quot;violations-test&quot;\n   pullRequestId = System.properties['GITHUB_PULLREQUESTID']\n   username = System.properties['GITHUB_USERNAME']\n   password = System.properties['GITHUB_PASSWORD']\n   oAuth2Token = System.properties['GITHUB_OAUTH2TOKEN']\n   gitHubUrl = &quot;https://api.github.com/&quot;\n   createCommentWithAllSingleFileComments = false\n   createSingleFileComments = true\n   violations = [\n    [&quot;FINDBUGS&quot;,   &quot;.&quot;, &quot;.*/findbugs/.*\\\\.xml\\$&quot;],\n    [&quot;PMD&quot;,        &quot;.&quot;, &quot;.*/pmd/.*\\\\.xml\\$&quot;],\n    [&quot;CHECKSTYLE&quot;, &quot;.&quot;, &quot;.*/checkstyle/.*\\\\.xml\\$&quot;],\n    [&quot;JSHINT&quot;,     &quot;.&quot;, &quot;.*/jshint/.*\\\\.xml\\$&quot;],\n    [&quot;CSSLINT&quot;,    &quot;.&quot;, &quot;.*/csslint/.*\\\\.xml\\$&quot;]\n   ]\n  }\n</code></pre>\n<p>Now all you need to do is to add the task to the build script, as you saw above, you need this:</p>\n<pre><code> script:\n  - ./gradlew build violationCommentsToGitHub -DGITHUB_PULLREQUESTID=$TRAVIS_PULL_REQUEST -DGITHUB_OAUTH2TOKEN=$GITHUB_OAUTH2TOKEN -i\n</code></pre>\n","comment_id":"24","plaintext":"I previously wrote about Violation Comments to Bitbucket Server\n[https://wiki.jenkins-ci.org/display/JENKINS/Violation+Comments+to+Bitbucket+Server+Plugin] \n plugin for Jenkins. I wanted to do the same thing with GitHub and Travis, here\nis the result.\n\n\n\nYou may also have a look at violations-test\n[https://github.com/tomasbjerre/violations-test/pull/2]  repo where I have a\nlive demo of this.\n\nEvery time I push to a pull request, or its target branch, Travis will perform\nstatic code analysis and report back to GitHub. I created a Maven plugin\n[https://github.com/tomasbjerre/violation-comments-to-github-maven-plugin]  and \nGradle plugin\n[https://github.com/tomasbjerre/violation-comments-to-github-gradle-plugin]  to\nmake this possible. I also created a Jenkins plugin\n[https://github.com/jenkinsci/violation-comments-to-github-jenkins-plugin].\n\nIt supports same format as violations-lib\n[https://github.com/tomasbjerre/violations-lib]:\n\n * Checkstyle [http://checkstyle.sourceforge.net/]\n * CPPLint [https://github.com/theandrewdavis/cpplint]\n * CPPCheck [http://cppcheck.sourceforge.net/]\n * CSSLint [https://github.com/CSSLint/csslint]\n * Findbugs [http://findbugs.sourceforge.net/]\n * Flake8 [http://flake8.readthedocs.org/en/latest/]  (PyLint\n   [https://www.pylint.org/], Pep8 [https://github.com/PyCQA/pycodestyle])\n * JSHint [http://jshint.com/]\n * Lint  A common XML format, used by different linters.\n * PerlCritic [https://github.com/Perl-Critic]\n * PMD [https://pmd.github.io/]\n * ReSharper [https://www.jetbrains.com/resharper/]\n * XMLLint [http://xmlsoft.org/xmllint.html]\n\nMany more formats are planned and pull requests\n[https://github.com/tomasbjerre/violations-lib]  are very welcome!\n\nThis will not work in Travis for pull requests from forked repositories. But \nwill work great with Travis for internal pull requests. But that is a limitation\nin Travis, not in the plugins  used for reporting. So if you want to do this on\npull requests from forked repos you can use a private hosted build server. I\ncreated a Jenkins plugin\n[https://github.com/tomasbjerre/violation-comments-to-github-jenkins-plugin] \nthat can be used for building pull requests from forked repositories. You may\nalso use the Maven plugin\n[https://github.com/tomasbjerre/violation-comments-to-github-maven-plugin]  or \nGradle plugin\n[https://github.com/tomasbjerre/violation-comments-to-github-gradle-plugin]  for\nthat.\n\nHere is how to set it up in Travis.\n\nTravis setup\nYou need to have a user that is allowed to post comments on the pull request.\nYou may use the users username and password, or an OAuth2 token. I will use\nOAuth2 token in this example. Here is how to create it:\n\ncurl -u 'yourgithubuser' -d '{\"note\":\"Violation comments\"}'\nhttps://api.github.com/authorizations\n\nIt will prompt for you password and give you back the token.\n\nYou need to add it to .travis.yml. Travis provides a nice tool for encrypting\nthe token:\n\nsudo apt-get install ruby-dev\ngem install travis\ntravis encrypt export GITHUB_OAUTH2TOKEN=YOUR TOKEN HERE\n\n\nAdd the encrypted token to your .travis.yml  under env. I'm including the Gradle\ntask here also:\n\nsudo: false\nlanguage: java\nenv:\n  - secure: \"YOUR ENCRYPTED TOKEN HERE\"\njdk:\n  - oraclejdk7\nscript:\n  - ./gradlew build violationCommentsToGitHub -DGITHUB_PULLREQUESTID=$TRAVIS_PULL_REQUEST -DGITHUB_OAUTH2TOKEN=$GITHUB_OAUTH2TOKEN -i --stacktrace\nnotifications:\n  email: false\n\n\nNow you need to edit your build.gradle  to include the plugin. As mentioned\nabove, there is also a Maven plugin\n[https://github.com/tomasbjerre/violation-comments-to-github-maven-plugin]  with\nthe exact same functionality. This blog post may not be up to date, so best is\nto check Gradle plugin\n[https://github.com/tomasbjerre/violation-comments-to-github-gradle-plugin]  for\nlatest version and config. But here is an example:\n\n  buildscript {\n    repositories {\n      maven {\n        url \"https://plugins.gradle.org/m2/\"\n      }\n    }\n    dependencies {\n      classpath \"se.bjurr.violations:violation-comments-to-github-gradle-plugin:1.1\"\n    }\n  }\n\n  apply plugin: \"se.bjurr.violations.violation-comments-to-github-gradle-plugin\"\n\n  task violationCommentsToGitHub(type: se.bjurr.violations.comments.github.plugin.gradle.ViolationCommentsToGitHubTask) {\n   repositoryOwner = \"tomasbjerre\";\n   repositoryName = \"violations-test\"\n   pullRequestId = System.properties['GITHUB_PULLREQUESTID']\n   username = System.properties['GITHUB_USERNAME']\n   password = System.properties['GITHUB_PASSWORD']\n   oAuth2Token = System.properties['GITHUB_OAUTH2TOKEN']\n   gitHubUrl = \"https://api.github.com/\"\n   createCommentWithAllSingleFileComments = false\n   createSingleFileComments = true\n   violations = [\n    [\"FINDBUGS\",   \".\", \".*/findbugs/.*\\\\.xml\\$\"],\n    [\"PMD\",        \".\", \".*/pmd/.*\\\\.xml\\$\"],\n    [\"CHECKSTYLE\", \".\", \".*/checkstyle/.*\\\\.xml\\$\"],\n    [\"JSHINT\",     \".\", \".*/jshint/.*\\\\.xml\\$\"],\n    [\"CSSLINT\",    \".\", \".*/csslint/.*\\\\.xml\\$\"]\n   ]\n  }\n\n\nNow all you need to do is to add the task to the build script, as you saw above,\nyou need this:\n\n script:\n  - ./gradlew build violationCommentsToGitHub -DGITHUB_PULLREQUESTID=$TRAVIS_PULL_REQUEST -DGITHUB_OAUTH2TOKEN=$GITHUB_OAUTH2TOKEN -i","feature_image":"/content/images/2018/02/GitHub-Mark.png","featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2016-03-04T21:01:59.000Z","created_by":"1","updated_at":"2018-02-24T09:10:30.000Z","updated_by":"1","published_at":"2016-03-04T21:30:58.000Z","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"custom_template":null},{"id":"597b4433e521cb4fbd9186a3","uuid":"3cc02964-4f5d-417d-89f5-85ded3b9ba07","title":"Clean invocations of dirty methods","slug":"clean-invocations-of-dirty-methods","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"I recently started to implement a [client for a REST API](https://github.com/tomasbjerre/bitbucket-server-java-client). I was using [RetroFit](http://square.github.io/retrofit/) and here is one the resources used by the client.\\n```\\npublic interface BitBucketServerService {\\n @GET(\\\"/rest/api/1.0/projects/{projectkey}/repos/{repositoryslug}/pull-requests?direction={direction}&at={at}&state={state}&order={order}&withattributes={withattributes}&withproperties={withproperties}\\\")\\n Call<BitbucketServerResponse<BitBucketServerPullRequest>> pullRequests(//\\n   @Query(\\\"projectkey\\\") String projectKey,//\\n   @Query(\\\"repositoryslug\\\") String repositoryslug,//\\n   @Query(\\\"direction\\\") String direction,//\\n   @Query(\\\"at\\\") Integer at,//\\n   @Query(\\\"state\\\") String state,//\\n   @Query(\\\"order\\\") String order,//\\n   @Query(\\\"withattributes\\\") boolean withattributes,//\\n   @Query(\\\"withproperties\\\") boolean withproperties);\\n}\\n```\\n\\nThe problem here is that calls to this service will be dirty. Alot of parameters in each invocation. Alot of strings that can accidentally be added in the wrong order. So just for comparison, here is an invocation of that service.\\n```\\nbitBucketServerService //\\n .pullRequests(\\\"projectKey\\\", \\\"repositoryslug\\\", \\\"direction\\\", 1, \\\"state\\\", \\\"order\\\", true, true);\\n```\\n\\nI created [Java Method Invocation Builder](https://github.com/tomasbjerre/java-method-invocation-builder). It adds the `@GenerateMethodInvocationBuilder` and also `@Default`. They are added to an interface, or class. It enables default values of method parameters  in Java and is making the invocations readable.\\n\\n```\\n@GenerateMethodInvocationBuilder\\npublic interface BitBucketServerService {\\n @GET(\\\"/rest/api/1.0/projects/{projectkey}/repos/{repositoryslug}/pull-requests?direction={direction}&at={at}&state={state}&order={order}&withattributes={withattributes}&withproperties={withproperties}\\\")\\n Call<BitbucketServerResponse<BitBucketServerPullRequest>> pullRequests(//\\n   @Query(\\\"projectkey\\\") String projectKey,//\\n   @Query(\\\"repositoryslug\\\") String repositoryslug,//\\n   @Default(\\\"INCOMING\\\") @Query(\\\"direction\\\") String direction,//\\n   @Query(\\\"at\\\") Integer at,//\\n   @Default(\\\"OPEN\\\") @Query(\\\"state\\\") String state,//\\n   @Default(\\\"NEWEST\\\") @Query(\\\"order\\\") String order,//\\n   @Default(\\\"true\\\") @Query(\\\"withattributes\\\") boolean withattributes,//\\n   @Default(\\\"true\\\") @Query(\\\"withproperties\\\") boolean withproperties);\\n}\\n```\\n\\n[Java Method Invocation Builder](https://github.com/tomasbjerre/java-method-invocation-builder) will generate builders for invoking every method in the **interface**, **or class**. So that the invoking code can look like this instead.\\n\\n```\\n  BitBucketServerServicePullRequestsBuilder.pullRequests()//\\n    .withProjectKey(\\\"projectKey\\\")//\\n    .withRepositoryslug(\\\"repositoryslug\\\")//\\n    .withAt(123)//\\n    .invoke(bitBucketServerService);\\n```\\n\\nThe code is generated as Java files at compile time. I created [Maven](https://github.com/tomasbjerre/java-method-invocation-builder/tree/master/example-maven) and [Gradle](https://github.com/tomasbjerre/java-method-invocation-builder/tree/master/example-gradle) examples to show how to use it.\\n\\n![Example](/content/images/2016/06/example_usage.png)\\n\"}]],\"sections\":[[10,0]]}","html":"<p>I recently started to implement a <a href=\"https://github.com/tomasbjerre/bitbucket-server-java-client\">client for a REST API</a>. I was using <a href=\"http://square.github.io/retrofit/\">RetroFit</a> and here is one the resources used by the client.</p>\n<pre><code>public interface BitBucketServerService {\n @GET(&quot;/rest/api/1.0/projects/{projectkey}/repos/{repositoryslug}/pull-requests?direction={direction}&amp;at={at}&amp;state={state}&amp;order={order}&amp;withattributes={withattributes}&amp;withproperties={withproperties}&quot;)\n Call&lt;BitbucketServerResponse&lt;BitBucketServerPullRequest&gt;&gt; pullRequests(//\n   @Query(&quot;projectkey&quot;) String projectKey,//\n   @Query(&quot;repositoryslug&quot;) String repositoryslug,//\n   @Query(&quot;direction&quot;) String direction,//\n   @Query(&quot;at&quot;) Integer at,//\n   @Query(&quot;state&quot;) String state,//\n   @Query(&quot;order&quot;) String order,//\n   @Query(&quot;withattributes&quot;) boolean withattributes,//\n   @Query(&quot;withproperties&quot;) boolean withproperties);\n}\n</code></pre>\n<p>The problem here is that calls to this service will be dirty. Alot of parameters in each invocation. Alot of strings that can accidentally be added in the wrong order. So just for comparison, here is an invocation of that service.</p>\n<pre><code>bitBucketServerService //\n .pullRequests(&quot;projectKey&quot;, &quot;repositoryslug&quot;, &quot;direction&quot;, 1, &quot;state&quot;, &quot;order&quot;, true, true);\n</code></pre>\n<p>I created <a href=\"https://github.com/tomasbjerre/java-method-invocation-builder\">Java Method Invocation Builder</a>. It adds the <code>@GenerateMethodInvocationBuilder</code> and also <code>@Default</code>. They are added to an interface, or class. It enables default values of method parameters  in Java and is making the invocations readable.</p>\n<pre><code>@GenerateMethodInvocationBuilder\npublic interface BitBucketServerService {\n @GET(&quot;/rest/api/1.0/projects/{projectkey}/repos/{repositoryslug}/pull-requests?direction={direction}&amp;at={at}&amp;state={state}&amp;order={order}&amp;withattributes={withattributes}&amp;withproperties={withproperties}&quot;)\n Call&lt;BitbucketServerResponse&lt;BitBucketServerPullRequest&gt;&gt; pullRequests(//\n   @Query(&quot;projectkey&quot;) String projectKey,//\n   @Query(&quot;repositoryslug&quot;) String repositoryslug,//\n   @Default(&quot;INCOMING&quot;) @Query(&quot;direction&quot;) String direction,//\n   @Query(&quot;at&quot;) Integer at,//\n   @Default(&quot;OPEN&quot;) @Query(&quot;state&quot;) String state,//\n   @Default(&quot;NEWEST&quot;) @Query(&quot;order&quot;) String order,//\n   @Default(&quot;true&quot;) @Query(&quot;withattributes&quot;) boolean withattributes,//\n   @Default(&quot;true&quot;) @Query(&quot;withproperties&quot;) boolean withproperties);\n}\n</code></pre>\n<p><a href=\"https://github.com/tomasbjerre/java-method-invocation-builder\">Java Method Invocation Builder</a> will generate builders for invoking every method in the <strong>interface</strong>, <strong>or class</strong>. So that the invoking code can look like this instead.</p>\n<pre><code>  BitBucketServerServicePullRequestsBuilder.pullRequests()//\n    .withProjectKey(&quot;projectKey&quot;)//\n    .withRepositoryslug(&quot;repositoryslug&quot;)//\n    .withAt(123)//\n    .invoke(bitBucketServerService);\n</code></pre>\n<p>The code is generated as Java files at compile time. I created <a href=\"https://github.com/tomasbjerre/java-method-invocation-builder/tree/master/example-maven\">Maven</a> and <a href=\"https://github.com/tomasbjerre/java-method-invocation-builder/tree/master/example-gradle\">Gradle</a> examples to show how to use it.</p>\n<p><img src=\"/content/images/2016/06/example_usage.png\" alt=\"Example\"></p>\n","comment_id":"25","plaintext":"I recently started to implement a client for a REST API\n[https://github.com/tomasbjerre/bitbucket-server-java-client]. I was using \nRetroFit [http://square.github.io/retrofit/]  and here is one the resources used\nby the client.\n\npublic interface BitBucketServerService {\n @GET(\"/rest/api/1.0/projects/{projectkey}/repos/{repositoryslug}/pull-requests?direction={direction}&at={at}&state={state}&order={order}&withattributes={withattributes}&withproperties={withproperties}\")\n Call<BitbucketServerResponse<BitBucketServerPullRequest>> pullRequests(//\n   @Query(\"projectkey\") String projectKey,//\n   @Query(\"repositoryslug\") String repositoryslug,//\n   @Query(\"direction\") String direction,//\n   @Query(\"at\") Integer at,//\n   @Query(\"state\") String state,//\n   @Query(\"order\") String order,//\n   @Query(\"withattributes\") boolean withattributes,//\n   @Query(\"withproperties\") boolean withproperties);\n}\n\n\nThe problem here is that calls to this service will be dirty. Alot of parameters\nin each invocation. Alot of strings that can accidentally be added in the wrong\norder. So just for comparison, here is an invocation of that service.\n\nbitBucketServerService //\n .pullRequests(\"projectKey\", \"repositoryslug\", \"direction\", 1, \"state\", \"order\", true, true);\n\n\nI created Java Method Invocation Builder\n[https://github.com/tomasbjerre/java-method-invocation-builder]. It adds the \n@GenerateMethodInvocationBuilder  and also @Default. They are added to an\ninterface, or class. It enables default values of method parameters in Java and\nis making the invocations readable.\n\n@GenerateMethodInvocationBuilder\npublic interface BitBucketServerService {\n @GET(\"/rest/api/1.0/projects/{projectkey}/repos/{repositoryslug}/pull-requests?direction={direction}&at={at}&state={state}&order={order}&withattributes={withattributes}&withproperties={withproperties}\")\n Call<BitbucketServerResponse<BitBucketServerPullRequest>> pullRequests(//\n   @Query(\"projectkey\") String projectKey,//\n   @Query(\"repositoryslug\") String repositoryslug,//\n   @Default(\"INCOMING\") @Query(\"direction\") String direction,//\n   @Query(\"at\") Integer at,//\n   @Default(\"OPEN\") @Query(\"state\") String state,//\n   @Default(\"NEWEST\") @Query(\"order\") String order,//\n   @Default(\"true\") @Query(\"withattributes\") boolean withattributes,//\n   @Default(\"true\") @Query(\"withproperties\") boolean withproperties);\n}\n\n\nJava Method Invocation Builder\n[https://github.com/tomasbjerre/java-method-invocation-builder]  will generate\nbuilders for invoking every method in the interface, or class. So that the\ninvoking code can look like this instead.\n\n  BitBucketServerServicePullRequestsBuilder.pullRequests()//\n    .withProjectKey(\"projectKey\")//\n    .withRepositoryslug(\"repositoryslug\")//\n    .withAt(123)//\n    .invoke(bitBucketServerService);\n\n\nThe code is generated as Java files at compile time. I created Maven\n[https://github.com/tomasbjerre/java-method-invocation-builder/tree/master/example-maven] \n and Gradle\n[https://github.com/tomasbjerre/java-method-invocation-builder/tree/master/example-gradle] \n examples to show how to use it.","feature_image":"/content/images/2018/02/java-1.png","featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2016-06-11T16:30:29.000Z","created_by":"1","updated_at":"2018-02-24T09:08:53.000Z","updated_by":"1","published_at":"2016-06-11T16:53:14.000Z","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"custom_template":null},{"id":"597b4433e521cb4fbd9186a4","uuid":"3fd3272e-d690-478c-b03e-742624228a64","title":"Continuous Integration with Bitbucket Server and Jenkins","slug":"continuous-integration-with-bitbucket-server-and-jenkins","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"I have started several projects where I develop plugins for Bitbucket Server and Jenkins. They are independent of each other but I thought it would be nice to have a blog post about how they can work together and on how I prefer to do continuous integration. This is it! =)\\n\\nWhat is the configuration that I apply?\\n\\n* [Gitflow](https://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow) workflow.\\n* Every commit, message and code, has to be reviewed before it can be merged.\\n* Every commit has to have an issue in its message.\\n* The size of the files that are put under version control cannot exceed 2000kb.\\n* The committer must use valid name and email in all commits.\\n* Changes can only be made with *feature branches* and merged with *pull requests*.\\n* *Pull requests* cannot be merged unless it its guaranteed that the target branch will still build after merge.\\n* *Pull requests* cannot be merged unless, at least, one other developer has reviewed it.\\n* *Static code analysis* will be made on every *pull request*.\\n\\nWhy do I apply this configuration?\\n\\n* **Git flow enables you to**\\n  * Use plugins for managing releases, like [JGit-Flow](https://bitbucket.org/atlassian/jgit-flow/wiki/Home).\\n  * Reduce time spent on documentation. You just need to refer to some [youtube-videos](https://www.youtube.com/results?search_query=git+flow) or [websites](http://lmgtfy.com/?q=git+flow).\\n  * Discuss any scenario on any public forum like [Stackoverflow](http://stackoverflow.com/search?q=git+flow).\\n  * Let a configuration manager have total control of *master* and *release*-branches. While developers have total control of *dev* and *feature*-branches.\\n  * Some people skip *dev* and use *master* as developer branch. I keep *dev* because when developing tools around GIT, its convenient to have a reference to latest release, *master*, and latest snapshot, *dev*. And since branches in git are basically just a file with a hash I think its a small price to pay for keeping it nice and tidy.\\n* **You will know exactly what is included in your releases**. The commits are reviewed, so you can trust that the message is true. Which means you can create your release notes by looking at the new commits in *dev* that are not yet merged to *master* (production). A special QA-jira is created to use for small fixes, like correcting toggling test case or formatting code.\\n* **You will make the code more maintainable and share knowledge among developers**. When tracking down a bug, the commit messages you find will be clear and understandable. Also the code will be cleaner from the reviews. Duplicated utility classes, diverging patterns... and so on will be denied.\\n* **You will never have a failing build on a shared branch**. Merge is only allowed, blocked by the Bitbucket Server, if it is guaranteed that target will still build after merge. Actually, if you have toggling test cases they can fail. But that should be found in code reviews.\\n* **Testers can pick a feature and try it out in a test environment before its merged to *dev***. By letting *Jenkins* perform the merge (without pushing), build the artifacts and deploy to an environment.\\n* **Your static code analysis will be honored**. You will see dramatically reduced amount of warnings from static code analysis. The developers will not be able to ignore such warnings (often the case with *Sonar*) as they will automatically be converted into comments on the code in the *pull request*.\\n* **Your repository will not quickly increase in size**. Remember that when you clone a Git repo you will download every version of everything. Its mostly a one time thing for a developer but something that a build server does several times a day. Once your repo has grown big its a bit of a pain getting rid of those large files.\\n\\nAnd finally, how do I apply the configuration? With Jenkins, Bitbucket Server (some of this is also possible to do if you are using GitHub) and plugins! I created a small [Docker Compose](https://github.com/tomasbjerre/jenkinsbitbucket) to help fiddle with this.\\n\\n# Bitbucket Server\\nThis is the Git repo that I use. It adds some things that Git does not have:\\n\\n* Authentication.\\n* Branch, repo and project permissions.\\n* Pull request support.\\n* Code review support.\\n* Alot of plugins.\\n\\nThe plugins I will use adds support for:\\n\\n * Commit checks with [Simple Bitbucket Server Commit Checker](https://marketplace.atlassian.com/plugins/se.bjurr.sscc.sscc/server/overview).\\n * Notifies Jenkins to perform verification of pull requests with [Pull Request Notifier for Bitbucket Server](https://marketplace.atlassian.com/plugins/se.bjurr.prnfs.pull-request-notifier-for-stash/server/overview).\\n * Synchronizing settings among repositories with [Settings Synchronizer for Bitbucket Server](https://marketplace.atlassian.com/plugins/se.bjurr.ssfb.settings-synchronizer-for-bitbucket/server/overview) \\n\\nYou can think about Git as an open database. Anyone can change anything. Anyone can add commits to any branch, with any author/committer name/email. It is very dangerous to collaborate around a repo that is not protected with a service like Bitbucket Server.\\n\\n## Simple Bitbucket Server Commit Checker\\nThis is one of my plugins. Its available for easy install from [Atlassian Marketplace](https://marketplace.atlassian.com/plugins/se.bjurr.sscc.sscc/server/overview) and is developed [on Github](https://github.com/tomasbjerre/simple-bitbucket-commit-checker).\\n\\nThe main reason why I developed this plugin was to allow custom rejection messages. The rejection messages also allows you to use variables so that you can reject a commit with a message saying exactly what the committer needs to do in order to fixup the commit. It also has a *dry run* mode where it only complains about the things that are not correct, but does not actually block the commit. It may be crucial to have such a feature if you introduce commit checks for 100+ committers.\\n\\n![Block committer emails not in Bitbucket Server](/content/images/2016/09/sscc-email.png)\\n\\nThe rejection messages are very clear.\\n\\n![Email rejected](/content/images/2016/09/sscc-reject.png)\\n\\nIt uses Jira:s [JQL](https://confluence.atlassian.com/jirasoftwarecloud/advanced-searching-764478330.html#Advancedsearching-ConstructingJQLqueries) to enable advanced and flexible validation of commit comments. It does not have to be an advanced query, simply adding `issue = ${REGEXP}` will validate that the Jiras exists.\\n\\n![JQL](/content/images/2016/09/sscc-issues.png)\\n\\nI use it to block commits:\\n\\n* Contains files that are too big, larger then 2000kb.\\n* Committer email or name does not match authenticated user in Bitbucket Server.\\n* Message does not contain an issue. Jira or custom incident pattern. I create a special issue in jira, a QA-jira, that can be use for small fixes. A small fix might be correcting toggling test case or formatting code.\\n\\n## Pull Request Notifier for Bitbucket Server\\nThis is one of my plugins. Its available for easy install from [Atlassian Marketplace](https://marketplace.atlassian.com/plugins/se.bjurr.prnfs.pull-request-notifier-for-stash/server/overview) and is developed [on Github](https://github.com/tomasbjerre/pull-request-notifier-for-bitbucket).\\n\\nIt invokes a URL when a pull request event happens in Bitbucket Server. The URL is completely customizable and supports variables so that you can notify any system with the information it needs on the format it needs it. \\n\\n![Pull Request Notifier for Bitbucket Server URL config](/content/images/2016/09/pull-request-notifier-url-config.png)\\n\\nThe main reason why I developed this plugin was to allow perfect verification of pull requests in Jenkins. But it is written in a way so that it is in no way limited to Jenkins. It basically just interacts with HTTP and can be used for many other purposes. I know people use it for posting updates regarding pull requests in Slack channels.\\n\\nIt enables you to guarantee that pull requests cannot be merged unless target branch will still build after the merge. If one of several pull requests to *dev* is merged, the plugin can re-trigger all other pull requests to verify them with the new commit that is now *dev*.\\n\\nIt adds support for *custom buttons* on pull request view. These buttons are mapped to a *notifications* (a URL being invoked). This means you can have a button labeled \\\"*Deploy to test env 1*\\\" and when it is pressed you trigger a job in Jenkins. The job is served with the feature branch of the pull request, builds the artifact and deploys it to that environment.\\n\\n![Pull Request Notifier for Bitbucket Server Button Config](/content/images/2016/09/prnfb-buttons.png)\\n\\nAnd in the pull request view you will see that button to the right, when clicking the dots.\\n\\n![Pull Request Notifier for Bitbucket Server Button In PR view](/content/images/2016/09/prnfb-button-pr-view.png)\\n\\nThe button will only be made visible if there is a configured notification that will actually trigger on the button being pressed. So make sure you add that also.\\n\\n![Pull Request Notifier for Bitucket Server Triggers](/content/images/2016/09/prnfb-triggers.png)\\n\\n## Settings Synchronizer for Bitbucket Server\\nThis is one of my plugins. Its available for easy install from [Atlassian Marketplace](https://marketplace.atlassian.com/plugins/se.bjurr.ssfb.settings-synchronizer-for-bitbucket/server/overview) and is developed [on Github](https://github.com/tomasbjerre/settings-synchronizer-for-bitbucket-plugin).\\n\\nIt is a bit of a pain to configure plugins for a 100, or even just a couple, of repositories. This plugin lets you synchronize plugin settings among your repositories.\\n\\n![Settings Synchronizer for Bitbucket Server](/content/images/2016/10/repoadmin.png)\\n\\n# Jenkins\\nThe build server that I use. Some say its just a glorified cron job. And yes thats pretty much it. The good thing about it is all the plugins. I dont think I would ever use it if it was not for the plugins.\\n\\nWhen I verify the pull requests I do it with a simple shell script build step.\\n\\n * From [Pull Request Notifier for Bitbucket Server](https://github.com/tomasbjerre/pull-request-notifier-for-bitbucket) I pass the `${EVERYTHING_URL}`.\\n * I check the job as parameterized and add the variables, used below, ass parameters.\\n * I check delay and set it to 0 seconds.\\n * I check allow parallel jobs.\\n\\nThe script is something like this.\\n\\n```\\ngit clone $PULL_REQUEST_TO_HTTP_CLONE_URL\\ncd *  \\ngit reset --hard $PULL_REQUEST_TO_HASH\\ngit status  \\ngit remote add from $PULL_REQUEST_FROM_HTTP_CLONE_URL\\ngit fetch --all\\ngit merge $PULL_REQUEST_FROM_HASH\\ngit --no-pager log --max-count=10 --graph --abbrev-commit\\n\\n#compile command here ...\\n```\\n\\n## Violation Comments to Bitbucket Server Plugin\\nThis is one of my Jenkins plugins. It is available in [Jenkins update sites](https://wiki.jenkins-ci.org/display/JENKINS/Violation+Comments+to+Bitbucket+Server+Plugin) and is developed [on Github](https://github.com/jenkinsci/violation-comments-to-stash-plugin). There is also a [Jenkins plugin for Github](https://wiki.jenkins-ci.org/display/JENKINS/Violation+Comments+to+Github+Plugin) if that is what you are using.\\n\\nMy opinion is that projects often put to much trust in that developers themselves will adhere to rules specified by static code analysis tools. They often trust that developers will have their IDE setup correctly to report problems. They also trust that developers will browse to [SonarQube](http://www.sonarqube.org/), every now and then, and find problems to fix. It is my strongest opinion that this never works. Some developers are really enthusiastic about it in the beginning but soon forgets to check for problems. Some never even cares in the first place. Commenting the pull requests with the problems found, makes them hard to ignore.\\n\\nWhen a pull request is verified, part of the verification is static code analysis. This plugin finds report files generated from that analysis and uses them to comment the pull request in Bitbucket Server.\\n\\n![Violation Comments to Bitbucket Server](/content/images/2016/09/screenshot-stash.png)\\n\\nThe post build action may look something like this.\\n\\n![Violation Comments to Bitbucket Server Post Build Action](/content/images/2016/09/violation-comments-to-bitbucket.png)\\n\\n## Git Changelog Plugin\\nThis is one of my Jenkins plugins. It is available in [Jenkins update sites](https://wiki.jenkins-ci.org/display/JENKINS/Git+Changelog+Plugin) and is developed [on Github](https://github.com/jenkinsci/git-changelog-plugin).\\n\\nThere may be several commits in the feature branch that is the source of the pull request. It may be an integration branch where developers has been working for weeks or even months. Then its very nice get a more organized view of what the feature branch actually contains.\\n\\n![Git Changelog Jenkins Plugin Configuration](/content/images/2016/09/git-changelog-postaction1.png)\\n\\nThis plugin is configured with a template and then creates a changelog where the template is rendered with the content of the feature branch.\\n\\n![Git Changelog Jenkins Plugin Template Configuration](/content/images/2016/09/git-changelog-postaction2.png)\\n\\nIt may look something like this if you chose to publish it on Jenkins job summary page. I used a Github repo here in the example because I dont have access to a Jira installation, but it works just the same with Jira! =)\\n\\n![Git Changelog Jenkins Summary](/content/images/2016/09/gitchangelog-prnfb-github.png)\\n\\nYou can also use this plugin to create release notes, just select *dev* as source branch and *master* as target branch. If you have a Jenkins job for *dev* then that is where to put that. It includes **integration with MediaWiki** so that releasenotes can be posted there. You can also chose to **create a file** where you are totally free to create a formatted HTML with CSS, or just plain text, the way you like it.\\n\\n## Stash Notifier Plugin\\nIt is available in [Jenkins update sites](https://wiki.jenkins-ci.org/display/JENKINS/StashNotifier+Plugin). It adds a post build step in Jenkns.\\n\\n![Post Build Step in Jenkins](/content/images/2016/09/stash-notifier-plugin.png)\\n\\nIt also reveals build status on Pull request view in Bitbucket Server.\\n\\n![Build status in Bitbucket Server](/content/images/2016/09/stash-notifier-in-bitbucket.png)\\n\\n# Conclusions\\nHope you found something useful here. Pull requests and suggested features are always welcome. Please dont email me directly but instead try to file issues on GitHub!\"}]],\"markups\":[],\"sections\":[[10,0]]}","html":"<p>I have started several projects where I develop plugins for Bitbucket Server and Jenkins. They are independent of each other but I thought it would be nice to have a blog post about how they can work together and on how I prefer to do continuous integration. This is it! =)</p>\n<p>What is the configuration that I apply?</p>\n<ul>\n<li><a href=\"https://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow\">Gitflow</a> workflow.</li>\n<li>Every commit, message and code, has to be reviewed before it can be merged.</li>\n<li>Every commit has to have an issue in its message.</li>\n<li>The size of the files that are put under version control cannot exceed 2000kb.</li>\n<li>The committer must use valid name and email in all commits.</li>\n<li>Changes can only be made with <em>feature branches</em> and merged with <em>pull requests</em>.</li>\n<li><em>Pull requests</em> cannot be merged unless it its guaranteed that the target branch will still build after merge.</li>\n<li><em>Pull requests</em> cannot be merged unless, at least, one other developer has reviewed it.</li>\n<li><em>Static code analysis</em> will be made on every <em>pull request</em>.</li>\n</ul>\n<p>Why do I apply this configuration?</p>\n<ul>\n<li><strong>Git flow enables you to</strong>\n<ul>\n<li>Use plugins for managing releases, like <a href=\"https://bitbucket.org/atlassian/jgit-flow/wiki/Home\">JGit-Flow</a>.</li>\n<li>Reduce time spent on documentation. You just need to refer to some <a href=\"https://www.youtube.com/results?search_query=git+flow\">youtube-videos</a> or <a href=\"http://lmgtfy.com/?q=git+flow\">websites</a>.</li>\n<li>Discuss any scenario on any public forum like <a href=\"http://stackoverflow.com/search?q=git+flow\">Stackoverflow</a>.</li>\n<li>Let a configuration manager have total control of <em>master</em> and <em>release</em>-branches. While developers have total control of <em>dev</em> and <em>feature</em>-branches.</li>\n<li>Some people skip <em>dev</em> and use <em>master</em> as developer branch. I keep <em>dev</em> because when developing tools around GIT, its convenient to have a reference to latest release, <em>master</em>, and latest snapshot, <em>dev</em>. And since branches in git are basically just a file with a hash I think its a small price to pay for keeping it nice and tidy.</li>\n</ul>\n</li>\n<li><strong>You will know exactly what is included in your releases</strong>. The commits are reviewed, so you can trust that the message is true. Which means you can create your release notes by looking at the new commits in <em>dev</em> that are not yet merged to <em>master</em> (production). A special QA-jira is created to use for small fixes, like correcting toggling test case or formatting code.</li>\n<li><strong>You will make the code more maintainable and share knowledge among developers</strong>. When tracking down a bug, the commit messages you find will be clear and understandable. Also the code will be cleaner from the reviews. Duplicated utility classes, diverging patterns... and so on will be denied.</li>\n<li><strong>You will never have a failing build on a shared branch</strong>. Merge is only allowed, blocked by the Bitbucket Server, if it is guaranteed that target will still build after merge. Actually, if you have toggling test cases they can fail. But that should be found in code reviews.</li>\n<li><strong>Testers can pick a feature and try it out in a test environment before its merged to <em>dev</em></strong>. By letting <em>Jenkins</em> perform the merge (without pushing), build the artifacts and deploy to an environment.</li>\n<li><strong>Your static code analysis will be honored</strong>. You will see dramatically reduced amount of warnings from static code analysis. The developers will not be able to ignore such warnings (often the case with <em>Sonar</em>) as they will automatically be converted into comments on the code in the <em>pull request</em>.</li>\n<li><strong>Your repository will not quickly increase in size</strong>. Remember that when you clone a Git repo you will download every version of everything. Its mostly a one time thing for a developer but something that a build server does several times a day. Once your repo has grown big its a bit of a pain getting rid of those large files.</li>\n</ul>\n<p>And finally, how do I apply the configuration? With Jenkins, Bitbucket Server (some of this is also possible to do if you are using GitHub) and plugins! I created a small <a href=\"https://github.com/tomasbjerre/jenkinsbitbucket\">Docker Compose</a> to help fiddle with this.</p>\n<h1 id=\"bitbucketserver\">Bitbucket Server</h1>\n<p>This is the Git repo that I use. It adds some things that Git does not have:</p>\n<ul>\n<li>Authentication.</li>\n<li>Branch, repo and project permissions.</li>\n<li>Pull request support.</li>\n<li>Code review support.</li>\n<li>Alot of plugins.</li>\n</ul>\n<p>The plugins I will use adds support for:</p>\n<ul>\n<li>Commit checks with <a href=\"https://marketplace.atlassian.com/plugins/se.bjurr.sscc.sscc/server/overview\">Simple Bitbucket Server Commit Checker</a>.</li>\n<li>Notifies Jenkins to perform verification of pull requests with <a href=\"https://marketplace.atlassian.com/plugins/se.bjurr.prnfs.pull-request-notifier-for-stash/server/overview\">Pull Request Notifier for Bitbucket Server</a>.</li>\n<li>Synchronizing settings among repositories with <a href=\"https://marketplace.atlassian.com/plugins/se.bjurr.ssfb.settings-synchronizer-for-bitbucket/server/overview\">Settings Synchronizer for Bitbucket Server</a></li>\n</ul>\n<p>You can think about Git as an open database. Anyone can change anything. Anyone can add commits to any branch, with any author/committer name/email. It is very dangerous to collaborate around a repo that is not protected with a service like Bitbucket Server.</p>\n<h2 id=\"simplebitbucketservercommitchecker\">Simple Bitbucket Server Commit Checker</h2>\n<p>This is one of my plugins. Its available for easy install from <a href=\"https://marketplace.atlassian.com/plugins/se.bjurr.sscc.sscc/server/overview\">Atlassian Marketplace</a> and is developed <a href=\"https://github.com/tomasbjerre/simple-bitbucket-commit-checker\">on Github</a>.</p>\n<p>The main reason why I developed this plugin was to allow custom rejection messages. The rejection messages also allows you to use variables so that you can reject a commit with a message saying exactly what the committer needs to do in order to fixup the commit. It also has a <em>dry run</em> mode where it only complains about the things that are not correct, but does not actually block the commit. It may be crucial to have such a feature if you introduce commit checks for 100+ committers.</p>\n<p><img src=\"/content/images/2016/09/sscc-email.png\" alt=\"Block committer emails not in Bitbucket Server\"></p>\n<p>The rejection messages are very clear.</p>\n<p><img src=\"/content/images/2016/09/sscc-reject.png\" alt=\"Email rejected\"></p>\n<p>It uses Jira:s <a href=\"https://confluence.atlassian.com/jirasoftwarecloud/advanced-searching-764478330.html#Advancedsearching-ConstructingJQLqueries\">JQL</a> to enable advanced and flexible validation of commit comments. It does not have to be an advanced query, simply adding <code>issue = ${REGEXP}</code> will validate that the Jiras exists.</p>\n<p><img src=\"/content/images/2016/09/sscc-issues.png\" alt=\"JQL\"></p>\n<p>I use it to block commits:</p>\n<ul>\n<li>Contains files that are too big, larger then 2000kb.</li>\n<li>Committer email or name does not match authenticated user in Bitbucket Server.</li>\n<li>Message does not contain an issue. Jira or custom incident pattern. I create a special issue in jira, a QA-jira, that can be use for small fixes. A small fix might be correcting toggling test case or formatting code.</li>\n</ul>\n<h2 id=\"pullrequestnotifierforbitbucketserver\">Pull Request Notifier for Bitbucket Server</h2>\n<p>This is one of my plugins. Its available for easy install from <a href=\"https://marketplace.atlassian.com/plugins/se.bjurr.prnfs.pull-request-notifier-for-stash/server/overview\">Atlassian Marketplace</a> and is developed <a href=\"https://github.com/tomasbjerre/pull-request-notifier-for-bitbucket\">on Github</a>.</p>\n<p>It invokes a URL when a pull request event happens in Bitbucket Server. The URL is completely customizable and supports variables so that you can notify any system with the information it needs on the format it needs it.</p>\n<p><img src=\"/content/images/2016/09/pull-request-notifier-url-config.png\" alt=\"Pull Request Notifier for Bitbucket Server URL config\"></p>\n<p>The main reason why I developed this plugin was to allow perfect verification of pull requests in Jenkins. But it is written in a way so that it is in no way limited to Jenkins. It basically just interacts with HTTP and can be used for many other purposes. I know people use it for posting updates regarding pull requests in Slack channels.</p>\n<p>It enables you to guarantee that pull requests cannot be merged unless target branch will still build after the merge. If one of several pull requests to <em>dev</em> is merged, the plugin can re-trigger all other pull requests to verify them with the new commit that is now <em>dev</em>.</p>\n<p>It adds support for <em>custom buttons</em> on pull request view. These buttons are mapped to a <em>notifications</em> (a URL being invoked). This means you can have a button labeled &quot;<em>Deploy to test env 1</em>&quot; and when it is pressed you trigger a job in Jenkins. The job is served with the feature branch of the pull request, builds the artifact and deploys it to that environment.</p>\n<p><img src=\"/content/images/2016/09/prnfb-buttons.png\" alt=\"Pull Request Notifier for Bitbucket Server Button Config\"></p>\n<p>And in the pull request view you will see that button to the right, when clicking the dots.</p>\n<p><img src=\"/content/images/2016/09/prnfb-button-pr-view.png\" alt=\"Pull Request Notifier for Bitbucket Server Button In PR view\"></p>\n<p>The button will only be made visible if there is a configured notification that will actually trigger on the button being pressed. So make sure you add that also.</p>\n<p><img src=\"/content/images/2016/09/prnfb-triggers.png\" alt=\"Pull Request Notifier for Bitucket Server Triggers\"></p>\n<h2 id=\"settingssynchronizerforbitbucketserver\">Settings Synchronizer for Bitbucket Server</h2>\n<p>This is one of my plugins. Its available for easy install from <a href=\"https://marketplace.atlassian.com/plugins/se.bjurr.ssfb.settings-synchronizer-for-bitbucket/server/overview\">Atlassian Marketplace</a> and is developed <a href=\"https://github.com/tomasbjerre/settings-synchronizer-for-bitbucket-plugin\">on Github</a>.</p>\n<p>It is a bit of a pain to configure plugins for a 100, or even just a couple, of repositories. This plugin lets you synchronize plugin settings among your repositories.</p>\n<p><img src=\"/content/images/2016/10/repoadmin.png\" alt=\"Settings Synchronizer for Bitbucket Server\"></p>\n<h1 id=\"jenkins\">Jenkins</h1>\n<p>The build server that I use. Some say its just a glorified cron job. And yes thats pretty much it. The good thing about it is all the plugins. I dont think I would ever use it if it was not for the plugins.</p>\n<p>When I verify the pull requests I do it with a simple shell script build step.</p>\n<ul>\n<li>From <a href=\"https://github.com/tomasbjerre/pull-request-notifier-for-bitbucket\">Pull Request Notifier for Bitbucket Server</a> I pass the <code>${EVERYTHING_URL}</code>.</li>\n<li>I check the job as parameterized and add the variables, used below, ass parameters.</li>\n<li>I check delay and set it to 0 seconds.</li>\n<li>I check allow parallel jobs.</li>\n</ul>\n<p>The script is something like this.</p>\n<pre><code>git clone $PULL_REQUEST_TO_HTTP_CLONE_URL\ncd *  \ngit reset --hard $PULL_REQUEST_TO_HASH\ngit status  \ngit remote add from $PULL_REQUEST_FROM_HTTP_CLONE_URL\ngit fetch --all\ngit merge $PULL_REQUEST_FROM_HASH\ngit --no-pager log --max-count=10 --graph --abbrev-commit\n\n#compile command here ...\n</code></pre>\n<h2 id=\"violationcommentstobitbucketserverplugin\">Violation Comments to Bitbucket Server Plugin</h2>\n<p>This is one of my Jenkins plugins. It is available in <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/Violation+Comments+to+Bitbucket+Server+Plugin\">Jenkins update sites</a> and is developed <a href=\"https://github.com/jenkinsci/violation-comments-to-stash-plugin\">on Github</a>. There is also a <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/Violation+Comments+to+Github+Plugin\">Jenkins plugin for Github</a> if that is what you are using.</p>\n<p>My opinion is that projects often put to much trust in that developers themselves will adhere to rules specified by static code analysis tools. They often trust that developers will have their IDE setup correctly to report problems. They also trust that developers will browse to <a href=\"http://www.sonarqube.org/\">SonarQube</a>, every now and then, and find problems to fix. It is my strongest opinion that this never works. Some developers are really enthusiastic about it in the beginning but soon forgets to check for problems. Some never even cares in the first place. Commenting the pull requests with the problems found, makes them hard to ignore.</p>\n<p>When a pull request is verified, part of the verification is static code analysis. This plugin finds report files generated from that analysis and uses them to comment the pull request in Bitbucket Server.</p>\n<p><img src=\"/content/images/2016/09/screenshot-stash.png\" alt=\"Violation Comments to Bitbucket Server\"></p>\n<p>The post build action may look something like this.</p>\n<p><img src=\"/content/images/2016/09/violation-comments-to-bitbucket.png\" alt=\"Violation Comments to Bitbucket Server Post Build Action\"></p>\n<h2 id=\"gitchangelogplugin\">Git Changelog Plugin</h2>\n<p>This is one of my Jenkins plugins. It is available in <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/Git+Changelog+Plugin\">Jenkins update sites</a> and is developed <a href=\"https://github.com/jenkinsci/git-changelog-plugin\">on Github</a>.</p>\n<p>There may be several commits in the feature branch that is the source of the pull request. It may be an integration branch where developers has been working for weeks or even months. Then its very nice get a more organized view of what the feature branch actually contains.</p>\n<p><img src=\"/content/images/2016/09/git-changelog-postaction1.png\" alt=\"Git Changelog Jenkins Plugin Configuration\"></p>\n<p>This plugin is configured with a template and then creates a changelog where the template is rendered with the content of the feature branch.</p>\n<p><img src=\"/content/images/2016/09/git-changelog-postaction2.png\" alt=\"Git Changelog Jenkins Plugin Template Configuration\"></p>\n<p>It may look something like this if you chose to publish it on Jenkins job summary page. I used a Github repo here in the example because I dont have access to a Jira installation, but it works just the same with Jira! =)</p>\n<p><img src=\"/content/images/2016/09/gitchangelog-prnfb-github.png\" alt=\"Git Changelog Jenkins Summary\"></p>\n<p>You can also use this plugin to create release notes, just select <em>dev</em> as source branch and <em>master</em> as target branch. If you have a Jenkins job for <em>dev</em> then that is where to put that. It includes <strong>integration with MediaWiki</strong> so that releasenotes can be posted there. You can also chose to <strong>create a file</strong> where you are totally free to create a formatted HTML with CSS, or just plain text, the way you like it.</p>\n<h2 id=\"stashnotifierplugin\">Stash Notifier Plugin</h2>\n<p>It is available in <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/StashNotifier+Plugin\">Jenkins update sites</a>. It adds a post build step in Jenkns.</p>\n<p><img src=\"/content/images/2016/09/stash-notifier-plugin.png\" alt=\"Post Build Step in Jenkins\"></p>\n<p>It also reveals build status on Pull request view in Bitbucket Server.</p>\n<p><img src=\"/content/images/2016/09/stash-notifier-in-bitbucket.png\" alt=\"Build status in Bitbucket Server\"></p>\n<h1 id=\"conclusions\">Conclusions</h1>\n<p>Hope you found something useful here. Pull requests and suggested features are always welcome. Please dont email me directly but instead try to file issues on GitHub!</p>\n","comment_id":"26","plaintext":"I have started several projects where I develop plugins for Bitbucket Server and\nJenkins. They are independent of each other but I thought it would be nice to\nhave a blog post about how they can work together and on how I prefer to do\ncontinuous integration. This is it! =)\n\nWhat is the configuration that I apply?\n\n * Gitflow\n   [https://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow] \n    workflow.\n * Every commit, message and code, has to be reviewed before it can be merged.\n * Every commit has to have an issue in its message.\n * The size of the files that are put under version control cannot exceed\n   2000kb.\n * The committer must use valid name and email in all commits.\n * Changes can only be made with feature branches  and merged with pull requests\n   .\n * Pull requests  cannot be merged unless it its guaranteed that the target\n   branch will still build after merge.\n * Pull requests  cannot be merged unless, at least, one other developer has\n   reviewed it.\n * Static code analysis  will be made on every pull request.\n\nWhy do I apply this configuration?\n\n * Git flow enables you to * Use plugins for managing releases, like JGit-Flow\n      [https://bitbucket.org/atlassian/jgit-flow/wiki/Home].\n    * Reduce time spent on documentation. You just need\n      to refer to some youtube-videos\n      [https://www.youtube.com/results?search_query=git+flow]  or websites\n      [http://lmgtfy.com/?q=git+flow].\n    * Discuss any scenario on any public forum like Stackoverflow\n      [http://stackoverflow.com/search?q=git+flow].\n    * Let a configuration manager have total control of master  and release\n      -branches. While developers have total control of dev  and feature\n      -branches.\n    * Some people skip dev  and use master  as developer branch. I keep dev \n      because when developing tools around GIT, its convenient to have a\n      reference to latest release, master, and latest snapshot, dev. And since\n      branches in git are basically just a file with a hash I think its a small\n      price to pay for keeping it nice and tidy.\n   \n   \n * You will know exactly what is included in your releases. The commits are\n   reviewed, so you can trust that the message is true. Which means you can\n   create your release notes by looking at the new commits in dev  that are not\n   yet merged to master  (production). A special QA-jira is created to use for\n   small fixes, like correcting toggling test case or formatting code.\n * You will make the code more maintainable and share knowledge among developers\n   . When tracking down a bug, the commit messages you find will be clear and\n   understandable. Also the code will be cleaner from the reviews. Duplicated\n   utility classes, diverging patterns... and so on will be denied.\n * You will never have a failing build on a shared branch. Merge is only\n   allowed, blocked by the Bitbucket Server, if it is guaranteed that target\n   will still build after merge. Actually, if you have toggling test cases they\n   can fail. But that should be found in code reviews.\n * Testers can pick a feature and try it out in a test environment before its\n   merged to dev. By letting Jenkins  perform the merge (without pushing), build\n   the artifacts and deploy to an environment.\n * Your static code analysis will be honored. You will see dramatically reduced\n   amount of warnings from static code analysis. The developers will not be able\n   to ignore such warnings (often the case with Sonar) as they will\n   automatically be converted into comments on the code in the pull request.\n * Your repository will not quickly increase in size. Remember that when you\n   clone a Git repo you will download every version of everything. Its mostly a\n   one time thing for a developer but something that a build server does several\n   times a day. Once your repo has grown big its a bit of a pain getting rid of\n   those large files.\n\nAnd finally, how do I apply the configuration? With Jenkins, Bitbucket Server\n(some of this is also possible to do if you are using GitHub) and plugins! I\ncreated a small Docker Compose [https://github.com/tomasbjerre/jenkinsbitbucket] \n to help fiddle with this.\n\nBitbucket Server\nThis is the Git repo that I use. It adds some things that Git does not have:\n\n * Authentication.\n * Branch, repo and project permissions.\n * Pull request support.\n * Code review support.\n * Alot of plugins.\n\nThe plugins I will use adds support for:\n\n * Commit checks with Simple Bitbucket Server Commit Checker\n   [https://marketplace.atlassian.com/plugins/se.bjurr.sscc.sscc/server/overview]\n   .\n * Notifies Jenkins to perform verification of pull requests with Pull Request\n   Notifier for Bitbucket Server\n   [https://marketplace.atlassian.com/plugins/se.bjurr.prnfs.pull-request-notifier-for-stash/server/overview]\n   .\n * Synchronizing settings among repositories with Settings Synchronizer for\n   Bitbucket Server\n   [https://marketplace.atlassian.com/plugins/se.bjurr.ssfb.settings-synchronizer-for-bitbucket/server/overview]\n\nYou can think about Git as an open database. Anyone can change anything. Anyone\ncan add commits to any branch, with any author/committer name/email. It is very\ndangerous to collaborate around a repo that is not protected with a service like\nBitbucket Server.\n\nSimple Bitbucket Server Commit Checker\nThis is one of my plugins. Its available for easy install from Atlassian\nMarketplace\n[https://marketplace.atlassian.com/plugins/se.bjurr.sscc.sscc/server/overview] \nand is developed on Github\n[https://github.com/tomasbjerre/simple-bitbucket-commit-checker].\n\nThe main reason why I developed this plugin was to allow custom rejection\nmessages. The rejection messages also allows you to use variables so that you\ncan reject a commit with a message saying exactly what the committer needs to do\nin order to fixup the commit. It also has a dry run  mode where it only\ncomplains about the things that are not correct, but does not actually block the\ncommit. It may be crucial to have such a feature if you introduce commit checks\nfor 100+ committers.\n\n\n\nThe rejection messages are very clear.\n\n\n\nIt uses Jira:s JQL  to enable advanced and flexible validation of commit\ncomments. It does not have to be an advanced query, simply adding issue =\n${REGEXP}  will validate that the Jiras exists.\n\n\n\nI use it to block commits:\n\n * Contains files that are too big, larger then 2000kb.\n * Committer email or name does not match authenticated user in Bitbucket\n   Server.\n * Message does not contain an issue. Jira or custom incident pattern. I create\n   a special issue in jira, a QA-jira, that can be use for small fixes. A small\n   fix might be correcting toggling test case or formatting code.\n\nPull Request Notifier for Bitbucket Server\nThis is one of my plugins. Its available for easy install from Atlassian\nMarketplace\n[https://marketplace.atlassian.com/plugins/se.bjurr.prnfs.pull-request-notifier-for-stash/server/overview] \n and is developed on Github\n[https://github.com/tomasbjerre/pull-request-notifier-for-bitbucket].\n\nIt invokes a URL when a pull request event happens in Bitbucket Server. The URL\nis completely customizable and supports variables so that you can notify any\nsystem with the information it needs on the format it needs it.\n\n\n\nThe main reason why I developed this plugin was to allow perfect verification of\npull requests in Jenkins. But it is written in a way so that it is in no way\nlimited to Jenkins. It basically just interacts with HTTP and can be used for\nmany other purposes. I know people use it for posting updates regarding pull\nrequests in Slack channels.\n\nIt enables you to guarantee that pull requests cannot be merged unless target\nbranch will still build after the merge. If one of several pull requests to dev \nis merged, the plugin can re-trigger all other pull requests to verify them with\nthe new commit that is now dev.\n\nIt adds support for custom buttons  on pull request view. These buttons are\nmapped to a notifications  (a URL being invoked). This means you can have a\nbutton labeled \"Deploy to test env 1\" and when it is pressed you trigger a job\nin Jenkins. The job is served with the feature branch of the pull request,\nbuilds the artifact and deploys it to that environment.\n\n\n\nAnd in the pull request view you will see that button to the right, when\nclicking the dots.\n\n\n\nThe button will only be made visible if there is a configured notification that\nwill actually trigger on the button being pressed. So make sure you add that\nalso.\n\n\n\nSettings Synchronizer for Bitbucket Server\nThis is one of my plugins. Its available for easy install from Atlassian\nMarketplace\n[https://marketplace.atlassian.com/plugins/se.bjurr.ssfb.settings-synchronizer-for-bitbucket/server/overview] \n and is developed on Github\n[https://github.com/tomasbjerre/settings-synchronizer-for-bitbucket-plugin].\n\nIt is a bit of a pain to configure plugins for a 100, or even just a couple, of\nrepositories. This plugin lets you synchronize plugin settings among your\nrepositories.\n\n\n\nJenkins\nThe build server that I use. Some say its just a glorified cron job. And yes\nthats pretty much it. The good thing about it is all the plugins. I dont think I\nwould ever use it if it was not for the plugins.\n\nWhen I verify the pull requests I do it with a simple shell script build step.\n\n * From Pull Request Notifier for Bitbucket Server\n   [https://github.com/tomasbjerre/pull-request-notifier-for-bitbucket]  I pass\n   the ${EVERYTHING_URL}.\n * I check the job as parameterized and add the variables, used below, ass\n   parameters.\n * I check delay and set it to 0 seconds.\n * I check allow parallel jobs.\n\nThe script is something like this.\n\ngit clone $PULL_REQUEST_TO_HTTP_CLONE_URL\ncd *  \ngit reset --hard $PULL_REQUEST_TO_HASH\ngit status  \ngit remote add from $PULL_REQUEST_FROM_HTTP_CLONE_URL\ngit fetch --all\ngit merge $PULL_REQUEST_FROM_HASH\ngit --no-pager log --max-count=10 --graph --abbrev-commit\n\n#compile command here ...\n\n\nViolation Comments to Bitbucket Server Plugin\nThis is one of my Jenkins plugins. It is available in Jenkins update sites\n[https://wiki.jenkins-ci.org/display/JENKINS/Violation+Comments+to+Bitbucket+Server+Plugin] \n and is developed on Github\n[https://github.com/jenkinsci/violation-comments-to-stash-plugin]. There is also\na Jenkins plugin for Github\n[https://wiki.jenkins-ci.org/display/JENKINS/Violation+Comments+to+Github+Plugin] \n if that is what you are using.\n\nMy opinion is that projects often put to much trust in that developers\nthemselves will adhere to rules specified by static code analysis tools. They\noften trust that developers will have their IDE setup correctly to report\nproblems. They also trust that developers will browse to SonarQube\n[http://www.sonarqube.org/], every now and then, and find problems to fix. It is\nmy strongest opinion that this never works. Some developers are really\nenthusiastic about it in the beginning but soon forgets to check for problems.\nSome never even cares in the first place. Commenting the pull requests with the\nproblems found, makes them hard to ignore.\n\nWhen a pull request is verified, part of the verification is static code\nanalysis. This plugin finds report files generated from that analysis and uses\nthem to comment the pull request in Bitbucket Server.\n\n\n\nThe post build action may look something like this.\n\n\n\nGit Changelog Plugin\nThis is one of my Jenkins plugins. It is available in Jenkins update sites\n[https://wiki.jenkins-ci.org/display/JENKINS/Git+Changelog+Plugin]  and is\ndeveloped on Github [https://github.com/jenkinsci/git-changelog-plugin].\n\nThere may be several commits in the feature branch that is the source of the\npull request. It may be an integration branch where developers has been working\nfor weeks or even months. Then its very nice get a more organized view of what\nthe feature branch actually contains.\n\n\n\nThis plugin is configured with a template and then creates a changelog where the\ntemplate is rendered with the content of the feature branch.\n\n\n\nIt may look something like this if you chose to publish it on Jenkins job\nsummary page. I used a Github repo here in the example because I dont have\naccess to a Jira installation, but it works just the same with Jira! =)\n\n\n\nYou can also use this plugin to create release notes, just select dev  as source\nbranch and master  as target branch. If you have a Jenkins job for dev  then\nthat is where to put that. It includes integration with MediaWiki  so that\nreleasenotes can be posted there. You can also chose to create a file  where you\nare totally free to create a formatted HTML with CSS, or just plain text, the\nway you like it.\n\nStash Notifier Plugin\nIt is available in Jenkins update sites\n[https://wiki.jenkins-ci.org/display/JENKINS/StashNotifier+Plugin]. It adds a\npost build step in Jenkns.\n\n\n\nIt also reveals build status on Pull request view in Bitbucket Server.\n\n\n\nConclusions\nHope you found something useful here. Pull requests and suggested features are\nalways welcome. Please dont email me directly but instead try to file issues on\nGitHub!","feature_image":"/content/images/2018/02/0722.sdt-atlassian.png","featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2016-09-07T17:17:25.000Z","created_by":"1","updated_at":"2018-08-31T05:51:39.000Z","updated_by":"1","published_at":"2016-09-10T08:07:34.000Z","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"custom_template":null},{"id":"597b4433e521cb4fbd9186a5","uuid":"3099c298-3f00-497a-86a9-67ad0789d172","title":"GitFlow and when you should use it","slug":"gitflow-and-when-you-should-use-it","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"There are a lot of people explaining [GitFlow](http://nvie.com/posts/a-successful-git-branching-model/) in different blog posts and videos. I could not find one that, using the correct arguments, explained what it is good for. These are my personal opinions and you don't have to agree =)\\n\\n*GitFlow* is really the simplest thing. Let's divide the people working with a project into 2 different roles, **developers** and **configuration manager(s)**, and look at what they do.\\n\\n# GitFlow as a developer\\nAs a **developer** you have 2 kinds of branches.\\n\\n * **develop** Integration branch. Refers to the *next release*.\\n * **feature/X** Feature branch where feature *X* is developed.\\n\\nYou may have **feature** branches that branch out of other **feature** branches. In order to, easily, collaborate with other developers on a larger feature. You may call that large feature branch, **integration** branch.\\n\\n* You should always merge code to **develop** as fast as you can. To spread commits quick and avoid merge conflicts.\\n* You should regularly *rebase*, or *merge*, **develop** into you **feature** branch. To base you code on the latest features and refactorings and avoid merge conflicts.\\n\\nTo work on the next release. You branch out of **develop**, work with the **feature**, merge back to **develop**.\\n\\n```\\n*    (develop)  Merge branch 'feature/work-with-correcting-a' into develop \\n|\\\\  \\n| *  (feature/work-with-correcting-a) Correcting a\\n|/  \\n*     Merge branch 'feature/work-with-a' into develop \\n|\\\\  \\n| *  (feature/work-with-a)  a \\n|/  \\n* \\n```\\n\\nTo work on the *next*-*next* release, or even further into the future, simply don't merge it back to **develop** before *next*-*next* is *next*. And keep in mind, it may be a good idea to merge it into **develop** earlier, to avoid merge conflicts, if you can do feature toggling.\\n\\nAs a **developer**, this is all there is to it! This is how **developers** most often prefer to work. Just look at any open source repository. Most often you fork the main repository and the **master** in your fork is your **feature** branch. But still, **this is as simple as it can get and this is how developers do it!**\\n\\n# GitFlow as a configuration manager\\nAs a **configuration manager** you have 2 kinds of branches.\\n\\n * **master** This is the what's in **production**.\\n * **release-X** This is what's included in **release** *X*.\\n\\nAs soon as it's *code freeze* it's time to create the first *release candidate*. That is done by branching out of **develop** into **release-X**. The version of **develop** is now set to 1.1, in Java that would mean changing the version to *1.1-SNAPSHOT* while in the release branch its still *1.0-SNAPSHOT*. The semantics of the versions is a side track, but I can recommend [this blog post](http://kylelieber.com/2012/06/maven-versioning-strategy/).\\n```\\n| *  (release-1, tag: 1.0-RC-1) Releasing RC 1\\n| *  Setting version to 1.0-RC1\\n* | (develop) Setting version to 1.1-SNAPSHOT\\n|/\\n```\\n\\nThe whole point of the **release-X** branch is to provide a *code freeze* for the release. The **developers** can continue their work exactly as described above. Most Git services allows you to define permissions per branch and only configuration managers should have permission to **release-X**.\\n\\nThe release candidate, *RC1*, is deployed and tested and if it's all good then it's released. But there is probably something that needs to be fixed. It can be done in different ways.\\n\\n* With *cherry-picking* from **develop**. \\nThis is the prettiest but it may also not be possible. Merge conflicts may hinder this. There is also a risk that the **develop**-branch is too far ahead making it hard to know if the fix will work once it's in the **release**-branch. But I feel that it gives the **configuration manager** the most control of the release process.\\n\\n* With merging a **feature**-branch that branches out of the **release**-branch.\\nThis often my preferred choice in large teams. It gives the **configuration manager** control of what's included in the release. It avoids risk of merge conflicts. The tests done on that **feature**-branch can be trusted. It can be done with pull requests.\\n\\n* With direct commits to the **release**-branch.\\nThis may fit a technical team where the **configuration manager** is also a **developer**. It provides a release process for the current release and enables the **developer** to work on the next release in **develop**. It lacks support for code review but you may not need that in a small project.\\n\\nHere is what it may look like if *cherry-picking* is used.\\n\\n```\\n| *  Setting version to 1.0-SNAPSHOT\\n| *  (release-1, tag: 1.0-RC-2) Releasing RC 2\\n| *  Setting version to 1.0-RC2\\n| *  Correcting a\\n| *  Setting version to 1.0-SNAPSHOT\\n| *  (tag: 1.0-RC-1) Releasing RC 1\\n| *  Setting version to 1.0-RC1\\n* | (develop) Setting version to 1.1-SNAPSHOT\\n|/\\n```\\n\\nNow if *RC2* is good and should be released then that exact artifact is deployed in production.\\n\\n* Released commit, **release-tag**, in **release-1** is merged into **master**.\\n    * To keep track of what is in production.\\n* **master** is merged into **develop**, this is important:\\n    * To make sure any changes made in production are also in the next release.\\n    * To allow a *fast-forward* of **master** next time you merge **release-tag** to **master**.\\n\\n#Conclusions\\n\\nI've shown the two roles in *GitFlow* and I hope I made it obvious that its actually a very simple workflow! It will not fit all projects.\\n\\nYou will probably **not gain from using *GitFLow*** in a library. That is just used by other software. Where a release is just a process of packaging an artifact an making it available for other software to use. You can probably just release a new version if something needs to be fixed later, and the users of the software can just keep using an older version until things are worked out.\\n\\nYou will probably **gain from using *GitFlow*** if you have a *code freeze*. It enables a *code freeze* without preventing developers from working on the next release.\\n\\nIf you just fire releases from *master*, without any branching, you can easily automate that process. If you need to make a release-branch and eventually merge it back into *master*, and *develop*, you will need a more complex flow. Which is a price you may not want to pay unless you are gaining something else from the flow!\"}]],\"sections\":[[10,0]]}","html":"<p>There are a lot of people explaining <a href=\"http://nvie.com/posts/a-successful-git-branching-model/\">GitFlow</a> in different blog posts and videos. I could not find one that, using the correct arguments, explained what it is good for. These are my personal opinions and you don't have to agree =)</p>\n<p><em>GitFlow</em> is really the simplest thing. Let's divide the people working with a project into 2 different roles, <strong>developers</strong> and <strong>configuration manager(s)</strong>, and look at what they do.</p>\n<h1 id=\"gitflowasadeveloper\">GitFlow as a developer</h1>\n<p>As a <strong>developer</strong> you have 2 kinds of branches.</p>\n<ul>\n<li><strong>develop</strong> Integration branch. Refers to the <em>next release</em>.</li>\n<li><strong>feature/X</strong> Feature branch where feature <em>X</em> is developed.</li>\n</ul>\n<p>You may have <strong>feature</strong> branches that branch out of other <strong>feature</strong> branches. In order to, easily, collaborate with other developers on a larger feature. You may call that large feature branch, <strong>integration</strong> branch.</p>\n<ul>\n<li>You should always merge code to <strong>develop</strong> as fast as you can. To spread commits quick and avoid merge conflicts.</li>\n<li>You should regularly <em>rebase</em>, or <em>merge</em>, <strong>develop</strong> into you <strong>feature</strong> branch. To base you code on the latest features and refactorings and avoid merge conflicts.</li>\n</ul>\n<p>To work on the next release. You branch out of <strong>develop</strong>, work with the <strong>feature</strong>, merge back to <strong>develop</strong>.</p>\n<pre><code>*    (develop)  Merge branch 'feature/work-with-correcting-a' into develop \n|\\  \n| *  (feature/work-with-correcting-a) Correcting a\n|/  \n*     Merge branch 'feature/work-with-a' into develop \n|\\  \n| *  (feature/work-with-a)  a \n|/  \n* \n</code></pre>\n<p>To work on the <em>next</em>-<em>next</em> release, or even further into the future, simply don't merge it back to <strong>develop</strong> before <em>next</em>-<em>next</em> is <em>next</em>. And keep in mind, it may be a good idea to merge it into <strong>develop</strong> earlier, to avoid merge conflicts, if you can do feature toggling.</p>\n<p>As a <strong>developer</strong>, this is all there is to it! This is how <strong>developers</strong> most often prefer to work. Just look at any open source repository. Most often you fork the main repository and the <strong>master</strong> in your fork is your <strong>feature</strong> branch. But still, <strong>this is as simple as it can get and this is how developers do it!</strong></p>\n<h1 id=\"gitflowasaconfigurationmanager\">GitFlow as a configuration manager</h1>\n<p>As a <strong>configuration manager</strong> you have 2 kinds of branches.</p>\n<ul>\n<li><strong>master</strong> This is the what's in <strong>production</strong>.</li>\n<li><strong>release-X</strong> This is what's included in <strong>release</strong> <em>X</em>.</li>\n</ul>\n<p>As soon as it's <em>code freeze</em> it's time to create the first <em>release candidate</em>. That is done by branching out of <strong>develop</strong> into <strong>release-X</strong>. The version of <strong>develop</strong> is now set to 1.1, in Java that would mean changing the version to <em>1.1-SNAPSHOT</em> while in the release branch its still <em>1.0-SNAPSHOT</em>. The semantics of the versions is a side track, but I can recommend <a href=\"http://kylelieber.com/2012/06/maven-versioning-strategy/\">this blog post</a>.</p>\n<pre><code>| *  (release-1, tag: 1.0-RC-1) Releasing RC 1\n| *  Setting version to 1.0-RC1\n* | (develop) Setting version to 1.1-SNAPSHOT\n|/\n</code></pre>\n<p>The whole point of the <strong>release-X</strong> branch is to provide a <em>code freeze</em> for the release. The <strong>developers</strong> can continue their work exactly as described above. Most Git services allows you to define permissions per branch and only configuration managers should have permission to <strong>release-X</strong>.</p>\n<p>The release candidate, <em>RC1</em>, is deployed and tested and if it's all good then it's released. But there is probably something that needs to be fixed. It can be done in different ways.</p>\n<ul>\n<li>\n<p>With <em>cherry-picking</em> from <strong>develop</strong>.<br>\nThis is the prettiest but it may also not be possible. Merge conflicts may hinder this. There is also a risk that the <strong>develop</strong>-branch is too far ahead making it hard to know if the fix will work once it's in the <strong>release</strong>-branch. But I feel that it gives the <strong>configuration manager</strong> the most control of the release process.</p>\n</li>\n<li>\n<p>With merging a <strong>feature</strong>-branch that branches out of the <strong>release</strong>-branch.<br>\nThis often my preferred choice in large teams. It gives the <strong>configuration manager</strong> control of what's included in the release. It avoids risk of merge conflicts. The tests done on that <strong>feature</strong>-branch can be trusted. It can be done with pull requests.</p>\n</li>\n<li>\n<p>With direct commits to the <strong>release</strong>-branch.<br>\nThis may fit a technical team where the <strong>configuration manager</strong> is also a <strong>developer</strong>. It provides a release process for the current release and enables the <strong>developer</strong> to work on the next release in <strong>develop</strong>. It lacks support for code review but you may not need that in a small project.</p>\n</li>\n</ul>\n<p>Here is what it may look like if <em>cherry-picking</em> is used.</p>\n<pre><code>| *  Setting version to 1.0-SNAPSHOT\n| *  (release-1, tag: 1.0-RC-2) Releasing RC 2\n| *  Setting version to 1.0-RC2\n| *  Correcting a\n| *  Setting version to 1.0-SNAPSHOT\n| *  (tag: 1.0-RC-1) Releasing RC 1\n| *  Setting version to 1.0-RC1\n* | (develop) Setting version to 1.1-SNAPSHOT\n|/\n</code></pre>\n<p>Now if <em>RC2</em> is good and should be released then that exact artifact is deployed in production.</p>\n<ul>\n<li>Released commit, <strong>release-tag</strong>, in <strong>release-1</strong> is merged into <strong>master</strong>.\n<ul>\n<li>To keep track of what is in production.</li>\n</ul>\n</li>\n<li><strong>master</strong> is merged into <strong>develop</strong>, this is important:\n<ul>\n<li>To make sure any changes made in production are also in the next release.</li>\n<li>To allow a <em>fast-forward</em> of <strong>master</strong> next time you merge <strong>release-tag</strong> to <strong>master</strong>.</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"conclusions\">Conclusions</h1>\n<p>I've shown the two roles in <em>GitFlow</em> and I hope I made it obvious that its actually a very simple workflow! It will not fit all projects.</p>\n<p>You will probably <strong>not gain from using <em>GitFLow</em></strong> in a library. That is just used by other software. Where a release is just a process of packaging an artifact an making it available for other software to use. You can probably just release a new version if something needs to be fixed later, and the users of the software can just keep using an older version until things are worked out.</p>\n<p>You will probably <strong>gain from using <em>GitFlow</em></strong> if you have a <em>code freeze</em>. It enables a <em>code freeze</em> without preventing developers from working on the next release.</p>\n<p>If you just fire releases from <em>master</em>, without any branching, you can easily automate that process. If you need to make a release-branch and eventually merge it back into <em>master</em>, and <em>develop</em>, you will need a more complex flow. Which is a price you may not want to pay unless you are gaining something else from the flow!</p>\n","comment_id":"27","plaintext":"There are a lot of people explaining GitFlow\n[http://nvie.com/posts/a-successful-git-branching-model/]  in different blog\nposts and videos. I could not find one that, using the correct arguments,\nexplained what it is good for. These are my personal opinions and you don't have\nto agree =)\n\nGitFlow  is really the simplest thing. Let's divide the people working with a\nproject into 2 different roles, developers  and configuration manager(s), and\nlook at what they do.\n\nGitFlow as a developer\nAs a developer  you have 2 kinds of branches.\n\n * develop  Integration branch. Refers to the next release.\n * feature/X  Feature branch where feature X  is developed.\n\nYou may have feature  branches that branch out of other feature  branches. In\norder to, easily, collaborate with other developers on a larger feature. You may\ncall that large feature branch, integration  branch.\n\n * You should always merge code to develop  as fast as you can. To spread\n   commits quick and avoid merge conflicts.\n * You should regularly rebase, or merge, develop  into you feature  branch. To\n   base you code on the latest features and refactorings and avoid merge\n   conflicts.\n\nTo work on the next release. You branch out of develop, work with the feature,\nmerge back to develop.\n\n*    (develop)  Merge branch 'feature/work-with-correcting-a' into develop \n|\\  \n| *  (feature/work-with-correcting-a) Correcting a\n|/  \n*     Merge branch 'feature/work-with-a' into develop \n|\\  \n| *  (feature/work-with-a)  a \n|/  \n* \n\n\nTo work on the next-next  release, or even further into the future, simply don't\nmerge it back to develop  before next-next  is next. And keep in mind, it may be\na good idea to merge it into develop  earlier, to avoid merge conflicts, if you\ncan do feature toggling.\n\nAs a developer, this is all there is to it! This is how developers  most often\nprefer to work. Just look at any open source repository. Most often you fork the\nmain repository and the master  in your fork is your feature  branch. But still,\n this is as simple as it can get and this is how developers do it!\n\nGitFlow as a configuration manager\nAs a configuration manager  you have 2 kinds of branches.\n\n * master  This is the what's in production.\n * release-X  This is what's included in release  X.\n\nAs soon as it's code freeze  it's time to create the first release candidate.\nThat is done by branching out of develop  into release-X. The version of develop \n is now set to 1.1, in Java that would mean changing the version to 1.1-SNAPSHOT \n while in the release branch its still 1.0-SNAPSHOT. The semantics of the\nversions is a side track, but I can recommend this blog post\n[http://kylelieber.com/2012/06/maven-versioning-strategy/].\n\n| *  (release-1, tag: 1.0-RC-1) Releasing RC 1\n| *  Setting version to 1.0-RC1\n* | (develop) Setting version to 1.1-SNAPSHOT\n|/\n\n\nThe whole point of the release-X  branch is to provide a code freeze  for the\nrelease. The developers  can continue their work exactly as described above.\nMost Git services allows you to define permissions per branch and only\nconfiguration managers should have permission to release-X.\n\nThe release candidate, RC1, is deployed and tested and if it's all good then\nit's released. But there is probably something that needs to be fixed. It can be\ndone in different ways.\n\n * With cherry-picking  from develop.\n   This is the prettiest but it may also not be possible. Merge conflicts may\n   hinder this. There is also a risk that the develop-branch is too far ahead\n   making it hard to know if the fix will work once it's in the release-branch.\n   But I feel that it gives the configuration manager  the most control of the\n   release process.\n   \n   \n * With merging a feature-branch that branches out of the release-branch.\n   This often my preferred choice in large teams. It gives the configuration\n   manager  control of what's included in the release. It avoids risk of merge\n   conflicts. The tests done on that feature-branch can be trusted. It can be\n   done with pull requests.\n   \n   \n * With direct commits to the release-branch.\n   This may fit a technical team where the configuration manager  is also a \n   developer. It provides a release process for the current release and enables\n   the developer  to work on the next release in develop. It lacks support for\n   code review but you may not need that in a small project.\n   \n   \n\nHere is what it may look like if cherry-picking  is used.\n\n| *  Setting version to 1.0-SNAPSHOT\n| *  (release-1, tag: 1.0-RC-2) Releasing RC 2\n| *  Setting version to 1.0-RC2\n| *  Correcting a\n| *  Setting version to 1.0-SNAPSHOT\n| *  (tag: 1.0-RC-1) Releasing RC 1\n| *  Setting version to 1.0-RC1\n* | (develop) Setting version to 1.1-SNAPSHOT\n|/\n\n\nNow if RC2  is good and should be released then that exact artifact is deployed\nin production.\n\n * Released commit, release-tag, in release-1  is merged into master. * To keep\n      track of what is in production.\n   \n   \n * master  is merged into develop, this is important: * To make sure any changes\n      made in production are also in the next release.\n    * To allow a fast-forward  of master  next time you merge release-tag  to \n      master.\n   \n   \n\nConclusions\nI've shown the two roles in GitFlow  and I hope I made it obvious that its\nactually a very simple workflow! It will not fit all projects.\n\nYou will probably not gain from using GitFLow  in a library. That is just used\nby other software. Where a release is just a process of packaging an artifact an\nmaking it available for other software to use. You can probably just release a\nnew version if something needs to be fixed later, and the users of the software\ncan just keep using an older version until things are worked out.\n\nYou will probably gain from using GitFlow  if you have a code freeze. It enables\na code freeze  without preventing developers from working on the next release.\n\nIf you just fire releases from master, without any branching, you can easily\nautomate that process. If you need to make a release-branch and eventually merge\nit back into master, and develop, you will need a more complex flow. Which is a\nprice you may not want to pay unless you are gaining something else from the\nflow!","feature_image":"/content/images/2018/02/poshgitflowversion.png","featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2017-02-25T03:28:42.000Z","created_by":"1","updated_at":"2018-07-16T16:38:50.000Z","updated_by":"1","published_at":"2017-02-25T04:56:31.000Z","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"custom_template":null},{"id":"597b4433e521cb4fbd9186a6","uuid":"0c0c6499-af7f-4067-b900-17f8d7864667","title":"Continuous Integration with GitLab and Jenkins","slug":"continuous-integration-with-gitlab-and-jenkins","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"My client recently started using GitLab. I did not find the plugins needed to properly verify merge requests. Here is what I wanted to do:\\n\\n * Trigger on merge requests events.\\n * Merge, compile, test and run static code analysis on it.\\n * Report static code analysis results to GitLab.\\n\\nWhen fiddling with this I came up with a Job DSL solution and a pipeline solution. Here is how they work.\\n\\n# Job DSL approach\\nI developed a couple of Jenkins Plugins to do this.\\n\\n* [Generic Webhook Trigger Jenkins Plugin](https://github.com/jenkinsci/generic-webhook-trigger-plugin)\\n* [Violation Comments To GitLab Jenkins Plugin](https://github.com/jenkinsci/violation-comments-to-gitlab-plugin)\\n\\nI also use the [HTTP Request Plugin](https://wiki.jenkins-ci.org/display/JENKINS/HTTP+Request+Plugin) and [Conditional BuildStep Plugin](https://wiki.jenkins-ci.org/display/JENKINS/Conditional+BuildStep+Plugin).\\n\\nHere is what you need to do to use this workflow.\\n\\n\\nIn Jenkins:\\n\\n 1. Install the plugins.\\n 2. Use the job DSL to create the job. The DSL is [in the wiki](https://wiki.jenkins-ci.org/display/JENKINS/Violation+Comments+to+GitLab+Plugin) and [in the repo](https://github.com/jenkinsci/violation-comments-to-gitlab-plugin).\\n\\nIn GitLab:\\n\\n 1. Create a API token. You will find it at `/profile/personal_access_tokens`\\n 2. Add a webhook. You will find it at `/root/violations-test/settings/integrations`. Point it at `http://user:password@jenkins:8080/generic-webhook-trigger/invoke`.\\n 3. Make sure you are authenticated, in this request, with a user that can view any jobs that should be triggered.\\n\\n\\nThe [GitLab merge request](https://gitlab.com/tomas.bjerre85/violations-test/merge_requests/1) will then be commented like this:\\n![alt](/content/images/2017/03/mergerequest-onecomment-1.png)\\n\\n#Pipeline approach\\n\\nI just use curl, [GitLab plugin](https://github.com/jenkinsci/gitlab-plugin) and [Violation Comments to GitLab Plugin](https://wiki.jenkins-ci.org/display/JENKINS/Violation+Comments+to+GitLab+Plugin) to implement it.\\n\\n![Violation Comments to GitLab pipeline](/content/images/2017/04/violation-pipeline.PNG)\\nHere is what you need to do to use this workflow.\\n\\nIn Jenkins:\\n\\n 1. Install the plugins.\\n 2. Create a pipeline job. The pipeline script is [in the wiki](https://wiki.jenkins-ci.org/display/JENKINS/Violation+Comments+to+GitLab+Plugin) and [in the repo](https://github.com/jenkinsci/violation-comments-to-gitlab-plugin).\\n\\nIn GitLab:\\n\\n 1. Create a API token. You will find it at `/profile/personal_access_tokens`\\n 2. Add a webhook. You will find it at `/root/violations-test/settings/integrations`.\\n\"}]],\"sections\":[[10,0]]}","html":"<p>My client recently started using GitLab. I did not find the plugins needed to properly verify merge requests. Here is what I wanted to do:</p>\n<ul>\n<li>Trigger on merge requests events.</li>\n<li>Merge, compile, test and run static code analysis on it.</li>\n<li>Report static code analysis results to GitLab.</li>\n</ul>\n<p>When fiddling with this I came up with a Job DSL solution and a pipeline solution. Here is how they work.</p>\n<h1 id=\"jobdslapproach\">Job DSL approach</h1>\n<p>I developed a couple of Jenkins Plugins to do this.</p>\n<ul>\n<li><a href=\"https://github.com/jenkinsci/generic-webhook-trigger-plugin\">Generic Webhook Trigger Jenkins Plugin</a></li>\n<li><a href=\"https://github.com/jenkinsci/violation-comments-to-gitlab-plugin\">Violation Comments To GitLab Jenkins Plugin</a></li>\n</ul>\n<p>I also use the <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/HTTP+Request+Plugin\">HTTP Request Plugin</a> and <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/Conditional+BuildStep+Plugin\">Conditional BuildStep Plugin</a>.</p>\n<p>Here is what you need to do to use this workflow.</p>\n<p>In Jenkins:</p>\n<ol>\n<li>Install the plugins.</li>\n<li>Use the job DSL to create the job. The DSL is <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/Violation+Comments+to+GitLab+Plugin\">in the wiki</a> and <a href=\"https://github.com/jenkinsci/violation-comments-to-gitlab-plugin\">in the repo</a>.</li>\n</ol>\n<p>In GitLab:</p>\n<ol>\n<li>Create a API token. You will find it at <code>/profile/personal_access_tokens</code></li>\n<li>Add a webhook. You will find it at <code>/root/violations-test/settings/integrations</code>. Point it at <code>http://user:password@jenkins:8080/generic-webhook-trigger/invoke</code>.</li>\n<li>Make sure you are authenticated, in this request, with a user that can view any jobs that should be triggered.</li>\n</ol>\n<p>The <a href=\"https://gitlab.com/tomas.bjerre85/violations-test/merge_requests/1\">GitLab merge request</a> will then be commented like this:<br>\n<img src=\"/content/images/2017/03/mergerequest-onecomment-1.png\" alt=\"alt\"></p>\n<h1 id=\"pipelineapproach\">Pipeline approach</h1>\n<p>I just use curl, <a href=\"https://github.com/jenkinsci/gitlab-plugin\">GitLab plugin</a> and <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/Violation+Comments+to+GitLab+Plugin\">Violation Comments to GitLab Plugin</a> to implement it.</p>\n<p><img src=\"/content/images/2017/04/violation-pipeline.PNG\" alt=\"Violation Comments to GitLab pipeline\"><br>\nHere is what you need to do to use this workflow.</p>\n<p>In Jenkins:</p>\n<ol>\n<li>Install the plugins.</li>\n<li>Create a pipeline job. The pipeline script is <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/Violation+Comments+to+GitLab+Plugin\">in the wiki</a> and <a href=\"https://github.com/jenkinsci/violation-comments-to-gitlab-plugin\">in the repo</a>.</li>\n</ol>\n<p>In GitLab:</p>\n<ol>\n<li>Create a API token. You will find it at <code>/profile/personal_access_tokens</code></li>\n<li>Add a webhook. You will find it at <code>/root/violations-test/settings/integrations</code>.</li>\n</ol>\n","comment_id":"29","plaintext":"My client recently started using GitLab. I did not find the plugins needed to\nproperly verify merge requests. Here is what I wanted to do:\n\n * Trigger on merge requests events.\n * Merge, compile, test and run static code analysis on it.\n * Report static code analysis results to GitLab.\n\nWhen fiddling with this I came up with a Job DSL solution and a pipeline\nsolution. Here is how they work.\n\nJob DSL approach\nI developed a couple of Jenkins Plugins to do this.\n\n * Generic Webhook Trigger Jenkins Plugin\n   [https://github.com/jenkinsci/generic-webhook-trigger-plugin]\n * Violation Comments To GitLab Jenkins Plugin\n   [https://github.com/jenkinsci/violation-comments-to-gitlab-plugin]\n\nI also use the HTTP Request Plugin\n[https://wiki.jenkins-ci.org/display/JENKINS/HTTP+Request+Plugin]  and \nConditional BuildStep Plugin\n[https://wiki.jenkins-ci.org/display/JENKINS/Conditional+BuildStep+Plugin].\n\nHere is what you need to do to use this workflow.\n\nIn Jenkins:\n\n 1. Install the plugins.\n 2. Use the job DSL to create the job. The DSL is in the wiki\n    [https://wiki.jenkins-ci.org/display/JENKINS/Violation+Comments+to+GitLab+Plugin] \n     and in the repo\n    [https://github.com/jenkinsci/violation-comments-to-gitlab-plugin].\n\nIn GitLab:\n\n 1. Create a API token. You will find it at /profile/personal_access_tokens\n 2. Add a webhook. You will find it at \n    /root/violations-test/settings/integrations. Point it at \n    http://user:password@jenkins:8080/generic-webhook-trigger/invoke.\n 3. Make sure you are authenticated, in this request, with a user that can view\n    any jobs that should be triggered.\n\nThe GitLab merge request\n[https://gitlab.com/tomas.bjerre85/violations-test/merge_requests/1]  will then\nbe commented like this:\n\n\nPipeline approach\nI just use curl, GitLab plugin [https://github.com/jenkinsci/gitlab-plugin]  and\n Violation Comments to GitLab Plugin\n[https://wiki.jenkins-ci.org/display/JENKINS/Violation+Comments+to+GitLab+Plugin] \n to implement it.\n\n\nHere is what you need to do to use this workflow.\n\nIn Jenkins:\n\n 1. Install the plugins.\n 2. Create a pipeline job. The pipeline script is in the wiki\n    [https://wiki.jenkins-ci.org/display/JENKINS/Violation+Comments+to+GitLab+Plugin] \n     and in the repo\n    [https://github.com/jenkinsci/violation-comments-to-gitlab-plugin].\n\nIn GitLab:\n\n 1. Create a API token. You will find it at /profile/personal_access_tokens\n 2. Add a webhook. You will find it at \n    /root/violations-test/settings/integrations.","feature_image":"/content/images/2018/02/gitlab.jpg","featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2017-03-12T21:51:44.000Z","created_by":"1","updated_at":"2018-02-24T08:57:27.000Z","updated_by":"1","published_at":"2017-03-12T22:01:49.000Z","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"custom_template":null},{"id":"597b4433e521cb4fbd9186a7","uuid":"221c2c8c-f050-4657-bbaa-da6bd8d6890c","title":"Java Code Formatting With Google Java Format","slug":"java-code-formatting-with-google-java-format","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"Most projects, that I work with nowadays, have a defined code standard that includes how the code should be formatted. That is great and improves code quality a lot... if followed!\\n\\nA single person, in the project, can lower the quality significantly by not formatting the code correctly. If such code is not blocked, from making it into shared branches, you will have the choice of keeping it or fixing it. This is a problem that I find incredibly annoying!\\n\\n* *Keeping it* means you have to live with faulty formatted code. If some developers use something like *save actions* in **Eclipse** then they will have a hard time keeping the lines unchanged when working on the file.\\n* *Re-formatting it* in a new commit makes it harder to maintain the project because things like `git blame` will show the re-format commit, not the original feature commit.\\n\\nThe most common solution to this, among the clients I've been working with, is to use a code style defined in **Eclipse**. Along with *save actions*. The code style is imported to **Eclipse** from an XML-file and some clients also use [Workspace Mechanics](http://marketplace.eclipse.org/content/workspace-mechanic) to setup *save actions* properly.\\n\\nDefining the code style in **Eclipse** is a very bad idea:\\n\\n* All people are not productive in **Eclipse**, some might for example be using **InteliJ** or **NetBeans**. They will have to have **Eclipse** installed just to use it for formatting.\\n* The semantics of the settings in the code style may change between versions of **Eclipse** (I have seen it!). Then you may start getting unnecessary diffs in commits after an upgrade.\\n* There is no way, as far as I know, to verify **Eclipse**-formatting as a step in a continuous integration flow. While it is easy for a reviewer to see that brackets are incorrectly positioned, other things may not be as obvious.\\n\\n# Google Java Format\\n\\nIf it is up to me, I choose [Google Java Format](https://github.com/google/google-java-format). Because:\\n\\n* There are plugins for Gradle and Maven so that it can easily be integrated in the build process. Applied when building and verified in continuous integration.\\n* It takes all decisions regarding formatting of Java code. It can even optimize imports, sorting and removing unused imports.\\n* All decisions in this code style is carefully taken considering how diffs will appear in files where it is applied.\\n* The code style, and the tool support for that, is completely separate from any IDE used. You can let the developers use whatever IDE they want. The important thing is what they produce, the code, which should have no references to any IDE.\\n\\nI use these in different projects:\\n\\n* [FMT Maven Plugin](https://github.com/coveo/fmt-maven-plugin). You just need to add it to the `pom.xml` and it will format the code at compile time. It includes a [validate](https://github.com/coveo/fmt-maven-plugin/blob/master/src/main/java/com/coveo/FMT.java#L62) attribute that can be used in continuous integration, perhaps with a build property, to validate that the code is formatted correctly.\\n* [Google Java Format Gradle Plugin](https://github.com/sherter/google-java-format-gradle-plugin). You just need to add it to the `build.gradle` and it can format the code at compile time with something like `compileJava.dependsOn 'googleJavaFormat'`. It adds a `verifyGoogleJavaFormat` task to be used in continuous integration to verify formatting.\\n\\nA common problem when auto formatting coding is with newlines. I use *phantom comments* to deal with that. Just add `//` at the end of the line, like [this](https://github.com/tomasbjerre/violations-lib/blob/master/src/main/java/se/bjurr/violations/lib/parsers/CheckStyleParser.java), to force the formatter to keep it that way.\"}]],\"markups\":[],\"sections\":[[10,0]]}","html":"<p>Most projects, that I work with nowadays, have a defined code standard that includes how the code should be formatted. That is great and improves code quality a lot... if followed!</p>\n<p>A single person, in the project, can lower the quality significantly by not formatting the code correctly. If such code is not blocked, from making it into shared branches, you will have the choice of keeping it or fixing it. This is a problem that I find incredibly annoying!</p>\n<ul>\n<li><em>Keeping it</em> means you have to live with faulty formatted code. If some developers use something like <em>save actions</em> in <strong>Eclipse</strong> then they will have a hard time keeping the lines unchanged when working on the file.</li>\n<li><em>Re-formatting it</em> in a new commit makes it harder to maintain the project because things like <code>git blame</code> will show the re-format commit, not the original feature commit.</li>\n</ul>\n<p>The most common solution to this, among the clients I've been working with, is to use a code style defined in <strong>Eclipse</strong>. Along with <em>save actions</em>. The code style is imported to <strong>Eclipse</strong> from an XML-file and some clients also use <a href=\"http://marketplace.eclipse.org/content/workspace-mechanic\">Workspace Mechanics</a> to setup <em>save actions</em> properly.</p>\n<p>Defining the code style in <strong>Eclipse</strong> is a very bad idea:</p>\n<ul>\n<li>All people are not productive in <strong>Eclipse</strong>, some might for example be using <strong>InteliJ</strong> or <strong>NetBeans</strong>. They will have to have <strong>Eclipse</strong> installed just to use it for formatting.</li>\n<li>The semantics of the settings in the code style may change between versions of <strong>Eclipse</strong> (I have seen it!). Then you may start getting unnecessary diffs in commits after an upgrade.</li>\n<li>There is no way, as far as I know, to verify <strong>Eclipse</strong>-formatting as a step in a continuous integration flow. While it is easy for a reviewer to see that brackets are incorrectly positioned, other things may not be as obvious.</li>\n</ul>\n<h1 id=\"googlejavaformat\">Google Java Format</h1>\n<p>If it is up to me, I choose <a href=\"https://github.com/google/google-java-format\">Google Java Format</a>. Because:</p>\n<ul>\n<li>There are plugins for Gradle and Maven so that it can easily be integrated in the build process. Applied when building and verified in continuous integration.</li>\n<li>It takes all decisions regarding formatting of Java code. It can even optimize imports, sorting and removing unused imports.</li>\n<li>All decisions in this code style is carefully taken considering how diffs will appear in files where it is applied.</li>\n<li>The code style, and the tool support for that, is completely separate from any IDE used. You can let the developers use whatever IDE they want. The important thing is what they produce, the code, which should have no references to any IDE.</li>\n</ul>\n<p>I use these in different projects:</p>\n<ul>\n<li><a href=\"https://github.com/coveo/fmt-maven-plugin\">FMT Maven Plugin</a>. You just need to add it to the <code>pom.xml</code> and it will format the code at compile time. It includes a <a href=\"https://github.com/coveo/fmt-maven-plugin/blob/master/src/main/java/com/coveo/FMT.java#L62\">validate</a> attribute that can be used in continuous integration, perhaps with a build property, to validate that the code is formatted correctly.</li>\n<li><a href=\"https://github.com/sherter/google-java-format-gradle-plugin\">Google Java Format Gradle Plugin</a>. You just need to add it to the <code>build.gradle</code> and it can format the code at compile time with something like <code>compileJava.dependsOn 'googleJavaFormat'</code>. It adds a <code>verifyGoogleJavaFormat</code> task to be used in continuous integration to verify formatting.</li>\n</ul>\n<p>A common problem when auto formatting coding is with newlines. I use <em>phantom comments</em> to deal with that. Just add <code>//</code> at the end of the line, like <a href=\"https://github.com/tomasbjerre/violations-lib/blob/master/src/main/java/se/bjurr/violations/lib/parsers/CheckStyleParser.java\">this</a>, to force the formatter to keep it that way.</p>\n","comment_id":"30","plaintext":"Most projects, that I work with nowadays, have a defined code standard that\nincludes how the code should be formatted. That is great and improves code\nquality a lot... if followed!\n\nA single person, in the project, can lower the quality significantly by not\nformatting the code correctly. If such code is not blocked, from making it into\nshared branches, you will have the choice of keeping it or fixing it. This is a\nproblem that I find incredibly annoying!\n\n * Keeping it  means you have to live with faulty formatted code. If some\n   developers use something like save actions  in Eclipse  then they will have a\n   hard time keeping the lines unchanged when working on the file.\n * Re-formatting it  in a new commit makes it harder to maintain the project\n   because things like git blame  will show the re-format commit, not the\n   original feature commit.\n\nThe most common solution to this, among the clients I've been working with, is\nto use a code style defined in Eclipse. Along with save actions. The code style\nis imported to Eclipse  from an XML-file and some clients also use Workspace\nMechanics [http://marketplace.eclipse.org/content/workspace-mechanic]  to setup \nsave actions  properly.\n\nDefining the code style in Eclipse  is a very bad idea:\n\n * All people are not productive in Eclipse, some might for example be using \n   InteliJ  or NetBeans. They will have to have Eclipse  installed just to use\n   it for formatting.\n * The semantics of the settings in the code style may change between versions\n   of Eclipse  (I have seen it!). Then you may start getting unnecessary diffs\n   in commits after an upgrade.\n * There is no way, as far as I know, to verify Eclipse-formatting as a step in\n   a continuous integration flow. While it is easy for a reviewer to see that\n   brackets are incorrectly positioned, other things may not be as obvious.\n\nGoogle Java Format\nIf it is up to me, I choose Google Java Format\n[https://github.com/google/google-java-format]. Because:\n\n * There are plugins for Gradle and Maven so that it can easily be integrated in\n   the build process. Applied when building and verified in continuous\n   integration.\n * It takes all decisions regarding formatting of Java code. It can even\n   optimize imports, sorting and removing unused imports.\n * All decisions in this code style is carefully taken considering how diffs\n   will appear in files where it is applied.\n * The code style, and the tool support for that, is completely separate from\n   any IDE used. You can let the developers use whatever IDE they want. The\n   important thing is what they produce, the code, which should have no\n   references to any IDE.\n\nI use these in different projects:\n\n * FMT Maven Plugin [https://github.com/coveo/fmt-maven-plugin]. You just need\n   to add it to the pom.xml  and it will format the code at compile time. It\n   includes a validate  attribute that can be used in continuous integration,\n   perhaps with a build property, to validate that the code is formatted\n   correctly.\n * Google Java Format Gradle Plugin\n   [https://github.com/sherter/google-java-format-gradle-plugin]. You just need\n   to add it to the build.gradle  and it can format the code at compile time\n   with something like compileJava.dependsOn 'googleJavaFormat'. It adds a \n   verifyGoogleJavaFormat  task to be used in continuous integration to verify\n   formatting.\n\nA common problem when auto formatting coding is with newlines. I use phantom\ncomments  to deal with that. Just add //  at the end of the line, like this\n[https://github.com/tomasbjerre/violations-lib/blob/master/src/main/java/se/bjurr/violations/lib/parsers/CheckStyleParser.java]\n, to force the formatter to keep it that way.","feature_image":"/content/images/2018/02/java.png","featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2017-06-11T19:21:23.000Z","created_by":"1","updated_at":"2018-08-30T18:18:39.000Z","updated_by":"1","published_at":"2017-06-11T20:47:00.000Z","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"custom_template":null},{"id":"597b4433e521cb4fbd9186a8","uuid":"9d62c3dd-e910-47a8-bb7a-f060f74e8993","title":"Starta Eget Konsultbolag","slug":"starta-eget-konsultbolag","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"Efter ver 7 r som anstlld konsult (mjukvaruutvecklare) valde jag nyligen att starta eget aktiebolag. Jag gr precis samma sak nu som jag gjorde som anstlld men numera i mitt eget bolag istllet. Det hr inlgget handlar om hur jag gjorde detta. Googlar man kring att starta eget s hittar man mycket. Men jag saknade ngon som beskriver det utifrn mina frutsttningar, det r vad jag frsker gra hr, eftersom jag tror att mnga har samma frutsttningar som mig. **Oh, and sorry if you don't speak Swedish =) The topic is about starting your own company in Sweden, you are probably not interested.**\\n\\nSka ocks sga att allt jag tagit reda p hr r genom googling och jag tar inget ansvar fr att det jag sger hr r korrekt och riktigt! S var kritisk nr du lser vad jag skriver nedan!\\n\\n# Varfr Starta Eget?\\n\\nDu kan **skatteplanera**. Om du redan innan ret r slut vet [grns fr statlig skatt](http://www.regeringen.se/pressmeddelanden/2017/03/upprakningen-av-skiktgranserna-for-statlig-inkomstskatt-2018-begransas-och-den-sarskilda-inkomstskatten-for-utomlands-bosatta-hojs/) och eventuella avdrag du kommer att gra. D kan du rkna ut exakt vilken ln du kan betala ut frn bolaget fr att du som privatperson ska hamna precis p grnsen fr statlig skatt.\\n\\nUtver lnen kan du ocks gra en **utdelning**. D skattar du 20% p summan upp till `2.75` gnger fregende rs *inkomstbasbeloppet* fr 2018 blir det `2.75 * 59300 = 163075`. Det r det som kallas frenklingsregeln. Man kan ocks rkna fram en grns, som r hlften av utbetald ln, och anvnda den om den r mer frdelaktig. [Den hr blog-posten](https://www.foretagande.se/sa-beraknas-skatt-pa-utdelning-3-12-reglerna/) beskriver detta bra. Frsta ret kan du eventuellt inte anvnda frenklingsregeln, de diskuterar det i [den hr trden](https://forum.vismaspcs.se/visma_spcs/topics/utdelning-forsta-aret).\\n\\nJag har [gjort ett excel-ark](https://docs.google.com/spreadsheets/d/1jfQSSOEINNq3OVc5pYG5NeFkvgcDqOEu1HjzpU2RQm0/edit?usp=sharing) fr att **optimera skatten**. Skatteverket har ven [en sida](https://www.skatteverket.se/privat/sjalvservice/allaetjanster/tjanster/raknautdinskatt.4.18e1b10334ebe8bc80001950.html) dr man kan rkna ut sin skatt. Du kan ven lsa mer om [skatter och avgifter p Verksamt](https://www.verksamt.se/starta/skatter-och-avgifter/aktiebolag). Se ven [den hr sidan](http://www.driva-eget.se/kalkyler/lonekalkyl) fr att f en uppfattning om hur mycket ln man kan ta ut.\\n\\nDet finns anledning att vara rdd fr det faktum att man inte fr ngra pengar alls om man inte har ett uppdrag. Men eget bolag kan du anvnda en **[periodiseringsfond](https://www.skatteverket.se/foretagochorganisationer/foretagare/enskildnaringsverksamhet/periodiseringsfond.4.361dc8c15312eff6fd2b8f2.html)** dr du lgger undan pengar mellan rkenskapsr. Du kan allts optimera din ln fr att slippa statlig skatt, lgga undan pengar i en periodiseringsfond och sedan betala ut dem ett r d du har mindre inkomster. P s vis slipper du bde bolagsskatten och statlig inkomstskatt.\\n\\nDu r **skrare som egen**. Bolaget kommer frmodligen att dra in mer pengar n vad som r lmpligt att direkt batala ut som ln. Fr du *500*kr/timme (ett vldigt lgt pris!) s drar du in cirka *80 000*kr under en mnad. D kan du betala *60 000*kr i ln. Men du vill frmodligen bara betala ut *36 575*kr eftersom det r grnsen fr statlig skatt. Att betala den lnen kostar cirka *48 000*kr fr bolaget och du har allts *32 000*kr kvar i bolaget. Gr du det varje mnad har du *384 000*kr kvar i bolaget nr rkenskapsret r slut. Du vill frmodligen anvnda en del fr att gra en utdelning. Men fr att jmfra med att vara anstlld s skulle du kunna betala ut samma ln *6* mnader in p nsta r, trots att du str helt utan inkomster! Fr att rkna ut hur mycket ln du kan betala ut kan du allts rkna shr `timpenning*(52-semesterveckor)*40/12/1.31` s kanske `500*(52-6)*40/12/1.31 = 58 524`.\\n\\nDu vljer sjlv om du vill betala in till en **tjnstepension** och i s fall vilken. Jag har tvingats betala till SEB under en lngre tid. Det enda jag bryr mig om r deras fondutbud. I SEB hittade jag bara en fond, [en rntefond](http://web.msse.se/SEB/SGF/quicktake.aspx?six=SEB-BDSEKA), som kndes \\\"ok\\\". Det r ven en frdel att du kan maximera lnen, gra utdelning och om det efter detta fortfarande finns pengar ver kan du anvnda dem till tjnstepension. Du slipper allts lsa in pengar i en sdan pension om det inte r s att det r en skattemssig frdel. Med tanke p att du, via utdelning, kan f ut kapital med en skatt p under 40% s kanske du inte vill anvnda en tjnstepension. Pengarna du fr ut via utdelningen r ju helt olsta och du kan investera hur du vill.\\n\\nDu **slipper ha ln efter lder**. Ju yngre du r, ju mer tjnar du p att ha eget konsultbolag. Den dumma tanken att man ska brja p en lg lneniv och sedan ka ett par procent per r mappar inte alls mot vad kunderna betala fr dig per timme. Kunderna har oftast ett pris p juniorer och ett p seniorer. Att du r 30, 31 eller 40 r gammal spelar ingen roll fr priset. r du yngre anstlld konsult betalar du fr dina ldre kollegors ln och frmner. Det kan mycket vl vara s att du drar in mer pengar n ngon som r 20 r ldre. Med eget bolag mer n dubblade jag min ln.\\n\\nDu kan **kpa kontorsmaterial vldigt billigt**. Dator, headset, hrlurar, skrmar... till mindre n halva priset jmfrt med om du kper det privat. D tnker jag inte bara p momsen. Tnk ven p hur mycket pengar bolaget behver betala ut fr att, efter skatt och arbetsgivaravgift, kunna stta in summan p det privata kontot. Sklart mste man tnka p att det man kper gs av fretaget och inte dig privat.\\n\\nS fort du har mjlighet att betala ut **[skattefritt traktamente](https://www.vismaspcs.se/visma-support/visma-eget-aktiebolag/content/skattefria_traktamenten.htm)** s ska du gra det. Du slipper tjafs med en arbetsgivare som nekar dig ngot som r s sjlvklart.\\n\\nDu kan **ka p vilken konferens du vill** och lta bolaget betala. Det finns ju intressanta utvecklarkonferenser nstan verallt. Du behver bara [hitta en](http://lmgtfy.com/?q=sidney+developer+conference) och ka. Inget tjafs med en arbetsgivare som tycker det r fr dyrt. Inga dryga vningar, innan eller p plats, utan bara du som bestmmer vilka frelsningar du tycker r intressanta och som du gr p.\\n\\nJag tycker att de flesta mten r meningslsa och vldigt trkiga. Det blir klart **frre mten** med eget bolag. Du kan spendera din tid med kunden istllet fr trkiga mnadsmten =)\\n\\nDu kan f **mindre administrativt jobb**. Som anstlld hade jag kvitton att rapportera varje vecka. Jag kpte tgbiljetter via SJ:s hemsida och fick allts kvittot som PDF. Jag var tvungen att rapporera dem varje vecka med kostnad och moms. Skriva ut ett papper i samband med tidrapportering. Skriva ut mina kvitton. Hffta fast mina kvitton p pappret frn tidrapporteringssystemet. Leta upp kuvert samt frimrke. Leta upp brevlda och posta kuvert med tidrapporten till konsultbolagets kontor. Som egen lgger jag aldrig mer n 2 timmar totalt under en hel mnad p att skta den fullstndiga bokfring inklusive alla kvitton. Allt gr jag digitalt.\\n\\nTill sist, och kanske det absolut bsta argumentet. Jag har **alltid sett mig sjlv som mitt eget varumrke**. D r ju inte steget lngt till att faktiskt vara det ocks.\\n\\n# Hur Starta Eget?\\nJag listar hr kortfattat vad man behver gra. Lngre ner finns vissa steg mer utfrligt beskrivna. Du kan rkna med att det tar 1-2 mnader frn att du skickar in frsta anskan till att allt runt bolaget r klart och du kan brja jobba i det. Skadar inte att titta p [andra listor ocks](https://www.verksamt.se/alla-e-tjanster/din-checklista/aktiebolag) fr att skra att du inte glmt ngot.\\n\\nJag valde **aktiebolag** framfr enskild firma. D r bolaget en juridisk person som ocks har ansvaret. En tydlig grns mellan bolag och privat ekonomi allts. Jag kan rekommendera [Verksamts jmfrelse av fretagsformer](https://www.verksamt.se/fundera/valj-foretagsform).\\n\\n**Skapa anskan** p [Verksamt](https://www.verksamt.se/). Du kommer behva en verksamhetsbeskrivning. Min ser ut shr:\\n> Fretaget ska bedriva konsultverksamhet fretrdesvis inom IT, samt utveckla mjukvaruprodukter, ga och frvalta vrdepapper och utva drmed frenlig verksamhet.\\n\\nNr det gller **fretagsnamn** s rekommenderar jag att bara ta ditt eget namn. AB eller aktiebolag mste vara med i namnet. S jag valde *Tomas Bjerre AB*. Risken om du vljer ngot annat r att Bolagsverket nekar dig fr att namnet liknar ngot som redan finns. Ondigt strul och du kan alltid ndra senare.\\n\\nDu kommer behva ange en **SNI-kod**. Jag valde *62010*.\\n\\nNr du skickat ivg anskan till Bolagsverket kommer de invnta ett **bankintyg**. Ls mer om att vlja bank nedan. Du behver kontakta en bank fr att skapa ett fretagskonto. Banken kommer be dig stta in 50 000 kr p ett speciellt konto. Banken behver kunna tala om fr Bolagsverket att hr finns det 50 000 kr som satts in med avsikt att anvndas fr aktiekapitalet. Nr du gjort detta ger de dig en e-postadress som du sedan ger till Bolagsverket (via verksamt.se). Sedan frgan Bolagsverket banken om pengarna r dr och nr banken svarar ja registreras bolaget. S fort bolaget r skapat s har du sedan ett fretagskonto dr det frn start finns 50 000 kr.\\n\\nJag valde **rkenskapsret** som *0101 - 1231*. Jag kan dock rekommendera brutet rkenskapsr. Allts att man vljer ett r som inte r ett kalenderr. Frdelen blir d att du kan vlja vilket r du betalar ut lnen p, om du nr statlig skatt 2017 kan du vnta till 2018 med att fortstta betala ut ln. Det r inte helt enkelt att [ndra i efterhand](https://www.skatteverket.se/download/18.3aa8c78a1466c584587d059/1408515815569/42405.pdf) och att ndra det bara fr att undvika skatt r inte en godtagbar anledning.\\n\\nNr du startar aktiebolag ska bolaget ha **F-skatt** och du som privatperson har A-skatt. Jag valde **kvartalsmoms**. Som **redovisningsmetod** valde jag [kontantmetoden](https://www.e-conomic.se/bokforingsprogram/ordlista/kontantmetoden) (kallas ven bokslutsmetoden). Jag uppfattade den som enklast, se hur man [bokfr kpt med kreditkort](https://forum.vismaspcs.se/visma_spcs/topics/bokfora-inkop-med-kreditkort-i-visma-eekonomi) t.ex.\\n\\nDet r vldigt svrt att uppskatta den **frvntade vinsten** frsta ret. Andra ret kommer Skatteverket fresl en. Ett tips r att ange den lgt. I mitt fall skulle jag frst betala in 20 000 kr innan jag hunnit f en enda inkomst i bolaget. Skulle du rka ut fr det r det bara att gra en ny preliminr inkomstdeklaration via Skatteverket och ange en lgre frvntad vinst. D fick jag ner denna siffran till 7 000 kr istllet.\\n\\nDet finns mnga smidiga **bokfringsprogram**. [Redovisningen](https://sv.wikipedia.org/wiki/Redovisning) var nog det jag var mest rdd fr i brjan. Jag mrkte tidigt att nr jag googlade om hur man bokfr olika saker s kom jag ofta in p [Visma:s support forum](https://forum.vismaspcs.se/visma_spcs). Jag har tidigare anvnt deras tidrapportering, PX, vilket suger ngot helt otroligt. Ser ut som en sommarjobbare hackade ihop det fr 15 r sedan och att man inte rrt det sedan dess. Men ven om jag var vldigt skeptisk till detta bolag s valde jag nd <a href=\\\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\\\" rel=\\\"nofollow\\\">Visma eEkonomi</a> fr bokfring just fr att deras support verkar vara helt exemplarisk. Att direkt bokfra ett kvitto i <a href=\\\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\\\" rel=\\\"nofollow\\\">Visma eEkonomi</a> r betydligt enklare n det jag tidigare gjort via tidrapportering som anstlld. Du kanske t.ex. vill bokfra [bokfringsprogrammet](https://forum.vismaspcs.se/visma_spcs/topics/8fxz374h0czze?topic-reply-list%5Bsettings%5D%5Bfilter_by%5D=all), [kp av dator och frskring](https://forum.vismaspcs.se/visma_spcs/topics/7h3lv4csqal8w) eller [kp av tgbiljett](https://forum.vismaspcs.se/visma_spcs/topics/con2lpq5fex2f). De [gr t.o.m. filmer](https://www.youtube.com/watch?v=jGgnxd6uBh4) dr de visar vissa flden. Hoppas jag r trovrdig trots att jag gtt med i deras affiliate-program och fr betalt fr att hnvisa andra dit =)\\n\\n<a href=\\\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\\\" rel=\\\"nofollow\\\">\\n\\n![Visma eEkonomi](/content/images/2017/07/affiliate-2014-vismaeekonomi1_728x90_eeko.gif)\\n</a>\\n\\nDu lr behva en **mobil** i bolaget. Som jag frstr det r det ok att kpa telefonen p bolaget. ven telefoni och SMS r ok. Datatrafiken dremot kan behva frmnsbeskattas. Det i kombination med att man slipper mnga dryga samtal om man istllet har ett privat abonnemang, gjorde att jag kpte den privat.\\n\\nDu lr behva en **ansvarsfrskring**. Jag valde en [frn If](https://www.if.se/web/se/foretag/varaforsakringar/offert/pages/default.aspx?varde=startforsakring) och fick betala 5 294 kr. Har du inte det och du rkar ut fr ngot, sg att ngon krver dig p flera miljoner, s konkursar du bara bolaget och slipper undan. Men med en ansvarsfrskring s kan du, kanske, gra rtt fr dig och betala. P s vis blir du en mer attraktiv konsult att anlita och det str ven ofta i kontrakten att du ska ha en frskring.\\n\\nJag valde att kontakta en **redovisningskonsult** som hjlper mig med ekonomiska frgor samt tar hand om **bokslut** / **rsredovisning** / **deklaration**. Jag tar hand om lpande bokfring samt kvartalsmoms, skatter och ln. Det kostar cirka 6 000 kr per r. En redovisningskonsult kan hjlpa dig med allt mjligt i bolaget. Vissa ger dem fullmakt s de kan skta all ekonomi. Jag fick tag p honom genom en bekant som tipsade men annars r det enkelt att googla. Har du valt Visma s [kan de hjlpa dig](https://vismaspcs.se/produkter/redovisning/visma-eekonomi-byra). I <a href=\\\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\\\" rel=\\\"nofollow\\\">Visma eEkonomi</a> kan du ven skapa en inloggning till din redovisningskonsult.\\n\\n**Revisor** r valfritt om man [omstter under 3 miljoner](http://www.bolagsverket.se/ff/foretagsformer/aktiebolag/starta/revisor). Det anvnder jag inte.\\n\\nDet kan ocks vara bra att ha klart fr sig **hur man hittar kunder**. Det finns mnga rena konsultmklare som tar en procentsats, ofta mellan 10-20% p din timpenning, om du tar ett uppdrag via dem. De har ofta ramavtal med stora konsultkpare. r du redan anstlld som konsult kanske du i brjan fortstter med samma kund fast som underkonsult istllet. Se, t.ex.:\\n\\n * [Assistera](http://www.assistera.se/sv)\\n * [Brainville](https://www.brainville.com/)\\n * [EWork](https://www.eworkgroup.com/se/)\\n * [Experis](https://cv.experis.se/)\\n * [Kvadrat](http://www.kvadrat.se/bli-kvadratare/)\\n * [Toptal](https://www.toptal.com/)\\n\\nOch till sist, du kan eventuellt gra **[investeraravdraget](http://www.kompred.se/nyttiga-tips/missa-inte-investeraravdraget/)** i din privata deklaration efter att du startat aktiebolag.\\n\\n## Bank\\n\\nJag frgade frst ngra banker via telefon och mail (ICA, Avanza, Swedbank). Det kndes som att de inte riktigt frstod vad jag menade nr jag sa att jag ville ha ett **bankintyg**.\\n\\n### Danskebank\\n\\n**Jag valde Danskebank**. Du fyller bara i [deras formulr](https://danskebank.se/sv-se/Foretag/Smaforetag/Pages/Product-packages.aspx) s ringer de upp. Danskebank skter allt per telefon och det fungerar mycket bra. De bad inte om ngon affrsplan eller budget utan litade p mig direkt. De visste ocks direkt vad det handlade om och de kndes plitliga. Eftersom jag inte var kund dr sedan tidigare s behvde de skicka lite papper till mig med posten frst. Men inom en vecka hade jag intyget! Snabbt, enkelt, smidigt och inget meningslst krngel.\\n\\nJag valde *Danske Business Plus* fr 99 kr/mn. **<a href=\\\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\\\" rel=\\\"nofollow\\\">Visma eEkonomi</a> stdjer ven Danskebank** p s vis att man kan klistra in kontoutdraget frn banken in i <a href=\\\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\\\" rel=\\\"nofollow\\\">Visma eEkonomi</a>, fr att automatiskt skapa bankhndelser. Sedan matchar man dem mot leverantrsfakturor eller verifikationer.\\n\\n# Hur Driva Eget?\\n\\nJag har lagt in terkommande hndelser i Google Calendar fr de olika datumen. Sedan angivit att de ska upprepas mnadsvis eller, i vissa fall, rsvis. Jag lgger ungefr 2 timmar varje mnad p att skta fretaget. Vad jag gr r:\\n\\n* En gng per mnaden\\n  * Importerar transaktioner frn skattekontot frn Skatteverket.\\n  * Importerar transaktioner frn fretagskontot frn banken.\\n  * Skickar fakturor fr mnaden.\\n  * Betalar ut ln, till anstllde.\\n  * Betalar skatt och avgifter till Skatteverket\\n      * Arbetsgivaravgift.\\n      * Inkomstskatt.\\n      * Debiterad preliminrskatt.\\n* En gng per kvartal.\\n  * Betalar in kvartalsmoms.\\n* En gng per r.\\n  * Bokslut, rsredovisning, deklaration.\\n  * I januari, skickar in kontrolluppgit fr fregende r till Skatteverket.\\n\\nJag valde **kvartalsmoms**, allts att jag efter varje kvartal redovisar och betalar in eventuell moms. Mer information om det finns [hr]( https://www.verksamt.se/driva/skatter-och-avgifter/moms-redovisa-och-betala). S fort kvartalet r slut kan man lmna in deklarationen. Man har ungefr 1.5 mnad p sig att lmna in den. ven fr detta har Visma gjort en film som visar [hur du gr i eEkonomi](https://www.youtube.com/watch?v=gPv_SahMnEw). Som jag frstr det anvnder man kontot *1630* (eller *2012* om det r enskild firma) just fr att [alla hndelser mot Skatteverket ska g via detta konto](https://forum.vismaspcs.se/visma_spcs/topics/maste-man-anvanda-sig-av-skattekontot-1630). Hur det fungerar med att betala, och f tillbaka moms, [beskriver Skatteverkets hr](https://www.skatteverket.se/foretagochorganisationer/moms/deklareraochbetalamoms/betalaochfatillbakamoms.4.58d555751259e4d66168000354.html). S kortfattat om du har <a href=\\\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\\\" rel=\\\"nofollow\\\">Visma eEkonomi</a> och kvartalsmoms s ska du vid varje kvartalsslut:\\n\\n * Skapa en momsredovisning fr kvartalet via bokfring / momsredovisning.\\n * Ladda ner *eskd*-filen.\\n * Skapa en [momsdeklaration](https://www.skatteverket.se/foretagochorganisationer/moms/deklareraochbetalamoms.4.7459477810df5bccdd480006935.html) enligt [Visma:s video](https://www.youtube.com/watch?v=gPv_SahMnEw).\\n * Ladda upp *eskd*-filen hos [Skatteverket](https://www.skatteverket.se/foretagochorganisationer/moms/deklareraochbetalamoms/betalaochfatillbakamoms.4.58d555751259e4d66168000354.html).\\n * Ladda ner [transaktioner frn Skatteverket till ditt skattekonto](https://www.youtube.com/watch?v=-7cDnn-NaME) och matchar dem sedan mot momshndelsen i dina bokfringshndelser.\\n * Nr du senare betalat in, eller ftt betalt, skapa och bokfr bankhndelsen p fretagskontot. Det visas i slutet p [den hr videon](https://www.youtube.com/watch?v=gPv_SahMnEw). Tnk p att anvnda *1630* fr AB och *2012* fr enskild firma.\\n\\nSkatteverket har skickat brev till dig med datum d du ska betala **debiterad preliminrskatt**. Det hr r ngot du betalar varje mnad och baserar sig p din frvntade vinst som du angav i din preliminra inkomstdeklaration. Du har ftt ett besked frn Skatteverket dr det str datum och hur mycket du ska betala. Om du har <a href=\\\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\\\" rel=\\\"nofollow\\\">Visma eEkonomi</a> kan du flja deras [film om skattekontot](https://www.youtube.com/watch?v=-7cDnn-NaME).\\n* Betala frn fretagskontot till fretagets skattekonto.\\n* Importerar bankhndelser frn fretagskontot.\\n* Ladda ner [transaktioner frn Skatteverket till ditt skattekonto](https://www.youtube.com/watch?v=-7cDnn-NaME) och matchar dem sedan mot momshndelsen i dina bokfringshndelser.\\n* Importera bankhndelsen frn banken till fretagskontot i <a href=\\\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\\\" rel=\\\"nofollow\\\">Visma eEkonomi</a>\\n* Importera bankhndelsen frn Skatteverket (du kan exportera den till fil) till skattekontot i <a href=\\\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\\\" rel=\\\"nofollow\\\">Visma eEkonomi</a>\\n* Matcha bankhndelsen p fretagskontot mot hndelsen p skattekontot. Egen kontering mellan egna bankkonton.\\n* Nr pengarna dragits av Skatteverket frn Skattekontot, importera den hndelsen.\\n* Matcha hndelsen mot bokfringsfrslaget *Debiterad preliminrskatt*.\\n\\nNr du ska betala ut **Ln** behver du betala *skatt*, *arbetsgivaravgift* samt sjlva *lnen*. Bde *skatt* och *arbetsgivaravgift* betalas till fretagets *skattekonto* s det r 2 betalningar som behver gras frn fretagskontot. Om du anvnder <a href=\\\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\\\" rel=\\\"nofollow\\\">Visma eEkonomi</a> kan du gra shr. Finns ven en [film hr](https://www.youtube.com/watch?v=ig2C9gQg2Eg) och en [bra trd](https://forum.vismaspcs.se/visma_spcs/topics/bokfora-lon-i-eekonomi) om detta i supportforumet.\\n* Under *ln* i huvudnenyn vljer du *anstllda*. Lgg upp den anstllde. Du kommer behva *Skattetabell* att anvnda. Den anstllde kan [logga in](https://www.skatteverket.se/) hos Skatteverket och hittar d skattetabell under \\\"Skatter och deklarationer\\\".\\n* Under *ln* i huvudnenyn vljer du *lnebesked* och skapar ett nytt.\\n* Ange lnen och vlj bokfr.\\n* Logga in p banken och betala ut lnen, efter skatt, till den anstlldes konto.\\n* Importera bankhndelsen till *fretagskontot* via *kassa och bankhndelser*.\\n* <a href=\\\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\\\" rel=\\\"nofollow\\\">Visma eEkonomi</a> kommer fresl att du matchar bankhndelsen mot lneutbetalningen, gr det. Nu r du klar med lnen, och nsta moment r att betala skatt och arbetsgivaravgift.\\n\\n**Arbetsgivardeklaration** lmnas enkelt via [Skatteverkets webbsida](https://www.skatteverket.se/foretagochorganisationer/arbetsgivare/lamnaarbetsgivardeklaration.4.6a6688231259309ff1f800029116.html).\\n\\n* Om du inte har betalat ut ngon ln stter du bara **0** i de obligatoriska flten och skickar in.\\n* Om du har betalat ut ln, och anvnder <a href=\\\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\\\" rel=\\\"nofollow\\\">Visma eEkonomi</a>.\\n  * G in under *ln* i huvudmenyn och vlj *arbetsgivardeklaration*.\\n  * Skapa ny.\\n  * Vlj mnaden d lnen betaldes ut.\\n  * Vlj *bokfr*. \\n  * Nu kan du [exportera en fil](https://www.youtube.com/watch?v=ig2C9gQg2Eg) om du klickar p *tgrder* fr deklarationen.\\n  * [Lmna in arbetsgivardeklarationen](https://www.skatteverket.se/foretagochorganisationer/arbetsgivare/lamnaarbetsgivardeklaration.4.6a6688231259309ff1f800029116.html) hos Skatteverket genom att importera filen.\\n  * P kvittensen visas ett bankgiro och OCR att anvnda fr att betala in skatten till fretagets skattekonto.\\n  * Betala in summan frn fretagets bankkonto.\\n  * Importera bankhndelsen frn banken till fretagskontot i <a href=\\\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\\\" rel=\\\"nofollow\\\">Visma eEkonomi</a>\\n  * Importera bankhndelsen frn Skatteverket (du kan exportera den till fil) till skattekontot i <a href=\\\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\\\" rel=\\\"nofollow\\\">Visma eEkonomi</a>\\n  * Matcha bankhndelsen p fretagskontot mot hndelsen p skattekontot. Egen kontering mellan egna bankkonton.\\n  * Nr pengarna dragits av Skatteverket frn Skattekontot, importera den hndelsen.\\n  * Matcha hndelsen mot bokfringsfrslaget arbetsgivardeklaration. Skatteverkat drar arbetsgivardeklartionen i 2 transaktioner, du behver [manuellt sl ihop dem](https://forum.vismaspcs.se/visma_spcs/topics/hur-matchar-jag-tva-belopp-pa-skattekontot-mot-en-arbetsgivardeklaration) fr att kunna anvnda det hr bokfringsfslaget. Men annars r det *1630* som krediteras och *2710* (personalskatt) samt *2731* (arbetsgivaravgift) som debiteras. Jag tycker ven [den hr sidan](https://www.blinfo.se/foretagskunskap/bokfora-lon__15472) r bra hr.\\n\\n<a href=\\\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\\\" rel=\\\"nofollow\\\">Visma eEkonomi</a> har en frdig mall fr **fakturor**. Du anger ditt fretags bankgiro, och/eller kontonummer, lgger upp kunder och artiklar. Sedan kan du enkelt skapa fakturor som du sedan kan skriva ut, spara som PDF eller maila.\\n\\nOm du **betalar ut traktamente** behver du kunna bevisa att [resorna gt rum och varit tjnsteresor](https://www.vismaspcs.se/visma-support/visma-eget-aktiebolag/content/skattefria_traktamenten.htm). Drfr kan det vara klokt att fra anteckningar fr resor. I mitt fall ker jag alltid tg och kommer hnvisa till tgbiljetterna om jag fr revision av Skatteverket. Jag skapar exceldokument, med utrkningen, som jag sedan exporterar till PDF och sparar fr att motivera traktamentet.\\n\\n![Traktamente](/content/images/2017/11/traktamente-utr.png)\\n\\nMan hr ibland uttrycket **skriva av** och jag tror mnga missfrstr det, kanske ven jag =) Men jag tolkar det som att allt man kper fr under ett halvt prisbasbelopp (ungefr 22 000 kr) skrivs av direkt, kostar det mer skriver man av det under flera r. Att *skriva av* innebr att man inte tar upp det som en tillgng, en inventarie, i bokfringen. Det r dock inte samma sak som att man fr ge bort prylen till sig sjlv eller ngon annan. Men jag r osker, [och mnga med mig](https://www.flashback.org/p49423662).\\n\\nAtt bokfra kp gjorda med **kreditkort** r lite speciellt men det har Visma en vldigt [bra artikel](https://forum.vismaspcs.se/visma_spcs/topics/bokfora-inkop-med-kreditkort-i-visma-eekonomi) om.\\n\\nJag sparar alltid alla **kvitton** direkt p Google Drive. r det inte digitalt fotar jag av med mobilen, laddar upp bilden och sparar ven original-kvittot i en prm. I bokfringsprogrammet r jag ocks noga med att **ladda upp bilder p varje verifikation**. [Bokfringslagen](https://www.riksdagen.se/sv/dokument-lagar/dokument/svensk-forfattningssamling/bokforingslag-19991078_sfs-1999-1078) sger att originalen ska sparas, s digitala ska sparas digitalt och de p papper sparas p papper. Jag tycker ven att [den hr artikeln](https://vismaspcs.se/ditt-foretagande/byra/de-har-kopiorna-behover-du-inte-skriva-ut) beskriver det bra. ven andra dokument fotar jag av och sparar p Google Drive, som beslut frn Skatteverket t.ex. Vldigt smidigt att kunna lsa allt var man n r.  Det r ganska enkelt att f tag p ett rejlt brandskyddat kassaskp ([#1](http://www.clasohlson.com/se/Dokumentsk%C3%A5p-Chubbsafes-Executive-40/Pr342428000) eller [#2](http://www.biltema.se/sv/Hem/Sakerhet-och-larm/Sakerhetsbox/Kassaskap-brandsakert-2000033385/)) s att man kan spara papper korrekt enligt lagstiftningen.\\n\\nP **bokslutsdagen, sista dagen p rkenskapsret, mste [obetalda fakturor tas upp i bokfring](https://www.verksamt.se/driva/ekonomi-och-bokforing/lopande-bokforing)** ven om du anvnder kontantmetoden. Det beskriver ocks Visma [hr](https://forum.vismaspcs.se/visma_spcs/topics/bokfora-inkop-med-kreditkort-i-visma-eekonomi). Om du har skapat en faktura som nnu inte blivit betald kommer <a href=\\\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\\\" rel=\\\"nofollow\\\">Visma eEkonomi</a> att ge dig fljande meddelande nr du skapar sista **kvartalsmomsen**.\\n\\n> Enligt Kontantmetoden ska du bokfra dina obetalda kundfordringar och leverantrsskulder vid rkenskapsrets slut och redovisa momsen. Detta kommer nu att gras automatiskt. Du br kontrollera att alla inbetalningar och utbetalningar p ret r avstmda innan du fortstter. Vill du fortstta?\\n\\nDet r viktigt att ta en extra titt p de sista transaktionerna innan rkenskapsret r slut s att det inte dykt upp ngot i sista sekunden. I mitt fall hade Danskebank skapat en faktura, och dragit pengarna, fr bankavgifter sista dagen i december.\\n\\nNr rkenskapsret r slut ska **kontrolluppgifter** fr anstllda skickas till Skatteverket. Det hr gller 2017 men r p gng att ndras s att man skickar samma uppgifter i arbetsgivardeklarationen istllet. Men i <a href=\\\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\\\" rel=\\\"nofollow\\\">Visma eEkonomi</a> finns en funktion under *ln* i huvudmenyn som kan anvndas om du skapat lnespecar.\\n\\n* Klicka p *Ny kontrolluppgift*.\\n* Fyll i dina uppgifter.\\n* Spara.\\n* Nu kan man ladda ner en *xml-fil* som kan laddas upp hos Skatteverket fr att fylla i *KU10*-blanketten.\\n\\nVisma har en vldigt bra [gratis broschyr om bokfring](http://download.vismaspcs.se/pdf/bokf%C3%B6ring-f%C3%B6r-nyb%C3%B6rjare.pdf?utm_source=Eloqua&utm_medium=email&utm_content=SE_SP_SI_Onboarding-eEko-Std-4&utm_campaign=SE_SP_SI_Onboarding-eA-Std-1704).\\n\\n# vrigt\\n\\nOm du **veckopendlar** som jag s kanske du har en **lgenhet p arbetsorten**. D kan man tnka sig att man [lter bolaget betala den](http://www.skatter.se/?q=node/2619). Jag blev rekommenderad att ta den privat och betala ut mer ln frn bolaget istllet. D rknar jag p detta vid utbetalning av ln s att ln efter avdrag hamnar p grnsen fr statlig skatt. Avdraget gr jag allts i min privata deklaration. Vljer man att lta bolaget direkt betala lgenheten blir det lite krngligare med bokfring och deklaration. Det kan ocks vara s att Skatteverket ser det som en frmn. S det hr kndes enklast.\\n\\nDet finns bolag som har som **affrsid att bara ha underkonsulter**. De ker p konferensresor och har gemensam kontorslokal precis som vilket annat bolag som helst. Skillnaden r bara att alla r underkonsulter. Detta bolag hjlper dig att starta ditt eget bolag och hitta kunder. De har ramavtal med stora konsultkpare och kan ordna bra timpriser. Ett snt bolag r [Kvadrat](http://www.kvadrat.se/).\\n\\nJag valde frst att ta ver kontraktet jag var p och d g frn anstlld konsult till underkonsult. Senare bytte jag uppdrag och d anslt jag mig till [Kvadrat](http://www.kvadrat.se/).\\n\\nHar du frgor om skatter s r det smidigt att man kan [maila Skatteverket](https://www.skatteverket.se/omoss/kontaktaoss/mejla/).\"}]],\"markups\":[],\"sections\":[[10,0]]}","html":"<p>Efter ver 7 r som anstlld konsult (mjukvaruutvecklare) valde jag nyligen att starta eget aktiebolag. Jag gr precis samma sak nu som jag gjorde som anstlld men numera i mitt eget bolag istllet. Det hr inlgget handlar om hur jag gjorde detta. Googlar man kring att starta eget s hittar man mycket. Men jag saknade ngon som beskriver det utifrn mina frutsttningar, det r vad jag frsker gra hr, eftersom jag tror att mnga har samma frutsttningar som mig. <strong>Oh, and sorry if you don't speak Swedish =) The topic is about starting your own company in Sweden, you are probably not interested.</strong></p>\n<p>Ska ocks sga att allt jag tagit reda p hr r genom googling och jag tar inget ansvar fr att det jag sger hr r korrekt och riktigt! S var kritisk nr du lser vad jag skriver nedan!</p>\n<h1 id=\"varfrstartaeget\">Varfr Starta Eget?</h1>\n<p>Du kan <strong>skatteplanera</strong>. Om du redan innan ret r slut vet <a href=\"http://www.regeringen.se/pressmeddelanden/2017/03/upprakningen-av-skiktgranserna-for-statlig-inkomstskatt-2018-begransas-och-den-sarskilda-inkomstskatten-for-utomlands-bosatta-hojs/\">grns fr statlig skatt</a> och eventuella avdrag du kommer att gra. D kan du rkna ut exakt vilken ln du kan betala ut frn bolaget fr att du som privatperson ska hamna precis p grnsen fr statlig skatt.</p>\n<p>Utver lnen kan du ocks gra en <strong>utdelning</strong>. D skattar du 20% p summan upp till <code>2.75</code> gnger fregende rs <em>inkomstbasbeloppet</em> fr 2018 blir det <code>2.75 * 59300 = 163075</code>. Det r det som kallas frenklingsregeln. Man kan ocks rkna fram en grns, som r hlften av utbetald ln, och anvnda den om den r mer frdelaktig. <a href=\"https://www.foretagande.se/sa-beraknas-skatt-pa-utdelning-3-12-reglerna/\">Den hr blog-posten</a> beskriver detta bra. Frsta ret kan du eventuellt inte anvnda frenklingsregeln, de diskuterar det i <a href=\"https://forum.vismaspcs.se/visma_spcs/topics/utdelning-forsta-aret\">den hr trden</a>.</p>\n<p>Jag har <a href=\"https://docs.google.com/spreadsheets/d/1jfQSSOEINNq3OVc5pYG5NeFkvgcDqOEu1HjzpU2RQm0/edit?usp=sharing\">gjort ett excel-ark</a> fr att <strong>optimera skatten</strong>. Skatteverket har ven <a href=\"https://www.skatteverket.se/privat/sjalvservice/allaetjanster/tjanster/raknautdinskatt.4.18e1b10334ebe8bc80001950.html\">en sida</a> dr man kan rkna ut sin skatt. Du kan ven lsa mer om <a href=\"https://www.verksamt.se/starta/skatter-och-avgifter/aktiebolag\">skatter och avgifter p Verksamt</a>. Se ven <a href=\"http://www.driva-eget.se/kalkyler/lonekalkyl\">den hr sidan</a> fr att f en uppfattning om hur mycket ln man kan ta ut.</p>\n<p>Det finns anledning att vara rdd fr det faktum att man inte fr ngra pengar alls om man inte har ett uppdrag. Men eget bolag kan du anvnda en <strong><a href=\"https://www.skatteverket.se/foretagochorganisationer/foretagare/enskildnaringsverksamhet/periodiseringsfond.4.361dc8c15312eff6fd2b8f2.html\">periodiseringsfond</a></strong> dr du lgger undan pengar mellan rkenskapsr. Du kan allts optimera din ln fr att slippa statlig skatt, lgga undan pengar i en periodiseringsfond och sedan betala ut dem ett r d du har mindre inkomster. P s vis slipper du bde bolagsskatten och statlig inkomstskatt.</p>\n<p>Du r <strong>skrare som egen</strong>. Bolaget kommer frmodligen att dra in mer pengar n vad som r lmpligt att direkt batala ut som ln. Fr du <em>500</em>kr/timme (ett vldigt lgt pris!) s drar du in cirka <em>80 000</em>kr under en mnad. D kan du betala <em>60 000</em>kr i ln. Men du vill frmodligen bara betala ut <em>36 575</em>kr eftersom det r grnsen fr statlig skatt. Att betala den lnen kostar cirka <em>48 000</em>kr fr bolaget och du har allts <em>32 000</em>kr kvar i bolaget. Gr du det varje mnad har du <em>384 000</em>kr kvar i bolaget nr rkenskapsret r slut. Du vill frmodligen anvnda en del fr att gra en utdelning. Men fr att jmfra med att vara anstlld s skulle du kunna betala ut samma ln <em>6</em> mnader in p nsta r, trots att du str helt utan inkomster! Fr att rkna ut hur mycket ln du kan betala ut kan du allts rkna shr <code>timpenning*(52-semesterveckor)*40/12/1.31</code> s kanske <code>500*(52-6)*40/12/1.31 = 58 524</code>.</p>\n<p>Du vljer sjlv om du vill betala in till en <strong>tjnstepension</strong> och i s fall vilken. Jag har tvingats betala till SEB under en lngre tid. Det enda jag bryr mig om r deras fondutbud. I SEB hittade jag bara en fond, <a href=\"http://web.msse.se/SEB/SGF/quicktake.aspx?six=SEB-BDSEKA\">en rntefond</a>, som kndes &quot;ok&quot;. Det r ven en frdel att du kan maximera lnen, gra utdelning och om det efter detta fortfarande finns pengar ver kan du anvnda dem till tjnstepension. Du slipper allts lsa in pengar i en sdan pension om det inte r s att det r en skattemssig frdel. Med tanke p att du, via utdelning, kan f ut kapital med en skatt p under 40% s kanske du inte vill anvnda en tjnstepension. Pengarna du fr ut via utdelningen r ju helt olsta och du kan investera hur du vill.</p>\n<p>Du <strong>slipper ha ln efter lder</strong>. Ju yngre du r, ju mer tjnar du p att ha eget konsultbolag. Den dumma tanken att man ska brja p en lg lneniv och sedan ka ett par procent per r mappar inte alls mot vad kunderna betala fr dig per timme. Kunderna har oftast ett pris p juniorer och ett p seniorer. Att du r 30, 31 eller 40 r gammal spelar ingen roll fr priset. r du yngre anstlld konsult betalar du fr dina ldre kollegors ln och frmner. Det kan mycket vl vara s att du drar in mer pengar n ngon som r 20 r ldre. Med eget bolag mer n dubblade jag min ln.</p>\n<p>Du kan <strong>kpa kontorsmaterial vldigt billigt</strong>. Dator, headset, hrlurar, skrmar... till mindre n halva priset jmfrt med om du kper det privat. D tnker jag inte bara p momsen. Tnk ven p hur mycket pengar bolaget behver betala ut fr att, efter skatt och arbetsgivaravgift, kunna stta in summan p det privata kontot. Sklart mste man tnka p att det man kper gs av fretaget och inte dig privat.</p>\n<p>S fort du har mjlighet att betala ut <strong><a href=\"https://www.vismaspcs.se/visma-support/visma-eget-aktiebolag/content/skattefria_traktamenten.htm\">skattefritt traktamente</a></strong> s ska du gra det. Du slipper tjafs med en arbetsgivare som nekar dig ngot som r s sjlvklart.</p>\n<p>Du kan <strong>ka p vilken konferens du vill</strong> och lta bolaget betala. Det finns ju intressanta utvecklarkonferenser nstan verallt. Du behver bara <a href=\"http://lmgtfy.com/?q=sidney+developer+conference\">hitta en</a> och ka. Inget tjafs med en arbetsgivare som tycker det r fr dyrt. Inga dryga vningar, innan eller p plats, utan bara du som bestmmer vilka frelsningar du tycker r intressanta och som du gr p.</p>\n<p>Jag tycker att de flesta mten r meningslsa och vldigt trkiga. Det blir klart <strong>frre mten</strong> med eget bolag. Du kan spendera din tid med kunden istllet fr trkiga mnadsmten =)</p>\n<p>Du kan f <strong>mindre administrativt jobb</strong>. Som anstlld hade jag kvitton att rapportera varje vecka. Jag kpte tgbiljetter via SJ:s hemsida och fick allts kvittot som PDF. Jag var tvungen att rapporera dem varje vecka med kostnad och moms. Skriva ut ett papper i samband med tidrapportering. Skriva ut mina kvitton. Hffta fast mina kvitton p pappret frn tidrapporteringssystemet. Leta upp kuvert samt frimrke. Leta upp brevlda och posta kuvert med tidrapporten till konsultbolagets kontor. Som egen lgger jag aldrig mer n 2 timmar totalt under en hel mnad p att skta den fullstndiga bokfring inklusive alla kvitton. Allt gr jag digitalt.</p>\n<p>Till sist, och kanske det absolut bsta argumentet. Jag har <strong>alltid sett mig sjlv som mitt eget varumrke</strong>. D r ju inte steget lngt till att faktiskt vara det ocks.</p>\n<h1 id=\"hurstartaeget\">Hur Starta Eget?</h1>\n<p>Jag listar hr kortfattat vad man behver gra. Lngre ner finns vissa steg mer utfrligt beskrivna. Du kan rkna med att det tar 1-2 mnader frn att du skickar in frsta anskan till att allt runt bolaget r klart och du kan brja jobba i det. Skadar inte att titta p <a href=\"https://www.verksamt.se/alla-e-tjanster/din-checklista/aktiebolag\">andra listor ocks</a> fr att skra att du inte glmt ngot.</p>\n<p>Jag valde <strong>aktiebolag</strong> framfr enskild firma. D r bolaget en juridisk person som ocks har ansvaret. En tydlig grns mellan bolag och privat ekonomi allts. Jag kan rekommendera <a href=\"https://www.verksamt.se/fundera/valj-foretagsform\">Verksamts jmfrelse av fretagsformer</a>.</p>\n<p><strong>Skapa anskan</strong> p <a href=\"https://www.verksamt.se/\">Verksamt</a>. Du kommer behva en verksamhetsbeskrivning. Min ser ut shr:</p>\n<blockquote>\n<p>Fretaget ska bedriva konsultverksamhet fretrdesvis inom IT, samt utveckla mjukvaruprodukter, ga och frvalta vrdepapper och utva drmed frenlig verksamhet.</p>\n</blockquote>\n<p>Nr det gller <strong>fretagsnamn</strong> s rekommenderar jag att bara ta ditt eget namn. AB eller aktiebolag mste vara med i namnet. S jag valde <em>Tomas Bjerre AB</em>. Risken om du vljer ngot annat r att Bolagsverket nekar dig fr att namnet liknar ngot som redan finns. Ondigt strul och du kan alltid ndra senare.</p>\n<p>Du kommer behva ange en <strong>SNI-kod</strong>. Jag valde <em>62010</em>.</p>\n<p>Nr du skickat ivg anskan till Bolagsverket kommer de invnta ett <strong>bankintyg</strong>. Ls mer om att vlja bank nedan. Du behver kontakta en bank fr att skapa ett fretagskonto. Banken kommer be dig stta in 50 000 kr p ett speciellt konto. Banken behver kunna tala om fr Bolagsverket att hr finns det 50 000 kr som satts in med avsikt att anvndas fr aktiekapitalet. Nr du gjort detta ger de dig en e-postadress som du sedan ger till Bolagsverket (via verksamt.se). Sedan frgan Bolagsverket banken om pengarna r dr och nr banken svarar ja registreras bolaget. S fort bolaget r skapat s har du sedan ett fretagskonto dr det frn start finns 50 000 kr.</p>\n<p>Jag valde <strong>rkenskapsret</strong> som <em>0101 - 1231</em>. Jag kan dock rekommendera brutet rkenskapsr. Allts att man vljer ett r som inte r ett kalenderr. Frdelen blir d att du kan vlja vilket r du betalar ut lnen p, om du nr statlig skatt 2017 kan du vnta till 2018 med att fortstta betala ut ln. Det r inte helt enkelt att <a href=\"https://www.skatteverket.se/download/18.3aa8c78a1466c584587d059/1408515815569/42405.pdf\">ndra i efterhand</a> och att ndra det bara fr att undvika skatt r inte en godtagbar anledning.</p>\n<p>Nr du startar aktiebolag ska bolaget ha <strong>F-skatt</strong> och du som privatperson har A-skatt. Jag valde <strong>kvartalsmoms</strong>. Som <strong>redovisningsmetod</strong> valde jag <a href=\"https://www.e-conomic.se/bokforingsprogram/ordlista/kontantmetoden\">kontantmetoden</a> (kallas ven bokslutsmetoden). Jag uppfattade den som enklast, se hur man <a href=\"https://forum.vismaspcs.se/visma_spcs/topics/bokfora-inkop-med-kreditkort-i-visma-eekonomi\">bokfr kpt med kreditkort</a> t.ex.</p>\n<p>Det r vldigt svrt att uppskatta den <strong>frvntade vinsten</strong> frsta ret. Andra ret kommer Skatteverket fresl en. Ett tips r att ange den lgt. I mitt fall skulle jag frst betala in 20 000 kr innan jag hunnit f en enda inkomst i bolaget. Skulle du rka ut fr det r det bara att gra en ny preliminr inkomstdeklaration via Skatteverket och ange en lgre frvntad vinst. D fick jag ner denna siffran till 7 000 kr istllet.</p>\n<p>Det finns mnga smidiga <strong>bokfringsprogram</strong>. <a href=\"https://sv.wikipedia.org/wiki/Redovisning\">Redovisningen</a> var nog det jag var mest rdd fr i brjan. Jag mrkte tidigt att nr jag googlade om hur man bokfr olika saker s kom jag ofta in p <a href=\"https://forum.vismaspcs.se/visma_spcs\">Visma:s support forum</a>. Jag har tidigare anvnt deras tidrapportering, PX, vilket suger ngot helt otroligt. Ser ut som en sommarjobbare hackade ihop det fr 15 r sedan och att man inte rrt det sedan dess. Men ven om jag var vldigt skeptisk till detta bolag s valde jag nd <a href=\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\" rel=\"nofollow\">Visma eEkonomi</a> fr bokfring just fr att deras support verkar vara helt exemplarisk. Att direkt bokfra ett kvitto i <a href=\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\" rel=\"nofollow\">Visma eEkonomi</a> r betydligt enklare n det jag tidigare gjort via tidrapportering som anstlld. Du kanske t.ex. vill bokfra <a href=\"https://forum.vismaspcs.se/visma_spcs/topics/8fxz374h0czze?topic-reply-list%5Bsettings%5D%5Bfilter_by%5D=all\">bokfringsprogrammet</a>, <a href=\"https://forum.vismaspcs.se/visma_spcs/topics/7h3lv4csqal8w\">kp av dator och frskring</a> eller <a href=\"https://forum.vismaspcs.se/visma_spcs/topics/con2lpq5fex2f\">kp av tgbiljett</a>. De <a href=\"https://www.youtube.com/watch?v=jGgnxd6uBh4\">gr t.o.m. filmer</a> dr de visar vissa flden. Hoppas jag r trovrdig trots att jag gtt med i deras affiliate-program och fr betalt fr att hnvisa andra dit =)</p>\n<a href=\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\" rel=\"nofollow\">\n<p><img src=\"/content/images/2017/07/affiliate-2014-vismaeekonomi1_728x90_eeko.gif\" alt=\"Visma eEkonomi\"><br>\n</a></p>\n<p>Du lr behva en <strong>mobil</strong> i bolaget. Som jag frstr det r det ok att kpa telefonen p bolaget. ven telefoni och SMS r ok. Datatrafiken dremot kan behva frmnsbeskattas. Det i kombination med att man slipper mnga dryga samtal om man istllet har ett privat abonnemang, gjorde att jag kpte den privat.</p>\n<p>Du lr behva en <strong>ansvarsfrskring</strong>. Jag valde en <a href=\"https://www.if.se/web/se/foretag/varaforsakringar/offert/pages/default.aspx?varde=startforsakring\">frn If</a> och fick betala 5 294 kr. Har du inte det och du rkar ut fr ngot, sg att ngon krver dig p flera miljoner, s konkursar du bara bolaget och slipper undan. Men med en ansvarsfrskring s kan du, kanske, gra rtt fr dig och betala. P s vis blir du en mer attraktiv konsult att anlita och det str ven ofta i kontrakten att du ska ha en frskring.</p>\n<p>Jag valde att kontakta en <strong>redovisningskonsult</strong> som hjlper mig med ekonomiska frgor samt tar hand om <strong>bokslut</strong> / <strong>rsredovisning</strong> / <strong>deklaration</strong>. Jag tar hand om lpande bokfring samt kvartalsmoms, skatter och ln. Det kostar cirka 6 000 kr per r. En redovisningskonsult kan hjlpa dig med allt mjligt i bolaget. Vissa ger dem fullmakt s de kan skta all ekonomi. Jag fick tag p honom genom en bekant som tipsade men annars r det enkelt att googla. Har du valt Visma s <a href=\"https://vismaspcs.se/produkter/redovisning/visma-eekonomi-byra\">kan de hjlpa dig</a>. I <a href=\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\" rel=\"nofollow\">Visma eEkonomi</a> kan du ven skapa en inloggning till din redovisningskonsult.</p>\n<p><strong>Revisor</strong> r valfritt om man <a href=\"http://www.bolagsverket.se/ff/foretagsformer/aktiebolag/starta/revisor\">omstter under 3 miljoner</a>. Det anvnder jag inte.</p>\n<p>Det kan ocks vara bra att ha klart fr sig <strong>hur man hittar kunder</strong>. Det finns mnga rena konsultmklare som tar en procentsats, ofta mellan 10-20% p din timpenning, om du tar ett uppdrag via dem. De har ofta ramavtal med stora konsultkpare. r du redan anstlld som konsult kanske du i brjan fortstter med samma kund fast som underkonsult istllet. Se, t.ex.:</p>\n<ul>\n<li><a href=\"http://www.assistera.se/sv\">Assistera</a></li>\n<li><a href=\"https://www.brainville.com/\">Brainville</a></li>\n<li><a href=\"https://www.eworkgroup.com/se/\">EWork</a></li>\n<li><a href=\"https://cv.experis.se/\">Experis</a></li>\n<li><a href=\"http://www.kvadrat.se/bli-kvadratare/\">Kvadrat</a></li>\n<li><a href=\"https://www.toptal.com/\">Toptal</a></li>\n</ul>\n<p>Och till sist, du kan eventuellt gra <strong><a href=\"http://www.kompred.se/nyttiga-tips/missa-inte-investeraravdraget/\">investeraravdraget</a></strong> i din privata deklaration efter att du startat aktiebolag.</p>\n<h2 id=\"bank\">Bank</h2>\n<p>Jag frgade frst ngra banker via telefon och mail (ICA, Avanza, Swedbank). Det kndes som att de inte riktigt frstod vad jag menade nr jag sa att jag ville ha ett <strong>bankintyg</strong>.</p>\n<h3 id=\"danskebank\">Danskebank</h3>\n<p><strong>Jag valde Danskebank</strong>. Du fyller bara i <a href=\"https://danskebank.se/sv-se/Foretag/Smaforetag/Pages/Product-packages.aspx\">deras formulr</a> s ringer de upp. Danskebank skter allt per telefon och det fungerar mycket bra. De bad inte om ngon affrsplan eller budget utan litade p mig direkt. De visste ocks direkt vad det handlade om och de kndes plitliga. Eftersom jag inte var kund dr sedan tidigare s behvde de skicka lite papper till mig med posten frst. Men inom en vecka hade jag intyget! Snabbt, enkelt, smidigt och inget meningslst krngel.</p>\n<p>Jag valde <em>Danske Business Plus</em> fr 99 kr/mn. <strong><a href=\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\" rel=\"nofollow\">Visma eEkonomi</a> stdjer ven Danskebank</strong> p s vis att man kan klistra in kontoutdraget frn banken in i <a href=\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\" rel=\"nofollow\">Visma eEkonomi</a>, fr att automatiskt skapa bankhndelser. Sedan matchar man dem mot leverantrsfakturor eller verifikationer.</p>\n<h1 id=\"hurdrivaeget\">Hur Driva Eget?</h1>\n<p>Jag har lagt in terkommande hndelser i Google Calendar fr de olika datumen. Sedan angivit att de ska upprepas mnadsvis eller, i vissa fall, rsvis. Jag lgger ungefr 2 timmar varje mnad p att skta fretaget. Vad jag gr r:</p>\n<ul>\n<li>En gng per mnaden\n<ul>\n<li>Importerar transaktioner frn skattekontot frn Skatteverket.</li>\n<li>Importerar transaktioner frn fretagskontot frn banken.</li>\n<li>Skickar fakturor fr mnaden.</li>\n<li>Betalar ut ln, till anstllde.</li>\n<li>Betalar skatt och avgifter till Skatteverket\n<ul>\n<li>Arbetsgivaravgift.</li>\n<li>Inkomstskatt.</li>\n<li>Debiterad preliminrskatt.</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>En gng per kvartal.\n<ul>\n<li>Betalar in kvartalsmoms.</li>\n</ul>\n</li>\n<li>En gng per r.\n<ul>\n<li>Bokslut, rsredovisning, deklaration.</li>\n<li>I januari, skickar in kontrolluppgit fr fregende r till Skatteverket.</li>\n</ul>\n</li>\n</ul>\n<p>Jag valde <strong>kvartalsmoms</strong>, allts att jag efter varje kvartal redovisar och betalar in eventuell moms. Mer information om det finns <a href=\"https://www.verksamt.se/driva/skatter-och-avgifter/moms-redovisa-och-betala\">hr</a>. S fort kvartalet r slut kan man lmna in deklarationen. Man har ungefr 1.5 mnad p sig att lmna in den. ven fr detta har Visma gjort en film som visar <a href=\"https://www.youtube.com/watch?v=gPv_SahMnEw\">hur du gr i eEkonomi</a>. Som jag frstr det anvnder man kontot <em>1630</em> (eller <em>2012</em> om det r enskild firma) just fr att <a href=\"https://forum.vismaspcs.se/visma_spcs/topics/maste-man-anvanda-sig-av-skattekontot-1630\">alla hndelser mot Skatteverket ska g via detta konto</a>. Hur det fungerar med att betala, och f tillbaka moms, <a href=\"https://www.skatteverket.se/foretagochorganisationer/moms/deklareraochbetalamoms/betalaochfatillbakamoms.4.58d555751259e4d66168000354.html\">beskriver Skatteverkets hr</a>. S kortfattat om du har <a href=\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\" rel=\"nofollow\">Visma eEkonomi</a> och kvartalsmoms s ska du vid varje kvartalsslut:</p>\n<ul>\n<li>Skapa en momsredovisning fr kvartalet via bokfring / momsredovisning.</li>\n<li>Ladda ner <em>eskd</em>-filen.</li>\n<li>Skapa en <a href=\"https://www.skatteverket.se/foretagochorganisationer/moms/deklareraochbetalamoms.4.7459477810df5bccdd480006935.html\">momsdeklaration</a> enligt <a href=\"https://www.youtube.com/watch?v=gPv_SahMnEw\">Visma:s video</a>.</li>\n<li>Ladda upp <em>eskd</em>-filen hos <a href=\"https://www.skatteverket.se/foretagochorganisationer/moms/deklareraochbetalamoms/betalaochfatillbakamoms.4.58d555751259e4d66168000354.html\">Skatteverket</a>.</li>\n<li>Ladda ner <a href=\"https://www.youtube.com/watch?v=-7cDnn-NaME\">transaktioner frn Skatteverket till ditt skattekonto</a> och matchar dem sedan mot momshndelsen i dina bokfringshndelser.</li>\n<li>Nr du senare betalat in, eller ftt betalt, skapa och bokfr bankhndelsen p fretagskontot. Det visas i slutet p <a href=\"https://www.youtube.com/watch?v=gPv_SahMnEw\">den hr videon</a>. Tnk p att anvnda <em>1630</em> fr AB och <em>2012</em> fr enskild firma.</li>\n</ul>\n<p>Skatteverket har skickat brev till dig med datum d du ska betala <strong>debiterad preliminrskatt</strong>. Det hr r ngot du betalar varje mnad och baserar sig p din frvntade vinst som du angav i din preliminra inkomstdeklaration. Du har ftt ett besked frn Skatteverket dr det str datum och hur mycket du ska betala. Om du har <a href=\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\" rel=\"nofollow\">Visma eEkonomi</a> kan du flja deras <a href=\"https://www.youtube.com/watch?v=-7cDnn-NaME\">film om skattekontot</a>.</p>\n<ul>\n<li>Betala frn fretagskontot till fretagets skattekonto.</li>\n<li>Importerar bankhndelser frn fretagskontot.</li>\n<li>Ladda ner <a href=\"https://www.youtube.com/watch?v=-7cDnn-NaME\">transaktioner frn Skatteverket till ditt skattekonto</a> och matchar dem sedan mot momshndelsen i dina bokfringshndelser.</li>\n<li>Importera bankhndelsen frn banken till fretagskontot i <a href=\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\" rel=\"nofollow\">Visma eEkonomi</a></li>\n<li>Importera bankhndelsen frn Skatteverket (du kan exportera den till fil) till skattekontot i <a href=\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\" rel=\"nofollow\">Visma eEkonomi</a></li>\n<li>Matcha bankhndelsen p fretagskontot mot hndelsen p skattekontot. Egen kontering mellan egna bankkonton.</li>\n<li>Nr pengarna dragits av Skatteverket frn Skattekontot, importera den hndelsen.</li>\n<li>Matcha hndelsen mot bokfringsfrslaget <em>Debiterad preliminrskatt</em>.</li>\n</ul>\n<p>Nr du ska betala ut <strong>Ln</strong> behver du betala <em>skatt</em>, <em>arbetsgivaravgift</em> samt sjlva <em>lnen</em>. Bde <em>skatt</em> och <em>arbetsgivaravgift</em> betalas till fretagets <em>skattekonto</em> s det r 2 betalningar som behver gras frn fretagskontot. Om du anvnder <a href=\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\" rel=\"nofollow\">Visma eEkonomi</a> kan du gra shr. Finns ven en <a href=\"https://www.youtube.com/watch?v=ig2C9gQg2Eg\">film hr</a> och en <a href=\"https://forum.vismaspcs.se/visma_spcs/topics/bokfora-lon-i-eekonomi\">bra trd</a> om detta i supportforumet.</p>\n<ul>\n<li>Under <em>ln</em> i huvudnenyn vljer du <em>anstllda</em>. Lgg upp den anstllde. Du kommer behva <em>Skattetabell</em> att anvnda. Den anstllde kan <a href=\"https://www.skatteverket.se/\">logga in</a> hos Skatteverket och hittar d skattetabell under &quot;Skatter och deklarationer&quot;.</li>\n<li>Under <em>ln</em> i huvudnenyn vljer du <em>lnebesked</em> och skapar ett nytt.</li>\n<li>Ange lnen och vlj bokfr.</li>\n<li>Logga in p banken och betala ut lnen, efter skatt, till den anstlldes konto.</li>\n<li>Importera bankhndelsen till <em>fretagskontot</em> via <em>kassa och bankhndelser</em>.</li>\n<li><a href=\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\" rel=\"nofollow\">Visma eEkonomi</a> kommer fresl att du matchar bankhndelsen mot lneutbetalningen, gr det. Nu r du klar med lnen, och nsta moment r att betala skatt och arbetsgivaravgift.</li>\n</ul>\n<p><strong>Arbetsgivardeklaration</strong> lmnas enkelt via <a href=\"https://www.skatteverket.se/foretagochorganisationer/arbetsgivare/lamnaarbetsgivardeklaration.4.6a6688231259309ff1f800029116.html\">Skatteverkets webbsida</a>.</p>\n<ul>\n<li>Om du inte har betalat ut ngon ln stter du bara <strong>0</strong> i de obligatoriska flten och skickar in.</li>\n<li>Om du har betalat ut ln, och anvnder <a href=\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\" rel=\"nofollow\">Visma eEkonomi</a>.\n<ul>\n<li>G in under <em>ln</em> i huvudmenyn och vlj <em>arbetsgivardeklaration</em>.</li>\n<li>Skapa ny.</li>\n<li>Vlj mnaden d lnen betaldes ut.</li>\n<li>Vlj <em>bokfr</em>.</li>\n<li>Nu kan du <a href=\"https://www.youtube.com/watch?v=ig2C9gQg2Eg\">exportera en fil</a> om du klickar p <em>tgrder</em> fr deklarationen.</li>\n<li><a href=\"https://www.skatteverket.se/foretagochorganisationer/arbetsgivare/lamnaarbetsgivardeklaration.4.6a6688231259309ff1f800029116.html\">Lmna in arbetsgivardeklarationen</a> hos Skatteverket genom att importera filen.</li>\n<li>P kvittensen visas ett bankgiro och OCR att anvnda fr att betala in skatten till fretagets skattekonto.</li>\n<li>Betala in summan frn fretagets bankkonto.</li>\n<li>Importera bankhndelsen frn banken till fretagskontot i <a href=\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\" rel=\"nofollow\">Visma eEkonomi</a></li>\n<li>Importera bankhndelsen frn Skatteverket (du kan exportera den till fil) till skattekontot i <a href=\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\" rel=\"nofollow\">Visma eEkonomi</a></li>\n<li>Matcha bankhndelsen p fretagskontot mot hndelsen p skattekontot. Egen kontering mellan egna bankkonton.</li>\n<li>Nr pengarna dragits av Skatteverket frn Skattekontot, importera den hndelsen.</li>\n<li>Matcha hndelsen mot bokfringsfrslaget arbetsgivardeklaration. Skatteverkat drar arbetsgivardeklartionen i 2 transaktioner, du behver <a href=\"https://forum.vismaspcs.se/visma_spcs/topics/hur-matchar-jag-tva-belopp-pa-skattekontot-mot-en-arbetsgivardeklaration\">manuellt sl ihop dem</a> fr att kunna anvnda det hr bokfringsfslaget. Men annars r det <em>1630</em> som krediteras och <em>2710</em> (personalskatt) samt <em>2731</em> (arbetsgivaravgift) som debiteras. Jag tycker ven <a href=\"https://www.blinfo.se/foretagskunskap/bokfora-lon__15472\">den hr sidan</a> r bra hr.</li>\n</ul>\n</li>\n</ul>\n<p><a href=\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\" rel=\"nofollow\">Visma eEkonomi</a> har en frdig mall fr <strong>fakturor</strong>. Du anger ditt fretags bankgiro, och/eller kontonummer, lgger upp kunder och artiklar. Sedan kan du enkelt skapa fakturor som du sedan kan skriva ut, spara som PDF eller maila.</p>\n<p>Om du <strong>betalar ut traktamente</strong> behver du kunna bevisa att <a href=\"https://www.vismaspcs.se/visma-support/visma-eget-aktiebolag/content/skattefria_traktamenten.htm\">resorna gt rum och varit tjnsteresor</a>. Drfr kan det vara klokt att fra anteckningar fr resor. I mitt fall ker jag alltid tg och kommer hnvisa till tgbiljetterna om jag fr revision av Skatteverket. Jag skapar exceldokument, med utrkningen, som jag sedan exporterar till PDF och sparar fr att motivera traktamentet.</p>\n<p><img src=\"/content/images/2017/11/traktamente-utr.png\" alt=\"Traktamente\"></p>\n<p>Man hr ibland uttrycket <strong>skriva av</strong> och jag tror mnga missfrstr det, kanske ven jag =) Men jag tolkar det som att allt man kper fr under ett halvt prisbasbelopp (ungefr 22 000 kr) skrivs av direkt, kostar det mer skriver man av det under flera r. Att <em>skriva av</em> innebr att man inte tar upp det som en tillgng, en inventarie, i bokfringen. Det r dock inte samma sak som att man fr ge bort prylen till sig sjlv eller ngon annan. Men jag r osker, <a href=\"https://www.flashback.org/p49423662\">och mnga med mig</a>.</p>\n<p>Att bokfra kp gjorda med <strong>kreditkort</strong> r lite speciellt men det har Visma en vldigt <a href=\"https://forum.vismaspcs.se/visma_spcs/topics/bokfora-inkop-med-kreditkort-i-visma-eekonomi\">bra artikel</a> om.</p>\n<p>Jag sparar alltid alla <strong>kvitton</strong> direkt p Google Drive. r det inte digitalt fotar jag av med mobilen, laddar upp bilden och sparar ven original-kvittot i en prm. I bokfringsprogrammet r jag ocks noga med att <strong>ladda upp bilder p varje verifikation</strong>. <a href=\"https://www.riksdagen.se/sv/dokument-lagar/dokument/svensk-forfattningssamling/bokforingslag-19991078_sfs-1999-1078\">Bokfringslagen</a> sger att originalen ska sparas, s digitala ska sparas digitalt och de p papper sparas p papper. Jag tycker ven att <a href=\"https://vismaspcs.se/ditt-foretagande/byra/de-har-kopiorna-behover-du-inte-skriva-ut\">den hr artikeln</a> beskriver det bra. ven andra dokument fotar jag av och sparar p Google Drive, som beslut frn Skatteverket t.ex. Vldigt smidigt att kunna lsa allt var man n r.  Det r ganska enkelt att f tag p ett rejlt brandskyddat kassaskp (<a href=\"http://www.clasohlson.com/se/Dokumentsk%C3%A5p-Chubbsafes-Executive-40/Pr342428000\">#1</a> eller <a href=\"http://www.biltema.se/sv/Hem/Sakerhet-och-larm/Sakerhetsbox/Kassaskap-brandsakert-2000033385/\">#2</a>) s att man kan spara papper korrekt enligt lagstiftningen.</p>\n<p>P <strong>bokslutsdagen, sista dagen p rkenskapsret, mste <a href=\"https://www.verksamt.se/driva/ekonomi-och-bokforing/lopande-bokforing\">obetalda fakturor tas upp i bokfring</a></strong> ven om du anvnder kontantmetoden. Det beskriver ocks Visma <a href=\"https://forum.vismaspcs.se/visma_spcs/topics/bokfora-inkop-med-kreditkort-i-visma-eekonomi\">hr</a>. Om du har skapat en faktura som nnu inte blivit betald kommer <a href=\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\" rel=\"nofollow\">Visma eEkonomi</a> att ge dig fljande meddelande nr du skapar sista <strong>kvartalsmomsen</strong>.</p>\n<blockquote>\n<p>Enligt Kontantmetoden ska du bokfra dina obetalda kundfordringar och leverantrsskulder vid rkenskapsrets slut och redovisa momsen. Detta kommer nu att gras automatiskt. Du br kontrollera att alla inbetalningar och utbetalningar p ret r avstmda innan du fortstter. Vill du fortstta?</p>\n</blockquote>\n<p>Det r viktigt att ta en extra titt p de sista transaktionerna innan rkenskapsret r slut s att det inte dykt upp ngot i sista sekunden. I mitt fall hade Danskebank skapat en faktura, och dragit pengarna, fr bankavgifter sista dagen i december.</p>\n<p>Nr rkenskapsret r slut ska <strong>kontrolluppgifter</strong> fr anstllda skickas till Skatteverket. Det hr gller 2017 men r p gng att ndras s att man skickar samma uppgifter i arbetsgivardeklarationen istllet. Men i <a href=\"https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282\" rel=\"nofollow\">Visma eEkonomi</a> finns en funktion under <em>ln</em> i huvudmenyn som kan anvndas om du skapat lnespecar.</p>\n<ul>\n<li>Klicka p <em>Ny kontrolluppgift</em>.</li>\n<li>Fyll i dina uppgifter.</li>\n<li>Spara.</li>\n<li>Nu kan man ladda ner en <em>xml-fil</em> som kan laddas upp hos Skatteverket fr att fylla i <em>KU10</em>-blanketten.</li>\n</ul>\n<p>Visma har en vldigt bra <a href=\"http://download.vismaspcs.se/pdf/bokf%C3%B6ring-f%C3%B6r-nyb%C3%B6rjare.pdf?utm_source=Eloqua&amp;utm_medium=email&amp;utm_content=SE_SP_SI_Onboarding-eEko-Std-4&amp;utm_campaign=SE_SP_SI_Onboarding-eA-Std-1704\">gratis broschyr om bokfring</a>.</p>\n<h1 id=\"vrigt\">vrigt</h1>\n<p>Om du <strong>veckopendlar</strong> som jag s kanske du har en <strong>lgenhet p arbetsorten</strong>. D kan man tnka sig att man <a href=\"http://www.skatter.se/?q=node/2619\">lter bolaget betala den</a>. Jag blev rekommenderad att ta den privat och betala ut mer ln frn bolaget istllet. D rknar jag p detta vid utbetalning av ln s att ln efter avdrag hamnar p grnsen fr statlig skatt. Avdraget gr jag allts i min privata deklaration. Vljer man att lta bolaget direkt betala lgenheten blir det lite krngligare med bokfring och deklaration. Det kan ocks vara s att Skatteverket ser det som en frmn. S det hr kndes enklast.</p>\n<p>Det finns bolag som har som <strong>affrsid att bara ha underkonsulter</strong>. De ker p konferensresor och har gemensam kontorslokal precis som vilket annat bolag som helst. Skillnaden r bara att alla r underkonsulter. Detta bolag hjlper dig att starta ditt eget bolag och hitta kunder. De har ramavtal med stora konsultkpare och kan ordna bra timpriser. Ett snt bolag r <a href=\"http://www.kvadrat.se/\">Kvadrat</a>.</p>\n<p>Jag valde frst att ta ver kontraktet jag var p och d g frn anstlld konsult till underkonsult. Senare bytte jag uppdrag och d anslt jag mig till <a href=\"http://www.kvadrat.se/\">Kvadrat</a>.</p>\n<p>Har du frgor om skatter s r det smidigt att man kan <a href=\"https://www.skatteverket.se/omoss/kontaktaoss/mejla/\">maila Skatteverket</a>.</p>\n","comment_id":"31","plaintext":"Efter ver 7 r som anstlld konsult (mjukvaruutvecklare) valde jag nyligen att\nstarta eget aktiebolag. Jag gr precis samma sak nu som jag gjorde som anstlld\nmen numera i mitt eget bolag istllet. Det hr inlgget handlar om hur jag\ngjorde detta. Googlar man kring att starta eget s hittar man mycket. Men jag\nsaknade ngon som beskriver det utifrn mina frutsttningar, det r vad jag\nfrsker gra hr, eftersom jag tror att mnga har samma frutsttningar som\nmig. Oh, and sorry if you don't speak Swedish =) The topic is about starting\nyour own company in Sweden, you are probably not interested.\n\nSka ocks sga att allt jag tagit reda p hr r genom googling och jag tar\ninget ansvar fr att det jag sger hr r korrekt och riktigt! S var kritisk\nnr du lser vad jag skriver nedan!\n\nVarfr Starta Eget?\nDu kan skatteplanera. Om du redan innan ret r slut vet grns fr statlig skatt\n[http://www.regeringen.se/pressmeddelanden/2017/03/upprakningen-av-skiktgranserna-for-statlig-inkomstskatt-2018-begransas-och-den-sarskilda-inkomstskatten-for-utomlands-bosatta-hojs/] \n och eventuella avdrag du kommer att gra. D kan du rkna ut exakt vilken ln\ndu kan betala ut frn bolaget fr att du som privatperson ska hamna precis p\ngrnsen fr statlig skatt.\n\nUtver lnen kan du ocks gra en utdelning. D skattar du 20% p summan upp\ntill 2.75  gnger fregende rs inkomstbasbeloppet  fr 2018 blir det 2.75 *\n59300 = 163075. Det r det som kallas frenklingsregeln. Man kan ocks rkna\nfram en grns, som r hlften av utbetald ln, och anvnda den om den r mer\nfrdelaktig. Den hr blog-posten\n[https://www.foretagande.se/sa-beraknas-skatt-pa-utdelning-3-12-reglerna/] \nbeskriver detta bra. Frsta ret kan du eventuellt inte anvnda\nfrenklingsregeln, de diskuterar det i den hr trden\n[https://forum.vismaspcs.se/visma_spcs/topics/utdelning-forsta-aret].\n\nJag har gjort ett excel-ark\n[https://docs.google.com/spreadsheets/d/1jfQSSOEINNq3OVc5pYG5NeFkvgcDqOEu1HjzpU2RQm0/edit?usp=sharing] \n fr att optimera skatten. Skatteverket har ven en sida\n[https://www.skatteverket.se/privat/sjalvservice/allaetjanster/tjanster/raknautdinskatt.4.18e1b10334ebe8bc80001950.html] \n dr man kan rkna ut sin skatt. Du kan ven lsa mer om skatter och avgifter\np\nVerksamt [https://www.verksamt.se/starta/skatter-och-avgifter/aktiebolag]. Se\nven den hr sidan [http://www.driva-eget.se/kalkyler/lonekalkyl]  fr att f en\nuppfattning om hur mycket ln man kan ta ut.\n\nDet finns anledning att vara rdd fr det faktum att man inte fr ngra pengar\nalls om man inte har ett uppdrag. Men eget bolag kan du anvnda en \nperiodiseringsfond\n[https://www.skatteverket.se/foretagochorganisationer/foretagare/enskildnaringsverksamhet/periodiseringsfond.4.361dc8c15312eff6fd2b8f2.html] \n dr du lgger undan pengar mellan rkenskapsr. Du kan allts optimera din ln\nfr att slippa statlig skatt, lgga undan pengar i en periodiseringsfond och\nsedan betala ut dem ett r d du har mindre inkomster. P s vis slipper du bde\nbolagsskatten och statlig inkomstskatt.\n\nDu r skrare som egen. Bolaget kommer frmodligen att dra in mer pengar n vad\nsom r lmpligt att direkt batala ut som ln. Fr du 500kr/timme (ett vldigt\nlgt pris!) s drar du in cirka 80 000kr under en mnad. D kan du betala 60 000\nkr i ln. Men du vill frmodligen bara betala ut 36 575kr eftersom det r\ngrnsen fr statlig skatt. Att betala den lnen kostar cirka 48 000kr fr\nbolaget och du har allts 32 000kr kvar i bolaget. Gr du det varje mnad har du\n 384 000kr kvar i bolaget nr rkenskapsret r slut. Du vill frmodligen\nanvnda en del fr att gra en utdelning. Men fr att jmfra med att vara\nanstlld s skulle du kunna betala ut samma ln 6  mnader in p nsta r, trots\natt du str helt utan inkomster! Fr att rkna ut hur mycket ln du kan betala\nut kan du allts rkna shr timpenning*(52-semesterveckor)*40/12/1.31  s\nkanske 500*(52-6)*40/12/1.31 = 58 524.\n\nDu vljer sjlv om du vill betala in till en tjnstepension  och i s fall\nvilken. Jag har tvingats betala till SEB under en lngre tid. Det enda jag bryr\nmig om r deras fondutbud. I SEB hittade jag bara en fond, en rntefond\n[http://web.msse.se/SEB/SGF/quicktake.aspx?six=SEB-BDSEKA], som kndes \"ok\". Det\nr ven en frdel att du kan maximera lnen, gra utdelning och om det efter\ndetta fortfarande finns pengar ver kan du anvnda dem till tjnstepension. Du\nslipper allts lsa in pengar i en sdan pension om det inte r s att det r en\nskattemssig frdel. Med tanke p att du, via utdelning, kan f ut kapital med\nen skatt p under 40% s kanske du inte vill anvnda en tjnstepension. Pengarna\ndu fr ut via utdelningen r ju helt olsta och du kan investera hur du vill.\n\nDu slipper ha ln efter lder. Ju yngre du r, ju mer tjnar du p att ha eget\nkonsultbolag. Den dumma tanken att man ska brja p en lg lneniv och sedan\nka ett par procent per r mappar inte alls mot vad kunderna betala fr dig per\ntimme. Kunderna har oftast ett pris p juniorer och ett p seniorer. Att du r\n30, 31 eller 40 r gammal spelar ingen roll fr priset. r du yngre anstlld\nkonsult betalar du fr dina ldre kollegors ln och frmner. Det kan mycket vl\nvara s att du drar in mer pengar n ngon som r 20 r ldre. Med eget bolag\nmer n dubblade jag min ln.\n\nDu kan kpa kontorsmaterial vldigt billigt. Dator, headset, hrlurar,\nskrmar... till mindre n halva priset jmfrt med om du kper det privat. D\ntnker jag inte bara p momsen. Tnk ven p hur mycket pengar bolaget behver\nbetala ut fr att, efter skatt och arbetsgivaravgift, kunna stta in summan p\ndet privata kontot. Sklart mste man tnka p att det man kper gs av\nfretaget och inte dig privat.\n\nS fort du har mjlighet att betala ut skattefritt traktamente\n[https://www.vismaspcs.se/visma-support/visma-eget-aktiebolag/content/skattefria_traktamenten.htm] \n s ska du gra det. Du slipper tjafs med en arbetsgivare som nekar dig ngot\nsom r s sjlvklart.\n\nDu kan ka p vilken konferens du vill  och lta bolaget betala. Det finns ju\nintressanta utvecklarkonferenser nstan verallt. Du behver bara hitta en\n[http://lmgtfy.com/?q=sidney+developer+conference]  och ka. Inget tjafs med en\narbetsgivare som tycker det r fr dyrt. Inga dryga vningar, innan eller p\nplats, utan bara du som bestmmer vilka frelsningar du tycker r intressanta\noch som du gr p.\n\nJag tycker att de flesta mten r meningslsa och vldigt trkiga. Det blir\nklart frre mten  med eget bolag. Du kan spendera din tid med kunden istllet\nfr trkiga mnadsmten =)\n\nDu kan f mindre administrativt jobb. Som anstlld hade jag kvitton att\nrapportera varje vecka. Jag kpte tgbiljetter via SJ:s hemsida och fick allts\nkvittot som PDF. Jag var tvungen att rapporera dem varje vecka med kostnad och\nmoms. Skriva ut ett papper i samband med tidrapportering. Skriva ut mina\nkvitton. Hffta fast mina kvitton p pappret frn tidrapporteringssystemet. Leta\nupp kuvert samt frimrke. Leta upp brevlda och posta kuvert med tidrapporten\ntill konsultbolagets kontor. Som egen lgger jag aldrig mer n 2 timmar totalt\nunder en hel mnad p att skta den fullstndiga bokfring inklusive alla\nkvitton. Allt gr jag digitalt.\n\nTill sist, och kanske det absolut bsta argumentet. Jag har alltid sett mig\nsjlv som mitt eget varumrke. D r ju inte steget lngt till att faktiskt vara\ndet ocks.\n\nHur Starta Eget?\nJag listar hr kortfattat vad man behver gra. Lngre ner finns vissa steg mer\nutfrligt beskrivna. Du kan rkna med att det tar 1-2 mnader frn att du\nskickar in frsta anskan till att allt runt bolaget r klart och du kan brja\njobba i det. Skadar inte att titta p andra listor ocks\n[https://www.verksamt.se/alla-e-tjanster/din-checklista/aktiebolag]  fr att\nskra att du inte glmt ngot.\n\nJag valde aktiebolag  framfr enskild firma. D r bolaget en juridisk person\nsom ocks har ansvaret. En tydlig grns mellan bolag och privat ekonomi allts.\nJag kan rekommendera Verksamts jmfrelse av fretagsformer\n[https://www.verksamt.se/fundera/valj-foretagsform].\n\nSkapa anskan  p Verksamt [https://www.verksamt.se/]. Du kommer behva en\nverksamhetsbeskrivning. Min ser ut shr:\n\nFretaget ska bedriva konsultverksamhet fretrdesvis inom IT, samt utveckla\nmjukvaruprodukter, ga och frvalta vrdepapper och utva drmed frenlig\nverksamhet.\n\nNr det gller fretagsnamn  s rekommenderar jag att bara ta ditt eget namn. AB\neller aktiebolag mste vara med i namnet. S jag valde Tomas Bjerre AB. Risken\nom du vljer ngot annat r att Bolagsverket nekar dig fr att namnet liknar\nngot som redan finns. Ondigt strul och du kan alltid ndra senare.\n\nDu kommer behva ange en SNI-kod. Jag valde 62010.\n\nNr du skickat ivg anskan till Bolagsverket kommer de invnta ett bankintyg.\nLs mer om att vlja bank nedan. Du behver kontakta en bank fr att skapa ett\nfretagskonto. Banken kommer be dig stta in 50 000 kr p ett speciellt konto.\nBanken behver kunna tala om fr Bolagsverket att hr finns det 50 000 kr som\nsatts in med avsikt att anvndas fr aktiekapitalet. Nr du gjort detta ger de\ndig en e-postadress som du sedan ger till Bolagsverket (via verksamt.se). Sedan\nfrgan Bolagsverket banken om pengarna r dr och nr banken svarar ja\nregistreras bolaget. S fort bolaget r skapat s har du sedan ett fretagskonto\ndr det frn start finns 50 000 kr.\n\nJag valde rkenskapsret  som 0101 - 1231. Jag kan dock rekommendera brutet\nrkenskapsr. Allts att man vljer ett r som inte r ett kalenderr. Frdelen\nblir d att du kan vlja vilket r du betalar ut lnen p, om du nr statlig\nskatt 2017 kan du vnta till 2018 med att fortstta betala ut ln. Det r inte\nhelt enkelt att ndra i efterhand\n[https://www.skatteverket.se/download/18.3aa8c78a1466c584587d059/1408515815569/42405.pdf] \n och att ndra det bara fr att undvika skatt r inte en godtagbar anledning.\n\nNr du startar aktiebolag ska bolaget ha F-skatt  och du som privatperson har\nA-skatt. Jag valde kvartalsmoms. Som redovisningsmetod  valde jag kontantmetoden\n[https://www.e-conomic.se/bokforingsprogram/ordlista/kontantmetoden]  (kallas\nven bokslutsmetoden). Jag uppfattade den som enklast, se hur man bokfr kpt\nmed kreditkort\n[https://forum.vismaspcs.se/visma_spcs/topics/bokfora-inkop-med-kreditkort-i-visma-eekonomi] \n t.ex.\n\nDet r vldigt svrt att uppskatta den frvntade vinsten  frsta ret. Andra\nret kommer Skatteverket fresl en. Ett tips r att ange den lgt. I mitt fall\nskulle jag frst betala in 20 000 kr innan jag hunnit f en enda inkomst i\nbolaget. Skulle du rka ut fr det r det bara att gra en ny preliminr\ninkomstdeklaration via Skatteverket och ange en lgre frvntad vinst. D fick\njag ner denna siffran till 7 000 kr istllet.\n\nDet finns mnga smidiga bokfringsprogram. Redovisningen\n[https://sv.wikipedia.org/wiki/Redovisning]  var nog det jag var mest rdd fr i\nbrjan. Jag mrkte tidigt att nr jag googlade om hur man bokfr olika saker s\nkom jag ofta in p Visma:s support forum [https://forum.vismaspcs.se/visma_spcs]\n. Jag har tidigare anvnt deras tidrapportering, PX, vilket suger ngot helt\notroligt. Ser ut som en sommarjobbare hackade ihop det fr 15 r sedan och att\nman inte rrt det sedan dess. Men ven om jag var vldigt skeptisk till detta\nbolag s valde jag nd Visma eEkonomi\n[https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282] \nfr bokfring just fr att deras support verkar vara helt exemplarisk. Att\ndirekt bokfra ett kvitto i Visma eEkonomi\n[https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282] \nr betydligt enklare n det jag tidigare gjort via tidrapportering som anstlld.\nDu kanske t.ex. vill bokfra bokfringsprogrammet\n[https://forum.vismaspcs.se/visma_spcs/topics/8fxz374h0czze?topic-reply-list%5Bsettings%5D%5Bfilter_by%5D=all]\n, kp av dator och frskring\n[https://forum.vismaspcs.se/visma_spcs/topics/7h3lv4csqal8w]  eller kp av\ntgbiljett [https://forum.vismaspcs.se/visma_spcs/topics/con2lpq5fex2f]. De gr\nt.o.m. filmer [https://www.youtube.com/watch?v=jGgnxd6uBh4]  dr de visar vissa\nflden. Hoppas jag r trovrdig trots att jag gtt med i deras affiliate-program\noch fr betalt fr att hnvisa andra dit =)\n\n[https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282]\n\nDu lr behva en mobil  i bolaget. Som jag frstr det r det ok att kpa\ntelefonen p bolaget. ven telefoni och SMS r ok. Datatrafiken dremot kan\nbehva frmnsbeskattas. Det i kombination med att man slipper mnga dryga\nsamtal om man istllet har ett privat abonnemang, gjorde att jag kpte den\nprivat.\n\nDu lr behva en ansvarsfrskring. Jag valde en frn If\n[https://www.if.se/web/se/foretag/varaforsakringar/offert/pages/default.aspx?varde=startforsakring] \n och fick betala 5 294 kr. Har du inte det och du rkar ut fr ngot, sg att\nngon krver dig p flera miljoner, s konkursar du bara bolaget och slipper\nundan. Men med en ansvarsfrskring s kan du, kanske, gra rtt fr dig och\nbetala. P s vis blir du en mer attraktiv konsult att anlita och det str ven\nofta i kontrakten att du ska ha en frskring.\n\nJag valde att kontakta en redovisningskonsult  som hjlper mig med ekonomiska\nfrgor samt tar hand om bokslut  / rsredovisning  / deklaration. Jag tar hand\nom lpande bokfring samt kvartalsmoms, skatter och ln. Det kostar cirka 6 000\nkr per r. En redovisningskonsult kan hjlpa dig med allt mjligt i bolaget.\nVissa ger dem fullmakt s de kan skta all ekonomi. Jag fick tag p honom genom\nen bekant som tipsade men annars r det enkelt att googla. Har du valt Visma s \nkan de hjlpa dig\n[https://vismaspcs.se/produkter/redovisning/visma-eekonomi-byra]. I Visma\neEkonomi\n[https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282] \nkan du ven skapa en inloggning till din redovisningskonsult.\n\nRevisor  r valfritt om man omstter under 3 miljoner\n[http://www.bolagsverket.se/ff/foretagsformer/aktiebolag/starta/revisor]. Det\nanvnder jag inte.\n\nDet kan ocks vara bra att ha klart fr sig hur man hittar kunder. Det finns\nmnga rena konsultmklare som tar en procentsats, ofta mellan 10-20% p din\ntimpenning, om du tar ett uppdrag via dem. De har ofta ramavtal med stora\nkonsultkpare. r du redan anstlld som konsult kanske du i brjan fortstter\nmed samma kund fast som underkonsult istllet. Se, t.ex.:\n\n * Assistera [http://www.assistera.se/sv]\n * Brainville [https://www.brainville.com/]\n * EWork [https://www.eworkgroup.com/se/]\n * Experis [https://cv.experis.se/]\n * Kvadrat [http://www.kvadrat.se/bli-kvadratare/]\n * Toptal [https://www.toptal.com/]\n\nOch till sist, du kan eventuellt gra investeraravdraget\n[http://www.kompred.se/nyttiga-tips/missa-inte-investeraravdraget/]  i din\nprivata deklaration efter att du startat aktiebolag.\n\nBank\nJag frgade frst ngra banker via telefon och mail (ICA, Avanza, Swedbank). Det\nkndes som att de inte riktigt frstod vad jag menade nr jag sa att jag ville\nha ett bankintyg.\n\nDanskebank\nJag valde Danskebank. Du fyller bara i deras formulr\n[https://danskebank.se/sv-se/Foretag/Smaforetag/Pages/Product-packages.aspx]  s\nringer de upp. Danskebank skter allt per telefon och det fungerar mycket bra.\nDe bad inte om ngon affrsplan eller budget utan litade p mig direkt. De\nvisste ocks direkt vad det handlade om och de kndes plitliga. Eftersom jag\ninte var kund dr sedan tidigare s behvde de skicka lite papper till mig med\nposten frst. Men inom en vecka hade jag intyget! Snabbt, enkelt, smidigt och\ninget meningslst krngel.\n\nJag valde Danske Business Plus  fr 99 kr/mn. Visma eEkonomi\n[https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282] \nstdjer ven Danskebank  p s vis att man kan klistra in kontoutdraget frn\nbanken in i Visma eEkonomi\n[https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282],\nfr att automatiskt skapa bankhndelser. Sedan matchar man dem mot\nleverantrsfakturor eller verifikationer.\n\nHur Driva Eget?\nJag har lagt in terkommande hndelser i Google Calendar fr de olika datumen.\nSedan angivit att de ska upprepas mnadsvis eller, i vissa fall, rsvis. Jag\nlgger ungefr 2 timmar varje mnad p att skta fretaget. Vad jag gr r:\n\n * En gng per mnaden * Importerar transaktioner frn skattekontot frn\n      Skatteverket.\n    * Importerar transaktioner frn fretagskontot frn\n      banken.\n    * Skickar fakturor fr mnaden.\n    * Betalar ut ln, till anstllde.\n    * Betalar skatt och avgifter till Skatteverket * Arbetsgivaravgift.\n       * Inkomstskatt.\n       * Debiterad preliminrskatt.\n      \n      \n   \n   \n * En gng per kvartal. * Betalar in kvartalsmoms.\n   \n   \n * En gng per r. * Bokslut, rsredovisning, deklaration.\n    * I januari, skickar in kontrolluppgit fr fregende r till\n      Skatteverket.\n   \n   \n\nJag valde kvartalsmoms, allts att jag efter varje kvartal redovisar och betalar\nin eventuell moms. Mer information om det finns hr\n[https://www.verksamt.se/driva/skatter-och-avgifter/moms-redovisa-och-betala].\nS fort kvartalet r slut kan man lmna in deklarationen. Man har ungefr 1.5\nmnad p sig att lmna in den. ven fr detta har Visma gjort en film som visar \nhur du gr i eEkonomi [https://www.youtube.com/watch?v=gPv_SahMnEw]. Som jag\nfrstr det anvnder man kontot 1630  (eller 2012  om det r enskild firma) just\nfr att alla hndelser mot Skatteverket ska g via detta konto\n[https://forum.vismaspcs.se/visma_spcs/topics/maste-man-anvanda-sig-av-skattekontot-1630]\n. Hur det fungerar med att betala, och f tillbaka moms, beskriver\nSkatteverkets\nhr\n[https://www.skatteverket.se/foretagochorganisationer/moms/deklareraochbetalamoms/betalaochfatillbakamoms.4.58d555751259e4d66168000354.html]\n. S kortfattat om du har Visma eEkonomi\n[https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282] \noch kvartalsmoms s ska du vid varje kvartalsslut:\n\n * Skapa en momsredovisning fr kvartalet via bokfring / momsredovisning.\n * Ladda ner eskd-filen.\n * Skapa en momsdeklaration\n   [https://www.skatteverket.se/foretagochorganisationer/moms/deklareraochbetalamoms.4.7459477810df5bccdd480006935.html] \n    enligt Visma:s video [https://www.youtube.com/watch?v=gPv_SahMnEw].\n * Ladda upp eskd-filen hos Skatteverket\n   [https://www.skatteverket.se/foretagochorganisationer/moms/deklareraochbetalamoms/betalaochfatillbakamoms.4.58d555751259e4d66168000354.html]\n   .\n * Ladda ner transaktioner frn Skatteverket till ditt skattekonto\n   [https://www.youtube.com/watch?v=-7cDnn-NaME]  och matchar dem sedan mot\n   momshndelsen i dina bokfringshndelser.\n * Nr du senare betalat in, eller ftt betalt, skapa och bokfr bankhndelsen\n   p fretagskontot. Det visas i slutet p den hr videon\n   [https://www.youtube.com/watch?v=gPv_SahMnEw]. Tnk p att anvnda 1630  fr\n   AB och 2012  fr enskild firma.\n\nSkatteverket har skickat brev till dig med datum d du ska betala debiterad\npreliminrskatt. Det hr r ngot du betalar varje mnad och baserar sig p din\nfrvntade vinst som du angav i din preliminra inkomstdeklaration. Du har ftt\nett besked frn Skatteverket dr det str datum och hur mycket du ska betala. Om\ndu har Visma eEkonomi\n[https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282] \nkan du flja deras film om skattekontot\n[https://www.youtube.com/watch?v=-7cDnn-NaME].\n\n * Betala frn fretagskontot till fretagets skattekonto.\n * Importerar bankhndelser frn fretagskontot.\n * Ladda ner transaktioner frn Skatteverket till ditt skattekonto\n   [https://www.youtube.com/watch?v=-7cDnn-NaME]  och matchar dem sedan mot\n   momshndelsen i dina bokfringshndelser.\n * Importera bankhndelsen frn banken till fretagskontot i Visma eEkonomi\n   [https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282]\n * Importera bankhndelsen frn Skatteverket (du kan exportera den till fil)\n   till skattekontot i Visma eEkonomi\n   [https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282]\n * Matcha bankhndelsen p fretagskontot mot hndelsen p skattekontot. Egen\n   kontering mellan egna bankkonton.\n * Nr pengarna dragits av Skatteverket frn Skattekontot, importera den\n   hndelsen.\n * Matcha hndelsen mot bokfringsfrslaget Debiterad preliminrskatt.\n\nNr du ska betala ut Ln  behver du betala skatt, arbetsgivaravgift  samt\nsjlva lnen. Bde skatt  och arbetsgivaravgift  betalas till fretagets \nskattekonto  s det r 2 betalningar som behver gras frn fretagskontot. Om\ndu anvnder Visma eEkonomi\n[https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282] \nkan du gra shr. Finns ven en film hr\n[https://www.youtube.com/watch?v=ig2C9gQg2Eg]  och en bra trd\n[https://forum.vismaspcs.se/visma_spcs/topics/bokfora-lon-i-eekonomi]  om detta\ni supportforumet.\n\n * Under ln  i huvudnenyn vljer du anstllda. Lgg upp den anstllde. Du\n   kommer behva Skattetabell  att anvnda. Den anstllde kan logga in\n   [https://www.skatteverket.se/]  hos Skatteverket och hittar d skattetabell\n   under \"Skatter och deklarationer\".\n * Under ln  i huvudnenyn vljer du lnebesked  och skapar ett nytt.\n * Ange lnen och vlj bokfr.\n * Logga in p banken och betala ut lnen, efter skatt, till den anstlldes\n   konto.\n * Importera bankhndelsen till fretagskontot  via kassa och bankhndelser.\n * Visma eEkonomi\n   [https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282] \n    kommer fresl att du matchar bankhndelsen mot lneutbetalningen, gr det.\n   Nu r du klar med lnen, och nsta moment r att betala skatt och\n   arbetsgivaravgift.\n\nArbetsgivardeklaration  lmnas enkelt via Skatteverkets webbsida\n[https://www.skatteverket.se/foretagochorganisationer/arbetsgivare/lamnaarbetsgivardeklaration.4.6a6688231259309ff1f800029116.html]\n.\n\n * Om du inte har betalat ut ngon ln stter du bara 0  i de obligatoriska\n   flten och skickar in.\n * Om du har betalat ut ln, och anvnder Visma eEkonomi\n   [https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282]\n   . * G in under ln  i huvudmenyn och vlj arbetsgivardeklaration.\n    * Skapa ny.\n    * Vlj mnaden d lnen betaldes ut.\n    * Vlj bokfr.\n    * Nu kan du exportera en fil [https://www.youtube.com/watch?v=ig2C9gQg2Eg] \n      om du klickar p tgrder  fr deklarationen.\n    * Lmna in arbetsgivardeklarationen\n      [https://www.skatteverket.se/foretagochorganisationer/arbetsgivare/lamnaarbetsgivardeklaration.4.6a6688231259309ff1f800029116.html] \n       hos Skatteverket genom att importera filen.\n    * P kvittensen visas ett bankgiro och OCR att anvnda fr att betala in\n      skatten till fretagets skattekonto.\n    * Betala in summan frn fretagets bankkonto.\n    * Importera bankhndelsen frn banken till fretagskontot i Visma eEkonomi\n      [https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282]\n    * Importera bankhndelsen frn Skatteverket (du kan exportera den till fil)\n      till skattekontot i Visma eEkonomi\n      [https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282]\n    * Matcha bankhndelsen p fretagskontot mot hndelsen p skattekontot.\n      Egen kontering mellan egna bankkonton.\n    * Nr pengarna dragits av Skatteverket frn Skattekontot, importera den\n      hndelsen.\n    * Matcha hndelsen mot bokfringsfrslaget arbetsgivardeklaration.\n      Skatteverkat drar arbetsgivardeklartionen i 2 transaktioner, du behver \n      manuellt sl ihop dem\n      [https://forum.vismaspcs.se/visma_spcs/topics/hur-matchar-jag-tva-belopp-pa-skattekontot-mot-en-arbetsgivardeklaration] \n       fr att kunna anvnda det hr bokfringsfslaget. Men annars r det 1630 \n      som krediteras och 2710  (personalskatt) samt 2731  (arbetsgivaravgift)\n      som debiteras. Jag tycker ven den hr sidan\n      [https://www.blinfo.se/foretagskunskap/bokfora-lon__15472]  r bra hr.\n   \n   \n\nVisma eEkonomi\n[https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282] \nhar en frdig mall fr fakturor. Du anger ditt fretags bankgiro, och/eller\nkontonummer, lgger upp kunder och artiklar. Sedan kan du enkelt skapa fakturor\nsom du sedan kan skriva ut, spara som PDF eller maila.\n\nOm du betalar ut traktamente  behver du kunna bevisa att resorna gt rum och\nvarit tjnsteresor\n[https://www.vismaspcs.se/visma-support/visma-eget-aktiebolag/content/skattefria_traktamenten.htm]\n. Drfr kan det vara klokt att fra anteckningar fr resor. I mitt fall ker\njag alltid tg och kommer hnvisa till tgbiljetterna om jag fr revision av\nSkatteverket. Jag skapar exceldokument, med utrkningen, som jag sedan\nexporterar till PDF och sparar fr att motivera traktamentet.\n\n\n\nMan hr ibland uttrycket skriva av  och jag tror mnga missfrstr det, kanske\nven jag =) Men jag tolkar det som att allt man kper fr under ett halvt\nprisbasbelopp (ungefr 22 000 kr) skrivs av direkt, kostar det mer skriver man\nav det under flera r. Att skriva av  innebr att man inte tar upp det som en\ntillgng, en inventarie, i bokfringen. Det r dock inte samma sak som att man\nfr ge bort prylen till sig sjlv eller ngon annan. Men jag r osker, och\nmnga med mig [https://www.flashback.org/p49423662].\n\nAtt bokfra kp gjorda med kreditkort  r lite speciellt men det har Visma en\nvldigt bra artikel\n[https://forum.vismaspcs.se/visma_spcs/topics/bokfora-inkop-med-kreditkort-i-visma-eekonomi] \n om.\n\nJag sparar alltid alla kvitton  direkt p Google Drive. r det inte digitalt\nfotar jag av med mobilen, laddar upp bilden och sparar ven original-kvittot i\nen prm. I bokfringsprogrammet r jag ocks noga med att ladda upp bilder p\nvarje verifikation. Bokfringslagen\n[https://www.riksdagen.se/sv/dokument-lagar/dokument/svensk-forfattningssamling/bokforingslag-19991078_sfs-1999-1078] \n sger att originalen ska sparas, s digitala ska sparas digitalt och de p\npapper sparas p papper. Jag tycker ven att den hr artikeln\n[https://vismaspcs.se/ditt-foretagande/byra/de-har-kopiorna-behover-du-inte-skriva-ut] \n beskriver det bra. ven andra dokument fotar jag av och sparar p Google Drive,\nsom beslut frn Skatteverket t.ex. Vldigt smidigt att kunna lsa allt var man\nn r. Det r ganska enkelt att f tag p ett rejlt brandskyddat kassaskp (#1\n[http://www.clasohlson.com/se/Dokumentsk%C3%A5p-Chubbsafes-Executive-40/Pr342428000] \n eller #2\n[http://www.biltema.se/sv/Hem/Sakerhet-och-larm/Sakerhetsbox/Kassaskap-brandsakert-2000033385/]\n) s att man kan spara papper korrekt enligt lagstiftningen.\n\nP bokslutsdagen, sista dagen p rkenskapsret, mste obetalda fakturor tas\nupp\ni bokfring\n[https://www.verksamt.se/driva/ekonomi-och-bokforing/lopande-bokforing]  ven om\ndu anvnder kontantmetoden. Det beskriver ocks Visma hr\n[https://forum.vismaspcs.se/visma_spcs/topics/bokfora-inkop-med-kreditkort-i-visma-eekonomi]\n. Om du har skapat en faktura som nnu inte blivit betald kommer Visma eEkonomi\n[https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282] \natt ge dig fljande meddelande nr du skapar sista kvartalsmomsen.\n\nEnligt Kontantmetoden ska du bokfra dina obetalda kundfordringar och\nleverantrsskulder vid rkenskapsrets slut och redovisa momsen. Detta kommer nu\natt gras automatiskt. Du br kontrollera att alla inbetalningar och\nutbetalningar p ret r avstmda innan du fortstter. Vill du fortstta?\n\nDet r viktigt att ta en extra titt p de sista transaktionerna innan\nrkenskapsret r slut s att det inte dykt upp ngot i sista sekunden. I mitt\nfall hade Danskebank skapat en faktura, och dragit pengarna, fr bankavgifter\nsista dagen i december.\n\nNr rkenskapsret r slut ska kontrolluppgifter  fr anstllda skickas till\nSkatteverket. Det hr gller 2017 men r p gng att ndras s att man skickar\nsamma uppgifter i arbetsgivardeklarationen istllet. Men i Visma eEkonomi\n[https://vismaspcs.se/produkter/bokforingsprogram/visma-eekonomi?pixid=15282] \nfinns en funktion under ln  i huvudmenyn som kan anvndas om du skapat\nlnespecar.\n\n * Klicka p Ny kontrolluppgift.\n * Fyll i dina uppgifter.\n * Spara.\n * Nu kan man ladda ner en xml-fil  som kan laddas upp hos Skatteverket fr att\n   fylla i KU10-blanketten.\n\nVisma har en vldigt bra gratis broschyr om bokfring\n[http://download.vismaspcs.se/pdf/bokf%C3%B6ring-f%C3%B6r-nyb%C3%B6rjare.pdf?utm_source=Eloqua&utm_medium=email&utm_content=SE_SP_SI_Onboarding-eEko-Std-4&utm_campaign=SE_SP_SI_Onboarding-eA-Std-1704]\n.\n\nvrigt\nOm du veckopendlar  som jag s kanske du har en lgenhet p arbetsorten. D kan\nman tnka sig att man lter bolaget betala den\n[http://www.skatter.se/?q=node/2619]. Jag blev rekommenderad att ta den privat\noch betala ut mer ln frn bolaget istllet. D rknar jag p detta vid\nutbetalning av ln s att ln efter avdrag hamnar p grnsen fr statlig skatt.\nAvdraget gr jag allts i min privata deklaration. Vljer man att lta bolaget\ndirekt betala lgenheten blir det lite krngligare med bokfring och\ndeklaration. Det kan ocks vara s att Skatteverket ser det som en frmn. S\ndet hr kndes enklast.\n\nDet finns bolag som har som affrsid att bara ha underkonsulter. De ker p\nkonferensresor och har gemensam kontorslokal precis som vilket annat bolag som\nhelst. Skillnaden r bara att alla r underkonsulter. Detta bolag hjlper dig\natt starta ditt eget bolag och hitta kunder. De har ramavtal med stora\nkonsultkpare och kan ordna bra timpriser. Ett snt bolag r Kvadrat\n[http://www.kvadrat.se/].\n\nJag valde frst att ta ver kontraktet jag var p och d g frn anstlld\nkonsult till underkonsult. Senare bytte jag uppdrag och d anslt jag mig till \nKvadrat [http://www.kvadrat.se/].\n\nHar du frgor om skatter s r det smidigt att man kan maila Skatteverket\n[https://www.skatteverket.se/omoss/kontaktaoss/mejla/].","feature_image":"/content/images/2017/12/vid_poolen.png","featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2017-06-27T20:01:37.000Z","created_by":"1","updated_at":"2018-09-26T07:20:21.000Z","updated_by":"1","published_at":"2017-06-29T10:42:56.000Z","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"custom_template":null},{"id":"597b64dc08a2db60d1f648ba","uuid":"0ba09695-d457-4894-8249-d8639a4214f0","title":"Ghost 1.0 free hosting with HTTPS and custom domain","slug":"ghost-1-0-free-hosting-with-https","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"I have been using [Ghost blogging platform](https://ghost.org/) for a few years now and I really like it! I have previously written about how I set it up with [GitHub pages and Buster](https://bjurr.com/ghost-blog-on-github-pages/). However a few important things have changed since then:\\n\\n* Buster is [no longer maintained](https://github.com/axitkhurana/buster/issues/66).\\n* Google is ranking HTTPS sites higher.\\n* Ghost 1.0 is released!\\n\\nTo coop with these new conditions, I made a few changes:\\n\\n* I use [Cloudflare](https://blog.cloudflare.com/secure-and-fast-github-pages-with-cloudflare/) to secure my blog with HTTPS.\\n* I setup Ghost blogging platform on localhost with [MySQL and NGINX](https://docs.ghost.org/docs/install).\\n* I created [a very simple shell script](https://github.com/tomasbjerre/bjurrcom/blob/tools/commit.sh) using `wget` to create a static website out of Ghost running on localhost.\\n\\nThis means I can still use Ghost 1.x, for free, with HTTPS, with [custom domain on GitHub pages](https://help.github.com/articles/using-a-custom-domain-with-github-pages/)!\\n\\nIf you want to enable comments, there is a good blog post about that [here](https://www.ghostforbeginners.com/how-to-enable-comments-on-a-ghost-blog/).\\n\\nCheckout [the repo](https://github.com/tomasbjerre/bjurrcom/tree/tools) to see exactly how it works. There is a branch, *master*, where the static content is committed. There is a branch, *tools*, where the `commit.sh` is placed and this this is also where the database and content gets backed up on publish. And publish is done by executing the `commit.sh` script. \\n\\nEnjoy! This is the first post with that new setup =)\\n\\n**Edit 180518:** GitHub now has support for HTTPS when using custom domains. So you don't need Cloudflare to get that.\"}]],\"sections\":[[10,0]]}","html":"<p>I have been using <a href=\"https://ghost.org/\">Ghost blogging platform</a> for a few years now and I really like it! I have previously written about how I set it up with <a href=\"https://bjurr.com/ghost-blog-on-github-pages/\">GitHub pages and Buster</a>. However a few important things have changed since then:</p>\n<ul>\n<li>Buster is <a href=\"https://github.com/axitkhurana/buster/issues/66\">no longer maintained</a>.</li>\n<li>Google is ranking HTTPS sites higher.</li>\n<li>Ghost 1.0 is released!</li>\n</ul>\n<p>To coop with these new conditions, I made a few changes:</p>\n<ul>\n<li>I use <a href=\"https://blog.cloudflare.com/secure-and-fast-github-pages-with-cloudflare/\">Cloudflare</a> to secure my blog with HTTPS.</li>\n<li>I setup Ghost blogging platform on localhost with <a href=\"https://docs.ghost.org/docs/install\">MySQL and NGINX</a>.</li>\n<li>I created <a href=\"https://github.com/tomasbjerre/bjurrcom/blob/tools/commit.sh\">a very simple shell script</a> using <code>wget</code> to create a static website out of Ghost running on localhost.</li>\n</ul>\n<p>This means I can still use Ghost 1.x, for free, with HTTPS, with <a href=\"https://help.github.com/articles/using-a-custom-domain-with-github-pages/\">custom domain on GitHub pages</a>!</p>\n<p>If you want to enable comments, there is a good blog post about that <a href=\"https://www.ghostforbeginners.com/how-to-enable-comments-on-a-ghost-blog/\">here</a>.</p>\n<p>Checkout <a href=\"https://github.com/tomasbjerre/bjurrcom/tree/tools\">the repo</a> to see exactly how it works. There is a branch, <em>master</em>, where the static content is committed. There is a branch, <em>tools</em>, where the <code>commit.sh</code> is placed and this this is also where the database and content gets backed up on publish. And publish is done by executing the <code>commit.sh</code> script.</p>\n<p>Enjoy! This is the first post with that new setup =)</p>\n<p><strong>Edit 180518:</strong> GitHub now has support for HTTPS when using custom domains. So you don't need Cloudflare to get that.</p>\n","comment_id":"597b64dc08a2db60d1f648ba","plaintext":"I have been using Ghost blogging platform [https://ghost.org/]  for a few years\nnow and I really like it! I have previously written about how I set it up with \nGitHub pages and Buster [https://bjurr.com/ghost-blog-on-github-pages/]. However\na few important things have changed since then:\n\n * Buster is no longer maintained\n   [https://github.com/axitkhurana/buster/issues/66].\n * Google is ranking HTTPS sites higher.\n * Ghost 1.0 is released!\n\nTo coop with these new conditions, I made a few changes:\n\n * I use Cloudflare\n   [https://blog.cloudflare.com/secure-and-fast-github-pages-with-cloudflare/] \n   to secure my blog with HTTPS.\n * I setup Ghost blogging platform on localhost with MySQL and NGINX\n   [https://docs.ghost.org/docs/install].\n * I created a very simple shell script\n   [https://github.com/tomasbjerre/bjurrcom/blob/tools/commit.sh]  using wget \n   to create a static website out of Ghost running on localhost.\n\nThis means I can still use Ghost 1.x, for free, with HTTPS, with custom domain\non GitHub pages\n[https://help.github.com/articles/using-a-custom-domain-with-github-pages/]!\n\nIf you want to enable comments, there is a good blog post about that here\n[https://www.ghostforbeginners.com/how-to-enable-comments-on-a-ghost-blog/].\n\nCheckout the repo [https://github.com/tomasbjerre/bjurrcom/tree/tools]  to see\nexactly how it works. There is a branch, master, where the static content is\ncommitted. There is a branch, tools, where the commit.sh  is placed and this\nthis is also where the database and content gets backed up on publish. And\npublish is done by executing the commit.sh  script.\n\nEnjoy! This is the first post with that new setup =)\n\nEdit 180518:  GitHub now has support for HTTPS when using custom domains. So you\ndon't need Cloudflare to get that.","feature_image":"/content/images/2018/02/Ghost-Logo.svg.png","featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2017-07-28T16:22:52.000Z","created_by":"1","updated_at":"2018-05-18T19:09:18.000Z","updated_by":"1","published_at":"2017-07-28T16:40:22.000Z","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"custom_template":null},{"id":"59e067ad8edbbd05ee0cef90","uuid":"8d1514e6-ed37-441c-ae20-e0c12288a7df","title":"FitNesse with Maven and Jenkins","slug":"fitnesse-with-maven-and-jenkins","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"I needed to automate [FitNesse](http://www.fitnesse.org/) tests in my clients build process. I also needed the test cases in Git so that *testers* can develop tests in the same feature branches as the *developers* are using.\\n\\nI was looking for a simple way of doing that in a Java project where Maven and Jenkins is being used. I did not find any acceptable solutiion, here is my solution.\\n\\n# What I Found\\nI found [Running from Junit](http://www.fitnesse.org/FitNesse.UserGuide.WritingAcceptanceTests.RunningFromJunit) in the official documentation. But I was unable to use it.\\n* That API looks strange and it is unclear how to use it.\\n* I could not find any API for specifying where the jar files, with the *service under test*, are on the filesystem. When digging into the code on GitHub I concluded that there are no such feature.\\n\\nI found the [Jenkins Plugin](https://wiki.jenkins.io/display/JENKINS/FitNesse+Plugin) but I wanted testers to be able to work with the test cases locally. That plugin would only, potentially, solve it in Jenkins. There is also [Xebia](http://blog.xebia.com/how-to-integrate-fitnesse-tests-into-jenkins/) but same problem there.\\n\\n# What I Did\\nI created a `pom` that uses `antrun` to basically just run the `java` program with command line arguments. The version of FitNesse is managed in the `pom`. \\n\\nThe wiki pages have:\\n```\\n!define TEST_SYSTEM {slim}\\n!path target/dependencies/*.jar\\n```\\n\\nHere is the `pom.xml`.\\n```\\n<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n<project xmlns=\\\"http://maven.apache.org/POM/4.0.0\\\" xmlns:xsi=\\\"http://www.w3.org/2001/XMLSchema-instance\\\"\\n xsi:schemaLocation=\\\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\\\">\\n <modelVersion>4.0.0</modelVersion>\\n\\n <artifactId>bjurr-fitnesse</artifactId>\\n\\n <dependencies>\\n  <dependency>\\n   <groupId>org.fitnesse</groupId>\\n   <artifactId>fitnesse</artifactId>\\n   <version>20161106</version>\\n   <scope>test</scope>\\n  </dependency>\\n </dependencies>\\n\\n <properties>\\n  <fitnesse.command></fitnesse.command>\\n </properties>\\n\\n <build>\\n  <plugins>\\n   <plugin>\\n    <artifactId>maven-antrun-plugin</artifactId>\\n    <version>1.3</version>\\n    <executions>\\n     <execution>\\n      <id>start-fitnesse</id>\\n      <phase>test</phase>\\n      <configuration>\\n       <tasks>\\n        <copy todir=\\\"target/dependencies\\\" flatten=\\\"true\\\">\\n         <fileset dir=\\\"../\\\">\\n          <include name=\\\"**/*.jar\\\" />\\n         </fileset>\\n        </copy>\\n        <echo message=\\\"\\\" />\\n        <echo message=\\\"\\\" />\\n        <echo message=\\\"Fitnesse wiki available here:\\\" />\\n        <echo message=\\\"\\\" />\\n        <echo message=\\\"  http://localhost:8888/MyTests.MySuite\\\" />\\n        <echo message=\\\"\\\" />\\n        <echo message=\\\"\\\" />\\n        <java classname=\\\"fitnesseMain.FitNesseMain\\\" classpathref=\\\"maven.test.classpath\\\"\\n         fork=\\\"true\\\">\\n         <arg line=\\\"-p 8888\\\" />\\n         <arg line=\\\"-d .\\\" />\\n         <arg line=\\\"-e 9999\\\" />\\n         <arg line=\\\"-b target/fitnesse-junit.xml\\\" />\\n         <arg line=\\\"${fitnesse.command}\\\" />\\n         <jvmarg value=\\\"-Xmx1024m\\\" />\\n        </java>\\n       </tasks>\\n      </configuration>\\n      <goals>\\n       <goal>run</goal>\\n      </goals>\\n     </execution>\\n    </executions>\\n   </plugin>\\n  </plugins>\\n </build>\\n</project>\\n```\\n\\nTo start the wiki to work with the test cases I do:\\n`mvn test`\\nAnd that will start the FitNesse wiki on *localhost*.\\n\\nWhen tests change, the changed wiki pages are committet and pushed to the remote repo.\\n\\nTo run all the tests I do:\\n`mvn test -Dfitnesse.command=\\\"-c MyTests.MySuite?suite&format=junit\\\"`\\nAnd in Jenkins I use the [Lockable Resources Plugin](https://wiki.jenkins.io/display/JENKINS/Lockable+Resources+Plugin) to allow IP port collision and only have one job running FitNesse at once.\\n\\nA pipeline `stage` may look like this:\\n```\\n...\\nstage('FitNesse test') {\\n  lock(resource: \\\"compiler_${env.NODE_NAME}\\\", inversePrecedence: true) {\\n   try {\\n    sh \\\"\\\"\\\"\\n     cd fitnesse\\n     ${mvnHome}/bin/mvn test -Dfitnesse.command=\\\\\\\"-c MyTests.MySuite?suite&format=junit\\\\\\\"\\n     tar -zcvf fitnesseTestResults.tar.gz FitNesseRoot/files/testResults\\n    \\\"\\\"\\\"\\n    archiveArtifacts artifacts: 'fitnesseTestResults.tar.gz', fingerprint: true\\n    junit \\\"**/fitnesse/target/*.xml\\\"\\n    commentMr(env.gitlabMergeRequestId, \\\"FitNesse ok :) $gitlabSourceBranch ${BUILD_URL}\\\")\\n   } catch (e) {\\n    commentMr(env.gitlabMergeRequestId, \\\"FitNesse **not ok** in $gitlabSourceBranch ${BUILD_URL}\\\")\\n    junit \\\"**/fitnesse/target/*.xml\\\"\\n    throw e\\n   }\\n  }\\n }\\n...\\n```\"}]],\"sections\":[[10,0]]}","html":"<p>I needed to automate <a href=\"http://www.fitnesse.org/\">FitNesse</a> tests in my clients build process. I also needed the test cases in Git so that <em>testers</em> can develop tests in the same feature branches as the <em>developers</em> are using.</p>\n<p>I was looking for a simple way of doing that in a Java project where Maven and Jenkins is being used. I did not find any acceptable solutiion, here is my solution.</p>\n<h1 id=\"whatifound\">What I Found</h1>\n<p>I found <a href=\"http://www.fitnesse.org/FitNesse.UserGuide.WritingAcceptanceTests.RunningFromJunit\">Running from Junit</a> in the official documentation. But I was unable to use it.</p>\n<ul>\n<li>That API looks strange and it is unclear how to use it.</li>\n<li>I could not find any API for specifying where the jar files, with the <em>service under test</em>, are on the filesystem. When digging into the code on GitHub I concluded that there are no such feature.</li>\n</ul>\n<p>I found the <a href=\"https://wiki.jenkins.io/display/JENKINS/FitNesse+Plugin\">Jenkins Plugin</a> but I wanted testers to be able to work with the test cases locally. That plugin would only, potentially, solve it in Jenkins. There is also <a href=\"http://blog.xebia.com/how-to-integrate-fitnesse-tests-into-jenkins/\">Xebia</a> but same problem there.</p>\n<h1 id=\"whatidid\">What I Did</h1>\n<p>I created a <code>pom</code> that uses <code>antrun</code> to basically just run the <code>java</code> program with command line arguments. The version of FitNesse is managed in the <code>pom</code>.</p>\n<p>The wiki pages have:</p>\n<pre><code>!define TEST_SYSTEM {slim}\n!path target/dependencies/*.jar\n</code></pre>\n<p>Here is the <code>pom.xml</code>.</p>\n<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\n xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt;\n &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n\n &lt;artifactId&gt;bjurr-fitnesse&lt;/artifactId&gt;\n\n &lt;dependencies&gt;\n  &lt;dependency&gt;\n   &lt;groupId&gt;org.fitnesse&lt;/groupId&gt;\n   &lt;artifactId&gt;fitnesse&lt;/artifactId&gt;\n   &lt;version&gt;20161106&lt;/version&gt;\n   &lt;scope&gt;test&lt;/scope&gt;\n  &lt;/dependency&gt;\n &lt;/dependencies&gt;\n\n &lt;properties&gt;\n  &lt;fitnesse.command&gt;&lt;/fitnesse.command&gt;\n &lt;/properties&gt;\n\n &lt;build&gt;\n  &lt;plugins&gt;\n   &lt;plugin&gt;\n    &lt;artifactId&gt;maven-antrun-plugin&lt;/artifactId&gt;\n    &lt;version&gt;1.3&lt;/version&gt;\n    &lt;executions&gt;\n     &lt;execution&gt;\n      &lt;id&gt;start-fitnesse&lt;/id&gt;\n      &lt;phase&gt;test&lt;/phase&gt;\n      &lt;configuration&gt;\n       &lt;tasks&gt;\n        &lt;copy todir=&quot;target/dependencies&quot; flatten=&quot;true&quot;&gt;\n         &lt;fileset dir=&quot;../&quot;&gt;\n          &lt;include name=&quot;**/*.jar&quot; /&gt;\n         &lt;/fileset&gt;\n        &lt;/copy&gt;\n        &lt;echo message=&quot;&quot; /&gt;\n        &lt;echo message=&quot;&quot; /&gt;\n        &lt;echo message=&quot;Fitnesse wiki available here:&quot; /&gt;\n        &lt;echo message=&quot;&quot; /&gt;\n        &lt;echo message=&quot;  http://localhost:8888/MyTests.MySuite&quot; /&gt;\n        &lt;echo message=&quot;&quot; /&gt;\n        &lt;echo message=&quot;&quot; /&gt;\n        &lt;java classname=&quot;fitnesseMain.FitNesseMain&quot; classpathref=&quot;maven.test.classpath&quot;\n         fork=&quot;true&quot;&gt;\n         &lt;arg line=&quot;-p 8888&quot; /&gt;\n         &lt;arg line=&quot;-d .&quot; /&gt;\n         &lt;arg line=&quot;-e 9999&quot; /&gt;\n         &lt;arg line=&quot;-b target/fitnesse-junit.xml&quot; /&gt;\n         &lt;arg line=&quot;${fitnesse.command}&quot; /&gt;\n         &lt;jvmarg value=&quot;-Xmx1024m&quot; /&gt;\n        &lt;/java&gt;\n       &lt;/tasks&gt;\n      &lt;/configuration&gt;\n      &lt;goals&gt;\n       &lt;goal&gt;run&lt;/goal&gt;\n      &lt;/goals&gt;\n     &lt;/execution&gt;\n    &lt;/executions&gt;\n   &lt;/plugin&gt;\n  &lt;/plugins&gt;\n &lt;/build&gt;\n&lt;/project&gt;\n</code></pre>\n<p>To start the wiki to work with the test cases I do:<br>\n<code>mvn test</code><br>\nAnd that will start the FitNesse wiki on <em>localhost</em>.</p>\n<p>When tests change, the changed wiki pages are committet and pushed to the remote repo.</p>\n<p>To run all the tests I do:<br>\n<code>mvn test -Dfitnesse.command=&quot;-c MyTests.MySuite?suite&amp;format=junit&quot;</code><br>\nAnd in Jenkins I use the <a href=\"https://wiki.jenkins.io/display/JENKINS/Lockable+Resources+Plugin\">Lockable Resources Plugin</a> to allow IP port collision and only have one job running FitNesse at once.</p>\n<p>A pipeline <code>stage</code> may look like this:</p>\n<pre><code>...\nstage('FitNesse test') {\n  lock(resource: &quot;compiler_${env.NODE_NAME}&quot;, inversePrecedence: true) {\n   try {\n    sh &quot;&quot;&quot;\n     cd fitnesse\n     ${mvnHome}/bin/mvn test -Dfitnesse.command=\\&quot;-c MyTests.MySuite?suite&amp;format=junit\\&quot;\n     tar -zcvf fitnesseTestResults.tar.gz FitNesseRoot/files/testResults\n    &quot;&quot;&quot;\n    archiveArtifacts artifacts: 'fitnesseTestResults.tar.gz', fingerprint: true\n    junit &quot;**/fitnesse/target/*.xml&quot;\n    commentMr(env.gitlabMergeRequestId, &quot;FitNesse ok :) $gitlabSourceBranch ${BUILD_URL}&quot;)\n   } catch (e) {\n    commentMr(env.gitlabMergeRequestId, &quot;FitNesse **not ok** in $gitlabSourceBranch ${BUILD_URL}&quot;)\n    junit &quot;**/fitnesse/target/*.xml&quot;\n    throw e\n   }\n  }\n }\n...\n</code></pre>\n","comment_id":"59e067ad8edbbd05ee0cef90","plaintext":"I needed to automate FitNesse [http://www.fitnesse.org/]  tests in my clients\nbuild process. I also needed the test cases in Git so that testers  can develop\ntests in the same feature branches as the developers  are using.\n\nI was looking for a simple way of doing that in a Java project where Maven and\nJenkins is being used. I did not find any acceptable solutiion, here is my\nsolution.\n\nWhat I Found\nI found Running from Junit\n[http://www.fitnesse.org/FitNesse.UserGuide.WritingAcceptanceTests.RunningFromJunit] \n in the official documentation. But I was unable to use it.\n\n * That API looks strange and it is unclear how to use it.\n * I could not find any API for specifying where the jar files, with the service\n   under test, are on the filesystem. When digging into the code on GitHub I\n   concluded that there are no such feature.\n\nI found the Jenkins Plugin\n[https://wiki.jenkins.io/display/JENKINS/FitNesse+Plugin]  but I wanted testers\nto be able to work with the test cases locally. That plugin would only,\npotentially, solve it in Jenkins. There is also Xebia\n[http://blog.xebia.com/how-to-integrate-fitnesse-tests-into-jenkins/]  but same\nproblem there.\n\nWhat I Did\nI created a pom  that uses antrun  to basically just run the java  program with\ncommand line arguments. The version of FitNesse is managed in the pom.\n\nThe wiki pages have:\n\n!define TEST_SYSTEM {slim}\n!path target/dependencies/*.jar\n\n\nHere is the pom.xml.\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">\n <modelVersion>4.0.0</modelVersion>\n\n <artifactId>bjurr-fitnesse</artifactId>\n\n <dependencies>\n  <dependency>\n   <groupId>org.fitnesse</groupId>\n   <artifactId>fitnesse</artifactId>\n   <version>20161106</version>\n   <scope>test</scope>\n  </dependency>\n </dependencies>\n\n <properties>\n  <fitnesse.command></fitnesse.command>\n </properties>\n\n <build>\n  <plugins>\n   <plugin>\n    <artifactId>maven-antrun-plugin</artifactId>\n    <version>1.3</version>\n    <executions>\n     <execution>\n      <id>start-fitnesse</id>\n      <phase>test</phase>\n      <configuration>\n       <tasks>\n        <copy todir=\"target/dependencies\" flatten=\"true\">\n         <fileset dir=\"../\">\n          <include name=\"**/*.jar\" />\n         </fileset>\n        </copy>\n        <echo message=\"\" />\n        <echo message=\"\" />\n        <echo message=\"Fitnesse wiki available here:\" />\n        <echo message=\"\" />\n        <echo message=\"  http://localhost:8888/MyTests.MySuite\" />\n        <echo message=\"\" />\n        <echo message=\"\" />\n        <java classname=\"fitnesseMain.FitNesseMain\" classpathref=\"maven.test.classpath\"\n         fork=\"true\">\n         <arg line=\"-p 8888\" />\n         <arg line=\"-d .\" />\n         <arg line=\"-e 9999\" />\n         <arg line=\"-b target/fitnesse-junit.xml\" />\n         <arg line=\"${fitnesse.command}\" />\n         <jvmarg value=\"-Xmx1024m\" />\n        </java>\n       </tasks>\n      </configuration>\n      <goals>\n       <goal>run</goal>\n      </goals>\n     </execution>\n    </executions>\n   </plugin>\n  </plugins>\n </build>\n</project>\n\n\nTo start the wiki to work with the test cases I do:\nmvn test\nAnd that will start the FitNesse wiki on localhost.\n\nWhen tests change, the changed wiki pages are committet and pushed to the remote\nrepo.\n\nTo run all the tests I do:\nmvn test -Dfitnesse.command=\"-c MyTests.MySuite?suite&format=junit\"\nAnd in Jenkins I use the Lockable Resources Plugin\n[https://wiki.jenkins.io/display/JENKINS/Lockable+Resources+Plugin]  to allow IP\nport collision and only have one job running FitNesse at once.\n\nA pipeline stage  may look like this:\n\n...\nstage('FitNesse test') {\n  lock(resource: \"compiler_${env.NODE_NAME}\", inversePrecedence: true) {\n   try {\n    sh \"\"\"\n     cd fitnesse\n     ${mvnHome}/bin/mvn test -Dfitnesse.command=\\\"-c MyTests.MySuite?suite&format=junit\\\"\n     tar -zcvf fitnesseTestResults.tar.gz FitNesseRoot/files/testResults\n    \"\"\"\n    archiveArtifacts artifacts: 'fitnesseTestResults.tar.gz', fingerprint: true\n    junit \"**/fitnesse/target/*.xml\"\n    commentMr(env.gitlabMergeRequestId, \"FitNesse ok :) $gitlabSourceBranch ${BUILD_URL}\")\n   } catch (e) {\n    commentMr(env.gitlabMergeRequestId, \"FitNesse **not ok** in $gitlabSourceBranch ${BUILD_URL}\")\n    junit \"**/fitnesse/target/*.xml\"\n    throw e\n   }\n  }\n }\n...","feature_image":"/content/images/2018/02/fitnesse-1.png","featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2017-10-13T07:13:49.000Z","created_by":"1","updated_at":"2018-02-24T09:03:08.000Z","updated_by":"1","published_at":"2017-10-13T07:32:28.000Z","published_by":"1","custom_excerpt":null,"codeinjection_head":"","codeinjection_foot":"","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"custom_template":null},{"id":"5a23da214b28b905d8304a37","uuid":"94db8a80-3e12-4300-93ee-5f0b0bb72a3d","title":"Sharing Gradle build scripts across repositories","slug":"sharing-gradle-build-scripts-cross-repositories","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"While migrating my OSS from Maven Central to [Bintray](https://bintray.com/tomasbjerre) I realized I had a lot of duplicated Gradle scripts in different repos. I found [some alternatives](https://stackoverflow.com/questions/9539986/how-to-share-a-common-build-gradle-via-a-repository) on how to share build scripts across repositories. I built on that and here is what I did.\\n\\n# Solution\\nThe Gradle scripts are gathered in a *script repository*, see [Gradle Scripts](https://github.com/tomasbjerre/gradle-scripts). The *script repository* is a Gradle project in its own that packages the scripts into a *jar*. That *jar* is added as a build script dependency in projects that needs the scripts.\\n\\nThis is really convenient when managing a large amount of repositories. Scripts, each adding a specific ability to the build process, can be gathered at one single place. Be released and managed in branches just like any other project. The dependency will also be cached, just like any other dependency, making the build much faster then applying a script form a URL.\\n\\nThis shows another advantage of Gradle compared to Maven. If I was using Maven I would have to create a *pom* that I would use as *parent* for these projects. Anyone using the project would also need that *parent*. So adding functionality to the build process would have negative effect on the built artifact. A parent would also risk adding too much functionality to the build process. If I had a Maven plugin and a pure library, I would not be able to construct a logical *parent* for them. With Gradle I just pick the abilities I want and there will be no trace, except the intended, in the built artifact.\\n\\n# Implementation\\n\\nIn my case I use [JitPack](https://jitpack.io/) to build and supply the script jar. It means I can have a master branch where I can push changes to the scripts and immediately have those changes take effect in all my repos. But within an organization you would probably want to build and upload to something like Nexus or Artifactory.\\n\\nA project using this method will have a very slim build script. A running example is the [build script](https://github.com/tomasbjerre/violations-lib/blob/master/build.gradle) of my [Violations Lib](https://github.com/tomasbjerre/violations-lib).\\n\"}]],\"sections\":[[10,0]]}","html":"<p>While migrating my OSS from Maven Central to <a href=\"https://bintray.com/tomasbjerre\">Bintray</a> I realized I had a lot of duplicated Gradle scripts in different repos. I found <a href=\"https://stackoverflow.com/questions/9539986/how-to-share-a-common-build-gradle-via-a-repository\">some alternatives</a> on how to share build scripts across repositories. I built on that and here is what I did.</p>\n<h1 id=\"solution\">Solution</h1>\n<p>The Gradle scripts are gathered in a <em>script repository</em>, see <a href=\"https://github.com/tomasbjerre/gradle-scripts\">Gradle Scripts</a>. The <em>script repository</em> is a Gradle project in its own that packages the scripts into a <em>jar</em>. That <em>jar</em> is added as a build script dependency in projects that needs the scripts.</p>\n<p>This is really convenient when managing a large amount of repositories. Scripts, each adding a specific ability to the build process, can be gathered at one single place. Be released and managed in branches just like any other project. The dependency will also be cached, just like any other dependency, making the build much faster then applying a script form a URL.</p>\n<p>This shows another advantage of Gradle compared to Maven. If I was using Maven I would have to create a <em>pom</em> that I would use as <em>parent</em> for these projects. Anyone using the project would also need that <em>parent</em>. So adding functionality to the build process would have negative effect on the built artifact. A parent would also risk adding too much functionality to the build process. If I had a Maven plugin and a pure library, I would not be able to construct a logical <em>parent</em> for them. With Gradle I just pick the abilities I want and there will be no trace, except the intended, in the built artifact.</p>\n<h1 id=\"implementation\">Implementation</h1>\n<p>In my case I use <a href=\"https://jitpack.io/\">JitPack</a> to build and supply the script jar. It means I can have a master branch where I can push changes to the scripts and immediately have those changes take effect in all my repos. But within an organization you would probably want to build and upload to something like Nexus or Artifactory.</p>\n<p>A project using this method will have a very slim build script. A running example is the <a href=\"https://github.com/tomasbjerre/violations-lib/blob/master/build.gradle\">build script</a> of my <a href=\"https://github.com/tomasbjerre/violations-lib\">Violations Lib</a>.</p>\n","comment_id":"5a23da214b28b905d8304a37","plaintext":"While migrating my OSS from Maven Central to Bintray\n[https://bintray.com/tomasbjerre]  I realized I had a lot of duplicated Gradle\nscripts in different repos. I found some alternatives\n[https://stackoverflow.com/questions/9539986/how-to-share-a-common-build-gradle-via-a-repository] \n on how to share build scripts across repositories. I built on that and here is\nwhat I did.\n\nSolution\nThe Gradle scripts are gathered in a script repository, see Gradle Scripts\n[https://github.com/tomasbjerre/gradle-scripts]. The script repository  is a\nGradle project in its own that packages the scripts into a jar. That jar  is\nadded as a build script dependency in projects that needs the scripts.\n\nThis is really convenient when managing a large amount of repositories. Scripts,\neach adding a specific ability to the build process, can be gathered at one\nsingle place. Be released and managed in branches just like any other project.\nThe dependency will also be cached, just like any other dependency, making the\nbuild much faster then applying a script form a URL.\n\nThis shows another advantage of Gradle compared to Maven. If I was using Maven I\nwould have to create a pom  that I would use as parent  for these projects.\nAnyone using the project would also need that parent. So adding functionality to\nthe build process would have negative effect on the built artifact. A parent\nwould also risk adding too much functionality to the build process. If I had a\nMaven plugin and a pure library, I would not be able to construct a logical \nparent  for them. With Gradle I just pick the abilities I want and there will be\nno trace, except the intended, in the built artifact.\n\nImplementation\nIn my case I use JitPack [https://jitpack.io/]  to build and supply the script\njar. It means I can have a master branch where I can push changes to the scripts\nand immediately have those changes take effect in all my repos. But within an\norganization you would probably want to build and upload to something like Nexus\nor Artifactory.\n\nA project using this method will have a very slim build script. A running\nexample is the build script\n[https://github.com/tomasbjerre/violations-lib/blob/master/build.gradle]  of my \nViolations Lib [https://github.com/tomasbjerre/violations-lib].","feature_image":"/content/images/2018/02/5847fb12cef1014c0b5e48d1.png","featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2017-12-03T11:04:01.000Z","created_by":"1","updated_at":"2018-02-24T09:00:04.000Z","updated_by":"1","published_at":"2017-12-03T19:35:10.000Z","published_by":"1","custom_excerpt":null,"codeinjection_head":"","codeinjection_foot":"","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"custom_template":null},{"id":"5a755597c56a61057b219788","uuid":"73afa94e-03b0-4d35-96c2-ce0bbac13826","title":"Managing 1000+ Git repositories in Jenkins with a breeze","slug":"managing-1000-repos-in-jenkins-with-a-breeze","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"This is a pattern that I find simple, easy/quick while still keeping you in control of your build flow. Should be no problem applying it in an organization with a huge amount of repositories!\\n\\nI am exclusively involved in **Java projects**. This post will sometimes assume *Maven* is being used. But it can probably inspire a solution in other projects too. I will not supply the complete running code. I'm just going to include small snippets and focus on explaining the general idea.\\n\\n# Problems\\nSplitting a big application into several smaller artifacts is a good thing! To me, that is obvious but still I find myself talking to people that don't agree on that. Here are some of the arguments I hear on why not to split applications.\\n\\n> \\\"I want to build whatever I have checked out, locally, on my filesystem. We will need to spend many frustrating hours stepping dependencies between artifacts.\\\"\\n\\n> \\\"It is hard to detect when artifacts no longer fit together. We will find severe problems late because we don't continuously integrate all the artifacts.\\\"\\n\\n> \\\"We will need a huge amount of jobs in Jenkins (releasing, testing, integrating, deploying, snapshots...). We will need to spend much time managing them.\\\"\\n\\nOk! All valid points! And **all of them are more or less show stoppers if you don't do continuous integration right!**\\n\\n# Solution\\nIn short, I propose a solution where you:\\n\\n * Define a clear branching strategy.\\n * Define a translation strategy between branch and Maven artifact version.\\n * Define how any given repo should be built.\\n * Automate and define how repos depend on each other.\\n * Add a *Jenkinsfile* to each repo.\\n * Create a [shared pipeline library](https://jenkins.io/doc/book/pipeline/shared-libraries/).\\n * Automate the creation of the jobs.\\n\\nYou might consider [Pipeline Multibranch Plugin](https://wiki.jenkins.io/display/JENKINS/Pipeline+Multibranch+Plugin). I use [Job DSL](https://github.com/jenkinsci/job-dsl-plugin/wiki) and [Folders Plugin](https://plugins.jenkins.io/cloudbees-folder). I have it create ordinary [pipeline](https://jenkins.io/doc/book/pipeline/)-jobs in a folder structure with a folder for each repository. \\n\\n* It gives me something static, the name of each job, to use when chaining jobs that depend on each other. There is a folder for each repository and it contains the jobs.\\n* It also allows several jobs to work with the same branch. I can easily create a release-job and a snapshot-job that both work with the *develop* branch.\\n\\nYou could have a static release-job and use mutlibranch to dynamically create every other job. But still, I feel I have more control with *Job DSL* and I feel it makes Jenkins look more organized.\\n\\n## Branching strategy\\nYou must know the meaing of the branches, in any given repo, in order to automate things. A defined branching strategy enables you to:\\n\\n * Clone any given repo.\\n * Detect what branches exists.\\n * Be sure which branch to use for *snapshots* or *releases*.\\n\\nIf your strategy is [GitFlow](https://bjurr.com/gitflow-and-when-you-should-use-it/), then:\\n\\n * The *snapshot*-job will\\n   * Build snapshots from *develop*.\\n   * Step dependencies in *develop*.\\n * The *release*-job will\\n   * Build releases from *hotfix* if it exists or else  *release*.\\n * The *feature*-job will build any *feature/X*-branches.\\n\\nEach repository has one release-cycle. Several artifacts, in the same repo, with different release-cycles are not allowed.\\n\\n## Branch to version translation\\n\\nThe integration between the Git service and Jenkins is setup so that when a commit is pushed to a feature-branch:\\n* A job is triggered.\\n* The branch name is identified.\\n* A version is derived form the branch name.\\n* Check to see if there is global a `bom` with that version\\n  * If no `bom` fall back to some default, fail or automate creation of that bom-version.\\n* The artifacts are built, with a `bom` with the version, and uploaded to a Maven repository.\\n\\nThe `bom` -repo may function in the same way. Developers branch out of *develop*, getting all default versions. They set specific versions for some artifacts and commit/push. Or you automate that same procedure whenever a `bom`-version is missing. Then the artifact that originally triggered the creation of that bom can find its version and set it to itself.\\n\\nThen it will be possible to automatically create *deploy*-jobs for any \\\"deployaple\\\" repository. Where a dropdown list can automatically be populated with features. Features are found by listing feature-branches and translating to versions.\\n\\nDevelopers won't have to fiddle with versions locally, they just have whatever version that is also in *develop*-branches. And can clone a bunch of repos, built locally, and work with that fitting together.\\n\\n## Building\\n\\nYou must know how to build any given repo. With Maven, the aggreement might be as simple as:\\n\\n* The project is built from the root of the repo.\\n* The version, of the repository, is specified in the root of the repo. When using Maven, it is the version of the *pom.xml*.\\n* Different Maven profiles are allowed. Any profiles that produces artifacts should be specified as metadata about the repo in the *Jenkinsfile*.\\n\\nThe important thing is to define these rules. Do not start treating specific repos differently in the global build scripts. Instead specify global rules that all repos should follow.\\n\\n## Depending repositories\\n\\nTo be able to automatically chain jobs and have them trigger each other, I need to know *depending repos* of each repo. The opposite of what you have in `pom.xml`.\\n\\nOne way of doing that is with a job that:\\n\\n * Regularly finds all repos, perhaps via the Git service REST-API.\\n * Parse the `pom.xml`-files.\\n   * Find out what `artifacts` are contains in what repos.\\n   * Find out what `artifacts` are used in what repos.\\n * Create a structure with the depending repos per repo.\\n * Optimize that structure so that transitive dependencies are removed from list of direct dependencies.\\n * Store that structure as a json text -file in a repo. Making it available for snapshot/release-jobs to clone and include.\\n\\nHaving this information pre-calculated saves alot of time when it is needed by some job.\\n\\nPerhaps the depending repo structure can look something like this.\\n```\\n{\\n ...\\n \\\"PROJECT-A/example-repo-d\\\": [\\n  \\\"PROJECT-B/example-repo-b\\\",\\n  \\\"PROJECT-C/example-repo-d\\\"\\n ],\\n \\\"PROJECT-C/example-repo-d\\\": [\\n  \\\"PROJECT-E/example-repo-b\\\"\\n ]\\n ...\\n}\\n```\\n\\n## Jenkinsfile\\nIt is very small and contains only metadata about the repo. This is just like [Jenkins Infra](https://github.com/jenkins-infra/pipeline-library/blob/master/vars/buildPlugin.groovy) handles their 1000+ plugins.\\n\\nWhen using Maven, you might want to specify *profiles* to be built.\\n\\nA repo that needs to be built, nothing else, may look like this:\\n```\\nbuildRepo()\\n```\\n\\nIt may specify profiles:\\n```\\nbuildRepo(\\n profiles: [\\n  'profile1'\\n ]\\n)\\n```\\n\\nAnd if a profiles are needed as well as no profile, it may look like:\\n```\\nbuildRepo(\\n profiles: [\\n  '',\\n  'profile1'\\n ]\\n)\\n```\\n\\nThis is all there is in the repositories. Only one *Jenkinsfile* and this is the only information it contains. I'm not saying you only need this. I'm just recommending to keep it light! Perhaps you invent thnkgs like `deployable: true` or `autoDeployEnv: 'TEST-XY'`...\\n\\n## Shared library\\nA [shared pipeline library](https://jenkins.io/doc/book/pipeline/shared-libraries/) allows you to, only once, define how to do releases, snapshots and all other tasks.\\n\\nWith the above *Jenkinsfile* there should be a `/vars/buildRepo.groovy` containing something like:\\n```\\n...\\ndef call(Map params = [:]) {\\n...\\n if (JOB_BASE_NAME.equals(\\\"snapshot\\\")) {\\n ...\\n } else if (JOB_BASE_NAME.equals(\\\"release\\\")) {\\n ...\\n }\\n...\\n}\\n...\\n```\\n\\n## Automate creation of jobs\\nMost Git services (GitHub, GitLab, Bitbucket...) provide REST API:s. You can use that to automate creation/deletion/adjustment of jobs and always be in sync with the repos you have in your Git service. The job DSL would loop through all repositories.\\n\\n```\\n...\\n folder(\\\"gen\\\") {\\n  displayName(\\\"Generated jobs\\\")\\n  description(\\\"\\\"\\\"\\n   These are generated by ${JOB_URL}\\n  \\\"\\\"\\\")\\n }\\n\\n getJson(server+ \\\"/rest/request/to/repos...\\\")\\n  .values\\n  .each { repo ->\\n  folder(\\\"gen\\\") {\\n   displayName(\\\"gen/\\\" + repo.name)\\n   description(\\\"\\\"\\\"\\n    Generated by ${JOB_URL}\\n   \\\"\\\"\\\")\\n  }\\n\\n  pipelineJob(\\\"gen/\\\" + repo.name + \\\"/snapshot\\\") {\\n...\\n```\\n\\n## Templates\\nI use the [Job DSL](https://github.com/jenkinsci/job-dsl-plugin/wiki) plugin. Perhaps you want these jobs for every repository:\\n\\n * *snapshot*\\n * *release*\\n * *feature*\\n * *pull-request*\\n\\nAlso a global job, *release-orchestration*.\\n\\nAll of these templates are pipelines. Their logic is implemented in the shared library. The shared library will find the Git repo to use from `scm.getUserRemoteConfigs().get(0).getUrl()` and the kind of job to build from `JOB_BASE_NAME`.\\n\\n### Snapshot\\nThis job will:\\n* Make sure *develop* is using latest dependencies ([found in Maven repository](http://www.mojohaus.org/versions-maven-plugin/update-properties-mojo.html)). If there are newer versions:\\n  * Step dependencies to latest version.\\n  * Commit changes.\\n  * Push changes.\\n  * Re-trigger self, to help Jenkins understand that this new commit does not need to be built again. Done.\\n* Build a snapshot version.\\n* Upload snapshot-version to Maven repository.\\n* Trigger *dependingRepos* configured in *Jenkinsfile*.\\n* Done.\\n\\nWhen using Maven, you can do this with [Versions Maven Plugin](http://www.mojohaus.org/versions-maven-plugin/).\\n\\n### Release\\nThis job will:\\n* Start from commit *C1*.\\n* Set dependencies to latest released versions.\\n* Step version to next release-version.\\n* Make a commit *C2*.\\n* Set dependencies to latest snapshots.\\n* Step version to next snapshot-version.\\n* Make a commit *C3*.\\n* Try to push changes. If not successful:\\n  * Hard reset to *C1*.\\n  * Pull.\\n  * Start again with creating *C2*.\\n  * Do this loop, perhaps 5 times before giving up and fail.\\n\\nThis allows developers to work in the branches during the release-process.\\n\\nNow that we know we are in sync with remote Git repo on where to perform the release, we can continue doing so.\\n\\n* Tag *C2* with the release-version.\\n* Perform the build commands, `mvn package` and loop any profiles needed.\\n* Deploy in Maven repository, `mvn deploy`.\\n\\nWhen using Maven, you can do this with [Versions Maven Plugin](http://www.mojohaus.org/versions-maven-plugin/).\\n\\n### Release orchestration\\nThis job will:\\n * Orchestrates a release.\\n * Is parameterized with each repo.\\n * When triggered:\\n   * Calculates the order to release selected repos. With the information found in their *Jenkinsfile*:s.\\n   * Invokes the *release*-jobs of each selected repo.\\n\\n# Features\\nHere is what features this setup can provide and how I intend them to be used.\\n## Release\\n\\nA release of a single repo can be performed from its *release*-job.\\n\\nThis will look at each repo and release from the branch that is first found in this order:\\n\\n1. *hotfix*\\n2. *release*\\n3. *develop*\\n4. *master*\\n\\nSo if you want to release from a specific commit, not latest *develop*, just push a *release*, or *hotfix*, -branch that points to that commit.\\n\\n### Orchestrating a release\\n\\nA release of one, or more, repos can be performed from the global *release-orchestration*-job. This will:\\n\\n* Ensure the release of each repo\\n  * Is done in the right order.\\n  * Their dependencies will be released first, if selected.\\n  * Use the latest release of their dependencies.\\n* After release, trigger the snapshot-job of the first repo that was released. So that all the snapshot-jobs will run and step snapshot-versions.\\n\\nIt will invoke the release-jobs of each repo. This means you can have a look there for more details on that specific release.\\n\\n## Hotfix\\n\\nHaving the priority among branches, mentioned above, will enable you to push a *hotfix*-branch from any commit and have the release being performed from that commit. If your *master* points to latest installed version:\\n\\n* `git checkout master`\\n* `git checkout -b hotfix`\\n* `git push -u origin hotfix`\\n\\nThen just trigger the release.\\n# Advantages\\nYour entire **Jenkins configuration is put under version control**. Well... you need to create one Job DSL -job manually that polls, or is triggered by changes in, the git service. But that job can have its DSL in a Git-repo. This has a bunch of advantages.\\n\\n * No more browsing around in Jenkins and fiddling with settings.\\n * You can track changes in the jobs. Just use `git blame`, it is all code now!\\n * All your jobs are backed up with Git.\\n * You can easily setup a development instance of Jenkins that behaves very much like your production instance.\\n * You can generate release-jobs in one Jenkins and snapshot jobs in another. Letting only a few people use the release-jenkins and anyone use the other instance.\"}]],\"markups\":[],\"sections\":[[10,0]]}","html":"<p>This is a pattern that I find simple, easy/quick while still keeping you in control of your build flow. Should be no problem applying it in an organization with a huge amount of repositories!</p>\n<p>I am exclusively involved in <strong>Java projects</strong>. This post will sometimes assume <em>Maven</em> is being used. But it can probably inspire a solution in other projects too. I will not supply the complete running code. I'm just going to include small snippets and focus on explaining the general idea.</p>\n<h1 id=\"problems\">Problems</h1>\n<p>Splitting a big application into several smaller artifacts is a good thing! To me, that is obvious but still I find myself talking to people that don't agree on that. Here are some of the arguments I hear on why not to split applications.</p>\n<blockquote>\n<p>&quot;I want to build whatever I have checked out, locally, on my filesystem. We will need to spend many frustrating hours stepping dependencies between artifacts.&quot;</p>\n</blockquote>\n<blockquote>\n<p>&quot;It is hard to detect when artifacts no longer fit together. We will find severe problems late because we don't continuously integrate all the artifacts.&quot;</p>\n</blockquote>\n<blockquote>\n<p>&quot;We will need a huge amount of jobs in Jenkins (releasing, testing, integrating, deploying, snapshots...). We will need to spend much time managing them.&quot;</p>\n</blockquote>\n<p>Ok! All valid points! And <strong>all of them are more or less show stoppers if you don't do continuous integration right!</strong></p>\n<h1 id=\"solution\">Solution</h1>\n<p>In short, I propose a solution where you:</p>\n<ul>\n<li>Define a clear branching strategy.</li>\n<li>Define a translation strategy between branch and Maven artifact version.</li>\n<li>Define how any given repo should be built.</li>\n<li>Automate and define how repos depend on each other.</li>\n<li>Add a <em>Jenkinsfile</em> to each repo.</li>\n<li>Create a <a href=\"https://jenkins.io/doc/book/pipeline/shared-libraries/\">shared pipeline library</a>.</li>\n<li>Automate the creation of the jobs.</li>\n</ul>\n<p>You might consider <a href=\"https://wiki.jenkins.io/display/JENKINS/Pipeline+Multibranch+Plugin\">Pipeline Multibranch Plugin</a>. I use <a href=\"https://github.com/jenkinsci/job-dsl-plugin/wiki\">Job DSL</a> and <a href=\"https://plugins.jenkins.io/cloudbees-folder\">Folders Plugin</a>. I have it create ordinary <a href=\"https://jenkins.io/doc/book/pipeline/\">pipeline</a>-jobs in a folder structure with a folder for each repository.</p>\n<ul>\n<li>It gives me something static, the name of each job, to use when chaining jobs that depend on each other. There is a folder for each repository and it contains the jobs.</li>\n<li>It also allows several jobs to work with the same branch. I can easily create a release-job and a snapshot-job that both work with the <em>develop</em> branch.</li>\n</ul>\n<p>You could have a static release-job and use mutlibranch to dynamically create every other job. But still, I feel I have more control with <em>Job DSL</em> and I feel it makes Jenkins look more organized.</p>\n<h2 id=\"branchingstrategy\">Branching strategy</h2>\n<p>You must know the meaing of the branches, in any given repo, in order to automate things. A defined branching strategy enables you to:</p>\n<ul>\n<li>Clone any given repo.</li>\n<li>Detect what branches exists.</li>\n<li>Be sure which branch to use for <em>snapshots</em> or <em>releases</em>.</li>\n</ul>\n<p>If your strategy is <a href=\"https://bjurr.com/gitflow-and-when-you-should-use-it/\">GitFlow</a>, then:</p>\n<ul>\n<li>The <em>snapshot</em>-job will\n<ul>\n<li>Build snapshots from <em>develop</em>.</li>\n<li>Step dependencies in <em>develop</em>.</li>\n</ul>\n</li>\n<li>The <em>release</em>-job will\n<ul>\n<li>Build releases from <em>hotfix</em> if it exists or else  <em>release</em>.</li>\n</ul>\n</li>\n<li>The <em>feature</em>-job will build any <em>feature/X</em>-branches.</li>\n</ul>\n<p>Each repository has one release-cycle. Several artifacts, in the same repo, with different release-cycles are not allowed.</p>\n<h2 id=\"branchtoversiontranslation\">Branch to version translation</h2>\n<p>The integration between the Git service and Jenkins is setup so that when a commit is pushed to a feature-branch:</p>\n<ul>\n<li>A job is triggered.</li>\n<li>The branch name is identified.</li>\n<li>A version is derived form the branch name.</li>\n<li>Check to see if there is global a <code>bom</code> with that version\n<ul>\n<li>If no <code>bom</code> fall back to some default, fail or automate creation of that bom-version.</li>\n</ul>\n</li>\n<li>The artifacts are built, with a <code>bom</code> with the version, and uploaded to a Maven repository.</li>\n</ul>\n<p>The <code>bom</code> -repo may function in the same way. Developers branch out of <em>develop</em>, getting all default versions. They set specific versions for some artifacts and commit/push. Or you automate that same procedure whenever a <code>bom</code>-version is missing. Then the artifact that originally triggered the creation of that bom can find its version and set it to itself.</p>\n<p>Then it will be possible to automatically create <em>deploy</em>-jobs for any &quot;deployaple&quot; repository. Where a dropdown list can automatically be populated with features. Features are found by listing feature-branches and translating to versions.</p>\n<p>Developers won't have to fiddle with versions locally, they just have whatever version that is also in <em>develop</em>-branches. And can clone a bunch of repos, built locally, and work with that fitting together.</p>\n<h2 id=\"building\">Building</h2>\n<p>You must know how to build any given repo. With Maven, the aggreement might be as simple as:</p>\n<ul>\n<li>The project is built from the root of the repo.</li>\n<li>The version, of the repository, is specified in the root of the repo. When using Maven, it is the version of the <em>pom.xml</em>.</li>\n<li>Different Maven profiles are allowed. Any profiles that produces artifacts should be specified as metadata about the repo in the <em>Jenkinsfile</em>.</li>\n</ul>\n<p>The important thing is to define these rules. Do not start treating specific repos differently in the global build scripts. Instead specify global rules that all repos should follow.</p>\n<h2 id=\"dependingrepositories\">Depending repositories</h2>\n<p>To be able to automatically chain jobs and have them trigger each other, I need to know <em>depending repos</em> of each repo. The opposite of what you have in <code>pom.xml</code>.</p>\n<p>One way of doing that is with a job that:</p>\n<ul>\n<li>Regularly finds all repos, perhaps via the Git service REST-API.</li>\n<li>Parse the <code>pom.xml</code>-files.\n<ul>\n<li>Find out what <code>artifacts</code> are contains in what repos.</li>\n<li>Find out what <code>artifacts</code> are used in what repos.</li>\n</ul>\n</li>\n<li>Create a structure with the depending repos per repo.</li>\n<li>Optimize that structure so that transitive dependencies are removed from list of direct dependencies.</li>\n<li>Store that structure as a json text -file in a repo. Making it available for snapshot/release-jobs to clone and include.</li>\n</ul>\n<p>Having this information pre-calculated saves alot of time when it is needed by some job.</p>\n<p>Perhaps the depending repo structure can look something like this.</p>\n<pre><code>{\n ...\n &quot;PROJECT-A/example-repo-d&quot;: [\n  &quot;PROJECT-B/example-repo-b&quot;,\n  &quot;PROJECT-C/example-repo-d&quot;\n ],\n &quot;PROJECT-C/example-repo-d&quot;: [\n  &quot;PROJECT-E/example-repo-b&quot;\n ]\n ...\n}\n</code></pre>\n<h2 id=\"jenkinsfile\">Jenkinsfile</h2>\n<p>It is very small and contains only metadata about the repo. This is just like <a href=\"https://github.com/jenkins-infra/pipeline-library/blob/master/vars/buildPlugin.groovy\">Jenkins Infra</a> handles their 1000+ plugins.</p>\n<p>When using Maven, you might want to specify <em>profiles</em> to be built.</p>\n<p>A repo that needs to be built, nothing else, may look like this:</p>\n<pre><code>buildRepo()\n</code></pre>\n<p>It may specify profiles:</p>\n<pre><code>buildRepo(\n profiles: [\n  'profile1'\n ]\n)\n</code></pre>\n<p>And if a profiles are needed as well as no profile, it may look like:</p>\n<pre><code>buildRepo(\n profiles: [\n  '',\n  'profile1'\n ]\n)\n</code></pre>\n<p>This is all there is in the repositories. Only one <em>Jenkinsfile</em> and this is the only information it contains. I'm not saying you only need this. I'm just recommending to keep it light! Perhaps you invent thnkgs like <code>deployable: true</code> or <code>autoDeployEnv: 'TEST-XY'</code>...</p>\n<h2 id=\"sharedlibrary\">Shared library</h2>\n<p>A <a href=\"https://jenkins.io/doc/book/pipeline/shared-libraries/\">shared pipeline library</a> allows you to, only once, define how to do releases, snapshots and all other tasks.</p>\n<p>With the above <em>Jenkinsfile</em> there should be a <code>/vars/buildRepo.groovy</code> containing something like:</p>\n<pre><code>...\ndef call(Map params = [:]) {\n...\n if (JOB_BASE_NAME.equals(&quot;snapshot&quot;)) {\n ...\n } else if (JOB_BASE_NAME.equals(&quot;release&quot;)) {\n ...\n }\n...\n}\n...\n</code></pre>\n<h2 id=\"automatecreationofjobs\">Automate creation of jobs</h2>\n<p>Most Git services (GitHub, GitLab, Bitbucket...) provide REST API:s. You can use that to automate creation/deletion/adjustment of jobs and always be in sync with the repos you have in your Git service. The job DSL would loop through all repositories.</p>\n<pre><code>...\n folder(&quot;gen&quot;) {\n  displayName(&quot;Generated jobs&quot;)\n  description(&quot;&quot;&quot;\n   These are generated by ${JOB_URL}\n  &quot;&quot;&quot;)\n }\n\n getJson(server+ &quot;/rest/request/to/repos...&quot;)\n  .values\n  .each { repo -&gt;\n  folder(&quot;gen&quot;) {\n   displayName(&quot;gen/&quot; + repo.name)\n   description(&quot;&quot;&quot;\n    Generated by ${JOB_URL}\n   &quot;&quot;&quot;)\n  }\n\n  pipelineJob(&quot;gen/&quot; + repo.name + &quot;/snapshot&quot;) {\n...\n</code></pre>\n<h2 id=\"templates\">Templates</h2>\n<p>I use the <a href=\"https://github.com/jenkinsci/job-dsl-plugin/wiki\">Job DSL</a> plugin. Perhaps you want these jobs for every repository:</p>\n<ul>\n<li><em>snapshot</em></li>\n<li><em>release</em></li>\n<li><em>feature</em></li>\n<li><em>pull-request</em></li>\n</ul>\n<p>Also a global job, <em>release-orchestration</em>.</p>\n<p>All of these templates are pipelines. Their logic is implemented in the shared library. The shared library will find the Git repo to use from <code>scm.getUserRemoteConfigs().get(0).getUrl()</code> and the kind of job to build from <code>JOB_BASE_NAME</code>.</p>\n<h3 id=\"snapshot\">Snapshot</h3>\n<p>This job will:</p>\n<ul>\n<li>Make sure <em>develop</em> is using latest dependencies (<a href=\"http://www.mojohaus.org/versions-maven-plugin/update-properties-mojo.html\">found in Maven repository</a>). If there are newer versions:\n<ul>\n<li>Step dependencies to latest version.</li>\n<li>Commit changes.</li>\n<li>Push changes.</li>\n<li>Re-trigger self, to help Jenkins understand that this new commit does not need to be built again. Done.</li>\n</ul>\n</li>\n<li>Build a snapshot version.</li>\n<li>Upload snapshot-version to Maven repository.</li>\n<li>Trigger <em>dependingRepos</em> configured in <em>Jenkinsfile</em>.</li>\n<li>Done.</li>\n</ul>\n<p>When using Maven, you can do this with <a href=\"http://www.mojohaus.org/versions-maven-plugin/\">Versions Maven Plugin</a>.</p>\n<h3 id=\"release\">Release</h3>\n<p>This job will:</p>\n<ul>\n<li>Start from commit <em>C1</em>.</li>\n<li>Set dependencies to latest released versions.</li>\n<li>Step version to next release-version.</li>\n<li>Make a commit <em>C2</em>.</li>\n<li>Set dependencies to latest snapshots.</li>\n<li>Step version to next snapshot-version.</li>\n<li>Make a commit <em>C3</em>.</li>\n<li>Try to push changes. If not successful:\n<ul>\n<li>Hard reset to <em>C1</em>.</li>\n<li>Pull.</li>\n<li>Start again with creating <em>C2</em>.</li>\n<li>Do this loop, perhaps 5 times before giving up and fail.</li>\n</ul>\n</li>\n</ul>\n<p>This allows developers to work in the branches during the release-process.</p>\n<p>Now that we know we are in sync with remote Git repo on where to perform the release, we can continue doing so.</p>\n<ul>\n<li>Tag <em>C2</em> with the release-version.</li>\n<li>Perform the build commands, <code>mvn package</code> and loop any profiles needed.</li>\n<li>Deploy in Maven repository, <code>mvn deploy</code>.</li>\n</ul>\n<p>When using Maven, you can do this with <a href=\"http://www.mojohaus.org/versions-maven-plugin/\">Versions Maven Plugin</a>.</p>\n<h3 id=\"releaseorchestration\">Release orchestration</h3>\n<p>This job will:</p>\n<ul>\n<li>Orchestrates a release.</li>\n<li>Is parameterized with each repo.</li>\n<li>When triggered:\n<ul>\n<li>Calculates the order to release selected repos. With the information found in their <em>Jenkinsfile</em>:s.</li>\n<li>Invokes the <em>release</em>-jobs of each selected repo.</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"features\">Features</h1>\n<p>Here is what features this setup can provide and how I intend them to be used.</p>\n<h2 id=\"release\">Release</h2>\n<p>A release of a single repo can be performed from its <em>release</em>-job.</p>\n<p>This will look at each repo and release from the branch that is first found in this order:</p>\n<ol>\n<li><em>hotfix</em></li>\n<li><em>release</em></li>\n<li><em>develop</em></li>\n<li><em>master</em></li>\n</ol>\n<p>So if you want to release from a specific commit, not latest <em>develop</em>, just push a <em>release</em>, or <em>hotfix</em>, -branch that points to that commit.</p>\n<h3 id=\"orchestratingarelease\">Orchestrating a release</h3>\n<p>A release of one, or more, repos can be performed from the global <em>release-orchestration</em>-job. This will:</p>\n<ul>\n<li>Ensure the release of each repo\n<ul>\n<li>Is done in the right order.</li>\n<li>Their dependencies will be released first, if selected.</li>\n<li>Use the latest release of their dependencies.</li>\n</ul>\n</li>\n<li>After release, trigger the snapshot-job of the first repo that was released. So that all the snapshot-jobs will run and step snapshot-versions.</li>\n</ul>\n<p>It will invoke the release-jobs of each repo. This means you can have a look there for more details on that specific release.</p>\n<h2 id=\"hotfix\">Hotfix</h2>\n<p>Having the priority among branches, mentioned above, will enable you to push a <em>hotfix</em>-branch from any commit and have the release being performed from that commit. If your <em>master</em> points to latest installed version:</p>\n<ul>\n<li><code>git checkout master</code></li>\n<li><code>git checkout -b hotfix</code></li>\n<li><code>git push -u origin hotfix</code></li>\n</ul>\n<p>Then just trigger the release.</p>\n<h1 id=\"advantages\">Advantages</h1>\n<p>Your entire <strong>Jenkins configuration is put under version control</strong>. Well... you need to create one Job DSL -job manually that polls, or is triggered by changes in, the git service. But that job can have its DSL in a Git-repo. This has a bunch of advantages.</p>\n<ul>\n<li>No more browsing around in Jenkins and fiddling with settings.</li>\n<li>You can track changes in the jobs. Just use <code>git blame</code>, it is all code now!</li>\n<li>All your jobs are backed up with Git.</li>\n<li>You can easily setup a development instance of Jenkins that behaves very much like your production instance.</li>\n<li>You can generate release-jobs in one Jenkins and snapshot jobs in another. Letting only a few people use the release-jenkins and anyone use the other instance.</li>\n</ul>\n","comment_id":"5a755597c56a61057b219788","plaintext":"This is a pattern that I find simple, easy/quick while still keeping you in\ncontrol of your build flow. Should be no problem applying it in an organization\nwith a huge amount of repositories!\n\nI am exclusively involved in Java projects. This post will sometimes assume \nMaven  is being used. But it can probably inspire a solution in other projects\ntoo. I will not supply the complete running code. I'm just going to include\nsmall snippets and focus on explaining the general idea.\n\nProblems\nSplitting a big application into several smaller artifacts is a good thing! To\nme, that is obvious but still I find myself talking to people that don't agree\non that. Here are some of the arguments I hear on why not to split applications.\n\n\"I want to build whatever I have checked out, locally, on my filesystem. We will\nneed to spend many frustrating hours stepping dependencies between artifacts.\"\n\n\"It is hard to detect when artifacts no longer fit together. We will find severe\nproblems late because we don't continuously integrate all the artifacts.\"\n\n\"We will need a huge amount of jobs in Jenkins (releasing, testing, integrating,\ndeploying, snapshots...). We will need to spend much time managing them.\"\n\nOk! All valid points! And all of them are more or less show stoppers if you\ndon't do continuous integration right!\n\nSolution\nIn short, I propose a solution where you:\n\n * Define a clear branching strategy.\n * Define a translation strategy between branch and Maven artifact version.\n * Define how any given repo should be built.\n * Automate and define how repos depend on each other.\n * Add a Jenkinsfile  to each repo.\n * Create a shared pipeline library\n   [https://jenkins.io/doc/book/pipeline/shared-libraries/].\n * Automate the creation of the jobs.\n\nYou might consider Pipeline Multibranch Plugin\n[https://wiki.jenkins.io/display/JENKINS/Pipeline+Multibranch+Plugin]. I use \nJob\nDSL [https://github.com/jenkinsci/job-dsl-plugin/wiki]  and Folders Plugin\n[https://plugins.jenkins.io/cloudbees-folder]. I have it create ordinary \npipeline [https://jenkins.io/doc/book/pipeline/]-jobs in a folder structure with\na folder for each repository.\n\n * It gives me something static, the name of each job, to use when chaining jobs\n   that depend on each other. There is a folder for each repository and it\n   contains the jobs.\n * It also allows several jobs to work with the same branch. I can easily create\n   a release-job and a snapshot-job that both work with the develop  branch.\n\nYou could have a static release-job and use mutlibranch to dynamically create\nevery other job. But still, I feel I have more control with Job DSL  and I feel\nit makes Jenkins look more organized.\n\nBranching strategy\nYou must know the meaing of the branches, in any given repo, in order to\nautomate things. A defined branching strategy enables you to:\n\n * Clone any given repo.\n * Detect what branches exists.\n * Be sure which branch to use for snapshots  or releases.\n\nIf your strategy is GitFlow\n[https://bjurr.com/gitflow-and-when-you-should-use-it/], then:\n\n * The snapshot-job will * Build snapshots from develop.\n    * Step dependencies in develop.\n   \n   \n * The release-job will * Build releases from hotfix  if it exists or else release.\n   \n   \n * The feature-job will build any feature/X-branches.\n\nEach repository has one release-cycle. Several artifacts, in the same repo, with\ndifferent release-cycles are not allowed.\n\nBranch to version translation\nThe integration between the Git service and Jenkins is setup so that when a\ncommit is pushed to a feature-branch:\n\n * A job is triggered.\n * The branch name is identified.\n * A version is derived form the branch name.\n * Check to see if there is global a bom  with that version * If no bom  fall back to some default, fail or automate creation of that\n      bom-version.\n   \n   \n * The artifacts are built, with a bom  with the version, and uploaded to a\n   Maven repository.\n\nThe bom  -repo may function in the same way. Developers branch out of develop,\ngetting all default versions. They set specific versions for some artifacts and\ncommit/push. Or you automate that same procedure whenever a bom-version is\nmissing. Then the artifact that originally triggered the creation of that bom\ncan find its version and set it to itself.\n\nThen it will be possible to automatically create deploy-jobs for any\n\"deployaple\" repository. Where a dropdown list can automatically be populated\nwith features. Features are found by listing feature-branches and translating to\nversions.\n\nDevelopers won't have to fiddle with versions locally, they just have whatever\nversion that is also in develop-branches. And can clone a bunch of repos, built\nlocally, and work with that fitting together.\n\nBuilding\nYou must know how to build any given repo. With Maven, the aggreement might be\nas simple as:\n\n * The project is built from the root of the repo.\n * The version, of the repository, is specified in the root of the repo. When\n   using Maven, it is the version of the pom.xml.\n * Different Maven profiles are allowed. Any profiles that produces artifacts\n   should be specified as metadata about the repo in the Jenkinsfile.\n\nThe important thing is to define these rules. Do not start treating specific\nrepos differently in the global build scripts. Instead specify global rules that\nall repos should follow.\n\nDepending repositories\nTo be able to automatically chain jobs and have them trigger each other, I need\nto know depending repos  of each repo. The opposite of what you have in pom.xml.\n\nOne way of doing that is with a job that:\n\n * Regularly finds all repos, perhaps via the Git service REST-API.\n * Parse the pom.xml-files. * Find out what artifacts  are contains in what repos.\n    * Find out what artifacts  are used in what repos.\n   \n   \n * Create a structure with the depending repos per repo.\n * Optimize that structure so that transitive dependencies are removed from list\n   of direct dependencies.\n * Store that structure as a json text -file in a repo. Making it available for\n   snapshot/release-jobs to clone and include.\n\nHaving this information pre-calculated saves alot of time when it is needed by\nsome job.\n\nPerhaps the depending repo structure can look something like this.\n\n{\n ...\n \"PROJECT-A/example-repo-d\": [\n  \"PROJECT-B/example-repo-b\",\n  \"PROJECT-C/example-repo-d\"\n ],\n \"PROJECT-C/example-repo-d\": [\n  \"PROJECT-E/example-repo-b\"\n ]\n ...\n}\n\n\nJenkinsfile\nIt is very small and contains only metadata about the repo. This is just like \nJenkins Infra\n[https://github.com/jenkins-infra/pipeline-library/blob/master/vars/buildPlugin.groovy] \n handles their 1000+ plugins.\n\nWhen using Maven, you might want to specify profiles  to be built.\n\nA repo that needs to be built, nothing else, may look like this:\n\nbuildRepo()\n\n\nIt may specify profiles:\n\nbuildRepo(\n profiles: [\n  'profile1'\n ]\n)\n\n\nAnd if a profiles are needed as well as no profile, it may look like:\n\nbuildRepo(\n profiles: [\n  '',\n  'profile1'\n ]\n)\n\n\nThis is all there is in the repositories. Only one Jenkinsfile  and this is the\nonly information it contains. I'm not saying you only need this. I'm just\nrecommending to keep it light! Perhaps you invent thnkgs like deployable: true \nor autoDeployEnv: 'TEST-XY'...\n\nShared library\nA shared pipeline library\n[https://jenkins.io/doc/book/pipeline/shared-libraries/]  allows you to, only\nonce, define how to do releases, snapshots and all other tasks.\n\nWith the above Jenkinsfile  there should be a /vars/buildRepo.groovy  containing\nsomething like:\n\n...\ndef call(Map params = [:]) {\n...\n if (JOB_BASE_NAME.equals(\"snapshot\")) {\n ...\n } else if (JOB_BASE_NAME.equals(\"release\")) {\n ...\n }\n...\n}\n...\n\n\nAutomate creation of jobs\nMost Git services (GitHub, GitLab, Bitbucket...) provide REST API:s. You can use\nthat to automate creation/deletion/adjustment of jobs and always be in sync with\nthe repos you have in your Git service. The job DSL would loop through all\nrepositories.\n\n...\n folder(\"gen\") {\n  displayName(\"Generated jobs\")\n  description(\"\"\"\n   These are generated by ${JOB_URL}\n  \"\"\")\n }\n\n getJson(server+ \"/rest/request/to/repos...\")\n  .values\n  .each { repo ->\n  folder(\"gen\") {\n   displayName(\"gen/\" + repo.name)\n   description(\"\"\"\n    Generated by ${JOB_URL}\n   \"\"\")\n  }\n\n  pipelineJob(\"gen/\" + repo.name + \"/snapshot\") {\n...\n\n\nTemplates\nI use the Job DSL [https://github.com/jenkinsci/job-dsl-plugin/wiki]  plugin.\nPerhaps you want these jobs for every repository:\n\n * snapshot\n * release\n * feature\n * pull-request\n\nAlso a global job, release-orchestration.\n\nAll of these templates are pipelines. Their logic is implemented in the shared\nlibrary. The shared library will find the Git repo to use from \nscm.getUserRemoteConfigs().get(0).getUrl()  and the kind of job to build from \nJOB_BASE_NAME.\n\nSnapshot\nThis job will:\n\n * Make sure develop  is using latest dependencies (found in Maven repository\n   [http://www.mojohaus.org/versions-maven-plugin/update-properties-mojo.html]).\n   If there are newer versions: * Step dependencies to latest version.\n    * Commit changes.\n    * Push changes.\n    * Re-trigger self, to help Jenkins understand\n      that this new commit does not need to be built again. Done.\n   \n   \n * Build a snapshot version.\n * Upload snapshot-version to Maven repository.\n * Trigger dependingRepos  configured in Jenkinsfile.\n * Done.\n\nWhen using Maven, you can do this with Versions Maven Plugin\n[http://www.mojohaus.org/versions-maven-plugin/].\n\nRelease\nThis job will:\n\n * Start from commit C1.\n * Set dependencies to latest released versions.\n * Step version to next release-version.\n * Make a commit C2.\n * Set dependencies to latest snapshots.\n * Step version to next snapshot-version.\n * Make a commit C3.\n * Try to push changes. If not successful: * Hard reset to C1.\n    * Pull.\n    * Start again with creating C2.\n    * Do this loop, perhaps 5 times\n      before giving up and fail.\n   \n   \n\nThis allows developers to work in the branches during the release-process.\n\nNow that we know we are in sync with remote Git repo on where to perform the\nrelease, we can continue doing so.\n\n * Tag C2  with the release-version.\n * Perform the build commands, mvn package  and loop any profiles needed.\n * Deploy in Maven repository, mvn deploy.\n\nWhen using Maven, you can do this with Versions Maven Plugin\n[http://www.mojohaus.org/versions-maven-plugin/].\n\nRelease orchestration\nThis job will:\n\n * Orchestrates a release.\n * Is parameterized with each repo.\n * When triggered: * Calculates the order to release selected repos. With the\n      information found in their Jenkinsfile:s.\n    * Invokes the release-jobs of each selected repo.\n   \n   \n\nFeatures\nHere is what features this setup can provide and how I intend them to be used.\n\nRelease\nA release of a single repo can be performed from its release-job.\n\nThis will look at each repo and release from the branch that is first found in\nthis order:\n\n 1. hotfix\n 2. release\n 3. develop\n 4. master\n\nSo if you want to release from a specific commit, not latest develop, just push\na release, or hotfix, -branch that points to that commit.\n\nOrchestrating a release\nA release of one, or more, repos can be performed from the global \nrelease-orchestration-job. This will:\n\n * Ensure the release of each repo * Is done in the right order.\n    * Their dependencies will be released first,\n      if selected.\n    * Use the latest release of their\n      dependencies.\n   \n   \n * After release, trigger the snapshot-job of the first repo that was released.\n   So that all the snapshot-jobs will run and step snapshot-versions.\n\nIt will invoke the release-jobs of each repo. This means you can have a look\nthere for more details on that specific release.\n\nHotfix\nHaving the priority among branches, mentioned above, will enable you to push a \nhotfix-branch from any commit and have the release being performed from that\ncommit. If your master  points to latest installed version:\n\n * git checkout master\n * git checkout -b hotfix\n * git push -u origin hotfix\n\nThen just trigger the release.\n\nAdvantages\nYour entire Jenkins configuration is put under version control. Well... you need\nto create one Job DSL -job manually that polls, or is triggered by changes in,\nthe git service. But that job can have its DSL in a Git-repo. This has a bunch\nof advantages.\n\n * No more browsing around in Jenkins and fiddling with settings.\n * You can track changes in the jobs. Just use git blame, it is all code now!\n * All your jobs are backed up with Git.\n * You can easily setup a development instance of Jenkins that behaves very much\n   like your production instance.\n * You can generate release-jobs in one Jenkins and snapshot jobs in another.\n   Letting only a few people use the release-jenkins and anyone use the other\n   instance.","feature_image":"/content/images/2018/02/superhero-1.png","featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2018-02-03T06:24:23.000Z","created_by":"1","updated_at":"2018-09-14T12:37:37.000Z","updated_by":"1","published_at":"2018-02-03T06:39:55.000Z","published_by":"1","custom_excerpt":null,"codeinjection_head":"","codeinjection_foot":"","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"custom_template":null},{"id":"5ac3be89b907cf054a31895e","uuid":"071a3b73-dfc8-40b7-8248-bcfa454ba56e","title":"Jenkins Integration on Steroids","slug":"jenkins-integration-on-steroids","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"Parameterized jobs in Jenkins is nothing new. But integrating with services like GitHub is much more than just accepting some *GET* parameters. [Generic Webhook Trigger](https://plugins.jenkins.io/generic-webhook-trigger) aims at simplifying triggering of jobs from complex *JSON*/*XML* webhook structures.\\n\\nI got the idea while working on the GitLab plugin. I [just needed a simple integer](https://github.com/jenkinsci/gitlab-plugin/pull/510) value from the GitLab webhook. After I opened [the PR](https://github.com/jenkinsci/gitlab-plugin/pull/510), it took 4+ months before it was merged and later released. Such a simple thing should not require that level of effort. But it is, and it is like that in other trigger plugins as well!\\n\\nThe idea with [Generic Webhook Trigger](https://plugins.jenkins.io/generic-webhook-trigger) is very simple.\\n\\n1. Post content is received.\\n2. Values are extracted from the received post content, using [JSONPath](https://github.com/json-path/JsonPath) or [XPath](https://www.w3schools.com/xml/xpath_intro.asp). And are contributed to the build with the configured variable names.\\n3. [Regular expression](https://jex.im/regulex/) is used to match the patterns that should trigger a build.\\n\\nThe webhooks provided by different services are often well documented. In contrast to all the different Jenkins plugins that consume them. That shows another advantage of using [Generic Webhook Trigger](https://plugins.jenkins.io/generic-webhook-trigger). You will be able to understand what you are doing. The alternative is to spend many frustrating hours with a bunch of very complex plugins.\\n\\nI think most Jenkins users just wants a way to consume a webhook. [This plugin](https://plugins.jenkins.io/generic-webhook-trigger) enables that and lets the users implement any use cases themselves. I think that is the best way to do it now that we have pipelines. Before pipelines there was a bigger need for complex plugins.\\n\\n## Simple use case\\n\\nLet's say we have a Git repository. It has some files in it, structured something like this:\\n```\\nsrc/main/java/...\\nsrc/test/java/...\\nsrc/main/resources/sql/...\\n```\\n\\n### Requirements\\n\\n* If the files in `src/main/resources/sql` is changed, then we want to run the SQL in a Docker to verify them. If these files are not changed, then we don't want to verify them. Perhaps it is a time consuming task and we want to avoid it.\\n* We are not allowed to use polling. We want instant builds and cannot have a large amount of Jenkins jobs polling our Git service every minute.\\n\\n### Implementation\\n\\nFirst step would be to setup the webhook in GitHub and point it to the running Jenkins instance.\\n\\n* Go to the webhooks page: https://github.com/tomasbjerre/you-repo-name/settings/hooks/\\n  * Set the *Content type* to `application/json`\\n  * Set the *Payload URL* to `http://JENKINS_URL/generic-webhook-trigger/invoke?token=abc123`\\n\\nNext step, create a job in Jenkins and configure [Generic Webhook Trigger](https://plugins.jenkins.io/generic-webhook-trigger). It supports Multibranch pipelines but I usually just create pipeline jobs using [Job DSL Plugin](https://github.com/jenkinsci/job-dsl-plugin/wiki). That is a bit off topic and covered in the documentation in GitHub.\\n\\n* Go to you Jenkins instance: http://localhost:8080/jenkins/\\n* Create a new job, perhaps Pipeline or Free Style.\\n* A new Trigger will appear, once [Generic Webhook Trigger](https://plugins.jenkins.io/generic-webhook-trigger) is installed, named \\\"*Generic Webhook Trigger*\\\". I'm adding variable named `changed_files` with expression `$.commits[*].['modified','added','removed'][*]`.\\n![generic_trigger_expr_files](/content/images/2018/04/generic_trigger_expr_files.png) You will probably want more variables here. Perhaps `$.ref` to get the branch name or `$.after` to get the commit that the ref points at after the change.\\n* Configure a token, this is how the invoker will know which job to trigger. If a job has a token configured then that token has to be supplied. If the job has no token configured then anyone can trigger the job.\\n![configure-token-1](/content/images/2018/08/configure-token-1.png)\\n* Add a filter with `text` like `$changed_files` and `expression` like `\\\"src/main/resources/sql/[^\\\"]+?\\\"`.\\n![generic_expr_folder](/content/images/2018/04/generic_expr_folder.png)  I'm only using one variable here but you can resolve more variables. Add more variables to the text-field and have a more complex regular expression.\\n\\nThat is it. Save the job and it will trigger for changes in SQL-scripts and nothing else!\\n\\n### Explaination\\n\\nSo what happens in the example above? When a commit is pushed to GitHub, it will invoke the the configured URL with a webhook. In reality, there is [much more](https://developer.github.com/v3/activity/events/types/#pushevent) in the webhook then this:\\n```\\n{\\n \\\"ref\\\": \\\"refs/heads/changes\\\",\\n \\\"after\\\": \\\"0d1a26e67d8f5eaf1f6ba5c57fc3c7d91ac0fd1c\\\",\\n \\\"commits\\\": [\\n  {\\n   \\\"added\\\": [\\n    \\\".gitignore\\\"\\n   ],\\n   \\\"removed\\\": [\\n   ],\\n   \\\"modified\\\": [\\n    \\\"README.md\\\",\\n    \\\"src/main/resources/sql/some_script.sql\\\"\\n   ]\\n  }\\n ],\\n repository {\\n  \\\"git_url\\\": \\\"git://github.com/baxterthehacker/public-repo.git\\\"\\n }\\n}\\n```\\n\\nThe [JSONPath](https://github.com/json-path/JsonPath) used above will resolve to `[\\\".gitignore\\\", \\\"README.md\\\", \\\"src/main/resources/sql/some_script.sql\\\"]` and it will be available in a variable `$changed_files` (that can also be used later in the build).\\n\\nThe `text` field of the *Optional filter* will also resolve to this, because we used `$changed_files` in that field.\\n\\nThe `expression` field of the *Optional filter* will match `src/main/resources/sql/some_script.sql` which will trigger the build. Without that change, the build would not have been triggered.\\n\\nIf you also define variables like:\\n* **branch** with expression `$.ref`\\n* **clone_url** with expression `$.repository.git_url`\\n\\nThen you can have a shell script build step like:\\n```\\ngit clone $clone_url\\ngit checkout $branch\\n...\\n```\\n\\n## Further reading\\n\\nAlways turn to the wiki for the most accurate documentation:\\nhttps://plugins.jenkins.io/generic-webhook-trigger\\n\\nAny issues should be reported here:\\nhttps://github.com/jenkinsci/generic-webhook-trigger-plugin/issues\\n\"}]],\"markups\":[],\"sections\":[[10,0]]}","html":"<p>Parameterized jobs in Jenkins is nothing new. But integrating with services like GitHub is much more than just accepting some <em>GET</em> parameters. <a href=\"https://plugins.jenkins.io/generic-webhook-trigger\">Generic Webhook Trigger</a> aims at simplifying triggering of jobs from complex <em>JSON</em>/<em>XML</em> webhook structures.</p>\n<p>I got the idea while working on the GitLab plugin. I <a href=\"https://github.com/jenkinsci/gitlab-plugin/pull/510\">just needed a simple integer</a> value from the GitLab webhook. After I opened <a href=\"https://github.com/jenkinsci/gitlab-plugin/pull/510\">the PR</a>, it took 4+ months before it was merged and later released. Such a simple thing should not require that level of effort. But it is, and it is like that in other trigger plugins as well!</p>\n<p>The idea with <a href=\"https://plugins.jenkins.io/generic-webhook-trigger\">Generic Webhook Trigger</a> is very simple.</p>\n<ol>\n<li>Post content is received.</li>\n<li>Values are extracted from the received post content, using <a href=\"https://github.com/json-path/JsonPath\">JSONPath</a> or <a href=\"https://www.w3schools.com/xml/xpath_intro.asp\">XPath</a>. And are contributed to the build with the configured variable names.</li>\n<li><a href=\"https://jex.im/regulex/\">Regular expression</a> is used to match the patterns that should trigger a build.</li>\n</ol>\n<p>The webhooks provided by different services are often well documented. In contrast to all the different Jenkins plugins that consume them. That shows another advantage of using <a href=\"https://plugins.jenkins.io/generic-webhook-trigger\">Generic Webhook Trigger</a>. You will be able to understand what you are doing. The alternative is to spend many frustrating hours with a bunch of very complex plugins.</p>\n<p>I think most Jenkins users just wants a way to consume a webhook. <a href=\"https://plugins.jenkins.io/generic-webhook-trigger\">This plugin</a> enables that and lets the users implement any use cases themselves. I think that is the best way to do it now that we have pipelines. Before pipelines there was a bigger need for complex plugins.</p>\n<h2 id=\"simpleusecase\">Simple use case</h2>\n<p>Let's say we have a Git repository. It has some files in it, structured something like this:</p>\n<pre><code>src/main/java/...\nsrc/test/java/...\nsrc/main/resources/sql/...\n</code></pre>\n<h3 id=\"requirements\">Requirements</h3>\n<ul>\n<li>If the files in <code>src/main/resources/sql</code> is changed, then we want to run the SQL in a Docker to verify them. If these files are not changed, then we don't want to verify them. Perhaps it is a time consuming task and we want to avoid it.</li>\n<li>We are not allowed to use polling. We want instant builds and cannot have a large amount of Jenkins jobs polling our Git service every minute.</li>\n</ul>\n<h3 id=\"implementation\">Implementation</h3>\n<p>First step would be to setup the webhook in GitHub and point it to the running Jenkins instance.</p>\n<ul>\n<li>Go to the webhooks page: <a href=\"https://github.com/tomasbjerre/you-repo-name/settings/hooks/\">https://github.com/tomasbjerre/you-repo-name/settings/hooks/</a>\n<ul>\n<li>Set the <em>Content type</em> to <code>application/json</code></li>\n<li>Set the <em>Payload URL</em> to <code>http://JENKINS_URL/generic-webhook-trigger/invoke?token=abc123</code></li>\n</ul>\n</li>\n</ul>\n<p>Next step, create a job in Jenkins and configure <a href=\"https://plugins.jenkins.io/generic-webhook-trigger\">Generic Webhook Trigger</a>. It supports Multibranch pipelines but I usually just create pipeline jobs using <a href=\"https://github.com/jenkinsci/job-dsl-plugin/wiki\">Job DSL Plugin</a>. That is a bit off topic and covered in the documentation in GitHub.</p>\n<ul>\n<li>Go to you Jenkins instance: <a href=\"http://localhost:8080/jenkins/\">http://localhost:8080/jenkins/</a></li>\n<li>Create a new job, perhaps Pipeline or Free Style.</li>\n<li>A new Trigger will appear, once <a href=\"https://plugins.jenkins.io/generic-webhook-trigger\">Generic Webhook Trigger</a> is installed, named &quot;<em>Generic Webhook Trigger</em>&quot;. I'm adding variable named <code>changed_files</code> with expression <code>$.commits[*].['modified','added','removed'][*]</code>.<br>\n<img src=\"/content/images/2018/04/generic_trigger_expr_files.png\" alt=\"generic_trigger_expr_files\"> You will probably want more variables here. Perhaps <code>$.ref</code> to get the branch name or <code>$.after</code> to get the commit that the ref points at after the change.</li>\n<li>Configure a token, this is how the invoker will know which job to trigger. If a job has a token configured then that token has to be supplied. If the job has no token configured then anyone can trigger the job.<br>\n<img src=\"/content/images/2018/08/configure-token-1.png\" alt=\"configure-token-1\"></li>\n<li>Add a filter with <code>text</code> like <code>$changed_files</code> and <code>expression</code> like <code>&quot;src/main/resources/sql/[^&quot;]+?&quot;</code>.<br>\n<img src=\"/content/images/2018/04/generic_expr_folder.png\" alt=\"generic_expr_folder\">  I'm only using one variable here but you can resolve more variables. Add more variables to the text-field and have a more complex regular expression.</li>\n</ul>\n<p>That is it. Save the job and it will trigger for changes in SQL-scripts and nothing else!</p>\n<h3 id=\"explaination\">Explaination</h3>\n<p>So what happens in the example above? When a commit is pushed to GitHub, it will invoke the the configured URL with a webhook. In reality, there is <a href=\"https://developer.github.com/v3/activity/events/types/#pushevent\">much more</a> in the webhook then this:</p>\n<pre><code>{\n &quot;ref&quot;: &quot;refs/heads/changes&quot;,\n &quot;after&quot;: &quot;0d1a26e67d8f5eaf1f6ba5c57fc3c7d91ac0fd1c&quot;,\n &quot;commits&quot;: [\n  {\n   &quot;added&quot;: [\n    &quot;.gitignore&quot;\n   ],\n   &quot;removed&quot;: [\n   ],\n   &quot;modified&quot;: [\n    &quot;README.md&quot;,\n    &quot;src/main/resources/sql/some_script.sql&quot;\n   ]\n  }\n ],\n repository {\n  &quot;git_url&quot;: &quot;git://github.com/baxterthehacker/public-repo.git&quot;\n }\n}\n</code></pre>\n<p>The <a href=\"https://github.com/json-path/JsonPath\">JSONPath</a> used above will resolve to <code>[&quot;.gitignore&quot;, &quot;README.md&quot;, &quot;src/main/resources/sql/some_script.sql&quot;]</code> and it will be available in a variable <code>$changed_files</code> (that can also be used later in the build).</p>\n<p>The <code>text</code> field of the <em>Optional filter</em> will also resolve to this, because we used <code>$changed_files</code> in that field.</p>\n<p>The <code>expression</code> field of the <em>Optional filter</em> will match <code>src/main/resources/sql/some_script.sql</code> which will trigger the build. Without that change, the build would not have been triggered.</p>\n<p>If you also define variables like:</p>\n<ul>\n<li><strong>branch</strong> with expression <code>$.ref</code></li>\n<li><strong>clone_url</strong> with expression <code>$.repository.git_url</code></li>\n</ul>\n<p>Then you can have a shell script build step like:</p>\n<pre><code>git clone $clone_url\ngit checkout $branch\n...\n</code></pre>\n<h2 id=\"furtherreading\">Further reading</h2>\n<p>Always turn to the wiki for the most accurate documentation:<br>\n<a href=\"https://plugins.jenkins.io/generic-webhook-trigger\">https://plugins.jenkins.io/generic-webhook-trigger</a></p>\n<p>Any issues should be reported here:<br>\n<a href=\"https://github.com/jenkinsci/generic-webhook-trigger-plugin/issues\">https://github.com/jenkinsci/generic-webhook-trigger-plugin/issues</a></p>\n","comment_id":"5ac3be89b907cf054a31895e","plaintext":"Parameterized jobs in Jenkins is nothing new. But integrating with services like\nGitHub is much more than just accepting some GET  parameters. Generic Webhook\nTrigger [https://plugins.jenkins.io/generic-webhook-trigger]  aims at\nsimplifying triggering of jobs from complex JSON/XML  webhook structures.\n\nI got the idea while working on the GitLab plugin. I just needed a simple\ninteger [https://github.com/jenkinsci/gitlab-plugin/pull/510]  value from the\nGitLab webhook. After I opened the PR\n[https://github.com/jenkinsci/gitlab-plugin/pull/510], it took 4+ months before\nit was merged and later released. Such a simple thing should not require that\nlevel of effort. But it is, and it is like that in other trigger plugins as\nwell!\n\nThe idea with Generic Webhook Trigger\n[https://plugins.jenkins.io/generic-webhook-trigger]  is very simple.\n\n 1. Post content is received.\n 2. Values are extracted from the received post content, using JSONPath\n    [https://github.com/json-path/JsonPath]  or XPath\n    [https://www.w3schools.com/xml/xpath_intro.asp]. And are contributed to the\n    build with the configured variable names.\n 3. Regular expression [https://jex.im/regulex/]  is used to match the patterns\n    that should trigger a build.\n\nThe webhooks provided by different services are often well documented. In\ncontrast to all the different Jenkins plugins that consume them. That shows\nanother advantage of using Generic Webhook Trigger\n[https://plugins.jenkins.io/generic-webhook-trigger]. You will be able to\nunderstand what you are doing. The alternative is to spend many frustrating\nhours with a bunch of very complex plugins.\n\nI think most Jenkins users just wants a way to consume a webhook. This plugin\n[https://plugins.jenkins.io/generic-webhook-trigger]  enables that and lets the\nusers implement any use cases themselves. I think that is the best way to do it\nnow that we have pipelines. Before pipelines there was a bigger need for complex\nplugins.\n\nSimple use case\nLet's say we have a Git repository. It has some files in it, structured\nsomething like this:\n\nsrc/main/java/...\nsrc/test/java/...\nsrc/main/resources/sql/...\n\n\nRequirements\n * If the files in src/main/resources/sql  is changed, then we want to run the\n   SQL in a Docker to verify them. If these files are not changed, then we don't\n   want to verify them. Perhaps it is a time consuming task and we want to avoid\n   it.\n * We are not allowed to use polling. We want instant builds and cannot have a\n   large amount of Jenkins jobs polling our Git service every minute.\n\nImplementation\nFirst step would be to setup the webhook in GitHub and point it to the running\nJenkins instance.\n\n * Go to the webhooks page: \n   https://github.com/tomasbjerre/you-repo-name/settings/hooks/ * Set the Content type  to application/json\n    * Set the Payload URL  to \n      http://JENKINS_URL/generic-webhook-trigger/invoke?token=abc123\n   \n   \n\nNext step, create a job in Jenkins and configure Generic Webhook Trigger\n[https://plugins.jenkins.io/generic-webhook-trigger]. It supports Multibranch\npipelines but I usually just create pipeline jobs using Job DSL Plugin\n[https://github.com/jenkinsci/job-dsl-plugin/wiki]. That is a bit off topic and\ncovered in the documentation in GitHub.\n\n * Go to you Jenkins instance: http://localhost:8080/jenkins/\n * Create a new job, perhaps Pipeline or Free Style.\n * A new Trigger will appear, once Generic Webhook Trigger\n   [https://plugins.jenkins.io/generic-webhook-trigger]  is installed, named \"\n   Generic Webhook Trigger\". I'm adding variable named changed_files  with\n   expression $.commits[*].['modified','added','removed'][*].\n   You will probably want more variables here. Perhaps $.ref  to get the branch\n   name or $.after  to get the commit that the ref points at after the change.\n * Configure a token, this is how the invoker will know which job to trigger. If\n   a job has a token configured then that token has to be supplied. If the job\n   has no token configured then anyone can trigger the job.\n   \n * Add a filter with text  like $changed_files  and expression  like \n   \"src/main/resources/sql/[^\"]+?\".\n   I'm only using one variable here but you can resolve more variables. Add more\n   variables to the text-field and have a more complex regular expression.\n\nThat is it. Save the job and it will trigger for changes in SQL-scripts and\nnothing else!\n\nExplaination\nSo what happens in the example above? When a commit is pushed to GitHub, it will\ninvoke the the configured URL with a webhook. In reality, there is much more  in\nthe webhook then this:\n\n{\n \"ref\": \"refs/heads/changes\",\n \"after\": \"0d1a26e67d8f5eaf1f6ba5c57fc3c7d91ac0fd1c\",\n \"commits\": [\n  {\n   \"added\": [\n    \".gitignore\"\n   ],\n   \"removed\": [\n   ],\n   \"modified\": [\n    \"README.md\",\n    \"src/main/resources/sql/some_script.sql\"\n   ]\n  }\n ],\n repository {\n  \"git_url\": \"git://github.com/baxterthehacker/public-repo.git\"\n }\n}\n\n\nThe JSONPath [https://github.com/json-path/JsonPath]  used above will resolve to\n [\".gitignore\", \"README.md\", \"src/main/resources/sql/some_script.sql\"]  and it\nwill be available in a variable $changed_files  (that can also be used later in\nthe build).\n\nThe text  field of the Optional filter  will also resolve to this, because we\nused $changed_files  in that field.\n\nThe expression  field of the Optional filter  will match \nsrc/main/resources/sql/some_script.sql  which will trigger the build. Without\nthat change, the build would not have been triggered.\n\nIf you also define variables like:\n\n * branch  with expression $.ref\n * clone_url  with expression $.repository.git_url\n\nThen you can have a shell script build step like:\n\ngit clone $clone_url\ngit checkout $branch\n...\n\n\nFurther reading\nAlways turn to the wiki for the most accurate documentation:\nhttps://plugins.jenkins.io/generic-webhook-trigger\n\nAny issues should be reported here:\nhttps://github.com/jenkinsci/generic-webhook-trigger-plugin/issues","feature_image":"/content/images/2018/04/superhero.png","featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2018-04-03T17:48:57.000Z","created_by":"1","updated_at":"2018-09-04T21:01:54.000Z","updated_by":"1","published_at":"2018-04-03T17:51:44.000Z","published_by":"1","custom_excerpt":null,"codeinjection_head":"","codeinjection_foot":"","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"custom_template":null},{"id":"5b7be89c06392206949fa8a2","uuid":"48fa21e5-97bb-4323-a45a-b32be5a634c9","title":"Yet Another Kotlin VS Java Comparison","slug":"yet-another-kotlin-vs-java-comparison","mobiledoc":"{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"card-markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"I recently started developing an application with Kotlin. I found myself constantly wondering exactly what effect the Kotlin features have on the actual compiled classes. I was able to automatically generate the answers I needed.\\n\\nFirst of all, my solution is [here on GitHub](https://github.com/tomasbjerre/yet-another-kotlin-vs-java-comparison).\\n\\nWhat I do is:\\n\\n1. Write Kotlin code\\n2. Compile the Kotlin code\\n3. De-compile the resulting classes to Java code\\n4. Gather the original Kotlin and resulting Java code\\n5. Render markdown where I present this in a nice and tidy way\\n\\nThe input is only Kotlin and the output is a report telling me what I want to know.\\n\\nFeel free to [clone the repo](https://github.com/tomasbjerre/yet-another-kotlin-vs-java-comparison) and experiment yourself. I happily accept pull requests.\"}]],\"sections\":[[10,0]]}","html":"<p>I recently started developing an application with Kotlin. I found myself constantly wondering exactly what effect the Kotlin features have on the actual compiled classes. I was able to automatically generate the answers I needed.</p>\n<p>First of all, my solution is <a href=\"https://github.com/tomasbjerre/yet-another-kotlin-vs-java-comparison\">here on GitHub</a>.</p>\n<p>What I do is:</p>\n<ol>\n<li>Write Kotlin code</li>\n<li>Compile the Kotlin code</li>\n<li>De-compile the resulting classes to Java code</li>\n<li>Gather the original Kotlin and resulting Java code</li>\n<li>Render markdown where I present this in a nice and tidy way</li>\n</ol>\n<p>The input is only Kotlin and the output is a report telling me what I want to know.</p>\n<p>Feel free to <a href=\"https://github.com/tomasbjerre/yet-another-kotlin-vs-java-comparison\">clone the repo</a> and experiment yourself. I happily accept pull requests.</p>\n","comment_id":"5b7be89c06392206949fa8a2","plaintext":"I recently started developing an application with Kotlin. I found myself\nconstantly wondering exactly what effect the Kotlin features have on the actual\ncompiled classes. I was able to automatically generate the answers I needed.\n\nFirst of all, my solution is here on GitHub\n[https://github.com/tomasbjerre/yet-another-kotlin-vs-java-comparison].\n\nWhat I do is:\n\n 1. Write Kotlin code\n 2. Compile the Kotlin code\n 3. De-compile the resulting classes to Java code\n 4. Gather the original Kotlin and resulting Java code\n 5. Render markdown where I present this in a nice and tidy way\n\nThe input is only Kotlin and the output is a report telling me what I want to\nknow.\n\nFeel free to clone the repo\n[https://github.com/tomasbjerre/yet-another-kotlin-vs-java-comparison]  and\nexperiment yourself. I happily accept pull requests.","feature_image":"/content/images/2018/08/kotlin_250x250.png","featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2018-08-21T10:25:32.000Z","created_by":"1","updated_at":"2018-08-21T10:38:20.000Z","updated_by":"1","published_at":"2018-08-21T10:36:07.000Z","published_by":"1","custom_excerpt":null,"codeinjection_head":"","codeinjection_foot":"","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"custom_template":null},{"id":"5b858416d1c4a4085e025db0","uuid":"a85ee22c-0147-4421-972f-bb075205b68e","title":"Moving to IntelliJ IDEA from Eclipse","slug":"moving-to-intellij-idea-from-eclipse","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"/content/images/2018/08/intellij-settings.png\",\"caption\":\"<a>git@github.com</a>:tomasbjerre/intelij-settings.git\"}],[\"image\",{\"src\":\"/content/images/2018/08/intellij-maven-download-sources.png\",\"caption\":\"Intellij - Download sources and documentation\"}],[\"image\",{\"src\":\"/content/images/2018/08/intellij-optimize-imports-1.png\",\"caption\":\"Intellij - Optimize imports on the fly\"}],[\"image\",{\"src\":\"/content/images/2018/08/intellij-imports.png\",\"caption\":\"IntelliJ - Settings search\"}],[\"image\",{\"src\":\"/content/images/2018/08/intellij-imports-folder.png\",\"caption\":\"IntelliJ - Batch optimize imports\"}]],\"markups\":[[\"strong\"],[\"a\",[\"href\",\"https://www.eclipse.org/downloads/\"]],[\"a\",[\"href\",\"https://github.com/eclipse\"]],[\"a\",[\"href\",\"https://www.jetbrains.com/idea/download/\"]],[\"a\",[\"href\",\"https://github.com/JetBrains/intellij-community\"]],[\"em\"],[\"a\",[\"href\",\"https://github.com/tomasbjerre/intelij-settings\"]],[\"a\",[\"href\",\"https://bjurr.com/java-code-formatting-with-google-java-format/\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Being a long time \"],[0,[0],1,\"Eclipse\"],[0,[],0,\" user I recently started using \"],[0,[0],1,\"IntelliJ\"],[0,[],0,\". Here are some notes on how I use it for Java and Kotlin. I will probably update this post continuously.\"]]],[1,\"h1\",[[0,[],0,\"Comparison\"]]],[1,\"p\",[[0,[],0,\"Here are some of the topics that I thought were most interesting when doing the switch.\"]]],[1,\"h2\",[[0,[],0,\"Free and Open Source\"]]],[1,\"p\",[[0,[],0,\"I don't want to depend on software that is not free and open source. That, to me, feels like a trap and something I want to avoid. \"]]],[1,\"p\",[[0,[0],1,\"Eclipse\"],[0,[],0,\" is \"],[0,[1],1,\"free\"],[0,[],0,\" and \"],[0,[2],1,\"open source\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[0],1,\"IntelliJ\"],[0,[],0,\" has a \"],[0,[3],1,\"community edition\"],[0,[],0,\" that is also free and \"],[0,[4],1,\"open source\"],[0,[],0,\". This is the one I use.\"]]],[1,\"p\",[[0,[],0,\"This is totally fine for me. \"],[0,[5],1,\"Less is more\"],[0,[],0,\"!\"]]],[1,\"h2\",[[0,[],0,\"Synchronize Settings\"]]],[1,\"p\",[[0,[],0,\"I want to automatically have my IDE setup exactly how I want it and synchronize that to all my installations. Avoiding the time consuming task of searching for settings and clicking checkboxes.\"]]],[1,\"p\",[[0,[],0,\"In\"],[0,[0],1,\" Eclipse\"],[0,[],0,\" I use Workspace Mechanics. The mechanics files are put under version control so that all developers of a project will have changes applied immediately when someone changes the settings.\"]]],[1,\"p\",[[0,[],0,\"In\"],[0,[0],1,\" IntelliJ\"],[0,[],0,\" this is built in. In the menu, \"],[0,[5],1,\"File -> Settings Repository\"],[0,[],0,\" you can add any git-repository. I just created a new \"],[0,[6],1,\"repository on GitHub\"],[0,[],0,\" and is now using that clone URL. To publish settings you do \"],[0,[5],1,\"File -> Settings Repository\"],[0,[],0,\" and click \"],[0,[5],1,\"Merge\"],[0,[],0,\".\"]]],[10,0],[1,\"p\",[[0,[],0,\"I have seen that some settings are not synchronized when using \"],[0,[0],1,\"IntelliJ\"],[0,[],0,\". I really miss is \"],[0,[5],1,\"automatically download sources\"],[0,[],0,\" and \"],[0,[5],1,\"documentation\"],[0,[],0,\" and most annoyingly is the option to \"],[0,[5],1,\"optimize imports on the fly\"],[0,[],0,\".\"]]],[10,1],[10,2],[1,\"h2\",[[0,[],0,\"Opening Several Projects In Same Window\"]]],[1,\"p\",[[0,[],0,\"In \"],[0,[0],1,\"Eclipse\"],[0,[],0,\" you would create a workspace and import projects in that workspace.\"]]],[1,\"p\",[[0,[],0,\"In \"],[0,[0],1,\"IntelliJ\"],[0,[],0,\" you create a project and add modules to it. A module can be a Maven, or Gradle, project. You do:\"]]],[3,\"ul\",[[[0,[5],1,\"File -> New -> Project ...\"]],[[0,[5],1,\"Empty project\"]],[[0,[],0,\"Name it anything you like\"]],[[0,[],0,\"Finnish\"]]]],[1,\"p\",[[0,[],0,\"Now to add a Gradle project to it, you do:\"]]],[3,\"ul\",[[[0,[],0,\"File -> New -> Module From Existing Sources...\"]],[[0,[],0,\"Select the \"],[0,[5],1,\"build.gradle\"],[0,[],0,\" file. If it were Maven you would select the \"],[0,[5],1,\"pom.xml\"],[0,[],0,\" file\"]]]],[1,\"h2\",[[0,[],0,\"Maintaining a Code Standard\"]]],[1,\"p\",[[0,[],0,\"In\"],[0,[0],1,\" Eclipse\"],[0,[],0,\" you can setup save actions that will apply the code standard whenever a file is saved.\"]]],[1,\"p\",[[0,[],0,\"In\"],[0,[0],1,\" IntelliJ\"],[0,[],0,\" I have not found any way of enforcing a code standard. It does a good job on understanding and adhering to how the current file already is formatted.\"]]],[1,\"h2\",[[0,[],0,\"Automatically Boost Code Quality\"]]],[1,\"p\",[[0,[],0,\"In \"],[0,[0],1,\"Eclipse\"],[0,[],0,\" I would setup save actions to automatically do things like:\"]]],[3,\"ul\",[[[0,[],0,\"Remove unused variables\"]],[[0,[],0,\"Organize imports, sorting and removing unused imports\"]],[[0,[],0,\"Adding final keyword to immutable attributes and variables\"]],[[0,[],0,\"Remove trailing white space\"]]]],[1,\"p\",[[0,[],0,\"In \"],[0,[0],1,\"IntelliJ\"],[0,[],0,\" you can find these settings by simply searching in the settings menu (\"],[0,[5],1,\"File -> Settings\"],[0,[],0,\").\"]]],[10,3],[1,\"p\",[[0,[],0,\"This will organize the imports when you are working with a file. You can also batch this by marking a folder in the menu and press \"],[0,[0],1,\"CTRL-ALT-O\"],[0,[],0,\".\"]]],[10,4],[1,\"h1\",[[0,[],0,\"Conclusions\"]]],[1,\"p\",[[0,[],0,\"I am missing some features in \"],[0,[0],1,\"IntelliJ\"],[0,[],0,\" regarding automatically correcting things in the code. But that is easily solved with Maven or Gradle. I wrote about that \"],[0,[7],1,\"here\"],[0,[],0,\".\"]]]]}","html":"<p>Being a long time <strong>Eclipse</strong> user I recently started using <strong>IntelliJ</strong>. Here are some notes on how I use it for Java and Kotlin. I will probably update this post continuously.</p><h1 id=\"comparison\">Comparison</h1><p>Here are some of the topics that I thought were most interesting when doing the switch.</p><h2 id=\"free-and-open-source\">Free and Open Source</h2><p>I don't want to depend on software that is not free and open source. That, to me, feels like a trap and something I want to avoid. </p><p><strong>Eclipse</strong> is <a href=\"https://www.eclipse.org/downloads/\">free</a> and <a href=\"https://github.com/eclipse\">open source</a>.</p><p><strong>IntelliJ</strong> has a <a href=\"https://www.jetbrains.com/idea/download/\">community edition</a> that is also free and <a href=\"https://github.com/JetBrains/intellij-community\">open source</a>. This is the one I use.</p><p>This is totally fine for me. <em>Less is more</em>!</p><h2 id=\"synchronize-settings\">Synchronize Settings</h2><p>I want to automatically have my IDE setup exactly how I want it and synchronize that to all my installations. Avoiding the time consuming task of searching for settings and clicking checkboxes.</p><p>In<strong> Eclipse</strong> I use Workspace Mechanics. The mechanics files are put under version control so that all developers of a project will have changes applied immediately when someone changes the settings.</p><p>In<strong> IntelliJ</strong> this is built in. In the menu, <em>File -&gt; Settings Repository</em> you can add any git-repository. I just created a new <a href=\"https://github.com/tomasbjerre/intelij-settings\">repository on GitHub</a> and is now using that clone URL. To publish settings you do <em>File -&gt; Settings Repository</em> and click <em>Merge</em>.</p><figure class=\"kg-image-card\"><img src=\"/content/images/2018/08/intellij-settings.png\" class=\"kg-image\"><figcaption><a>git@github.com</a>:tomasbjerre/intelij-settings.git</figcaption></figure><p>I have seen that some settings are not synchronized when using <strong>IntelliJ</strong>. I really miss is <em>automatically download sources</em> and <em>documentation</em> and most annoyingly is the option to <em>optimize imports on the fly</em>.</p><figure class=\"kg-image-card\"><img src=\"/content/images/2018/08/intellij-maven-download-sources.png\" class=\"kg-image\"><figcaption>Intellij - Download sources and documentation</figcaption></figure><figure class=\"kg-image-card\"><img src=\"/content/images/2018/08/intellij-optimize-imports-1.png\" class=\"kg-image\"><figcaption>Intellij - Optimize imports on the fly</figcaption></figure><h2 id=\"opening-several-projects-in-same-window\">Opening Several Projects In Same Window</h2><p>In <strong>Eclipse</strong> you would create a workspace and import projects in that workspace.</p><p>In <strong>IntelliJ</strong> you create a project and add modules to it. A module can be a Maven, or Gradle, project. You do:</p><ul><li><em>File -&gt; New -&gt; Project ...</em></li><li><em>Empty project</em></li><li>Name it anything you like</li><li>Finnish</li></ul><p>Now to add a Gradle project to it, you do:</p><ul><li>File -&gt; New -&gt; Module From Existing Sources...</li><li>Select the <em>build.gradle</em> file. If it were Maven you would select the <em>pom.xml</em> file</li></ul><h2 id=\"maintaining-a-code-standard\">Maintaining a Code Standard</h2><p>In<strong> Eclipse</strong> you can setup save actions that will apply the code standard whenever a file is saved.</p><p>In<strong> IntelliJ</strong> I have not found any way of enforcing a code standard. It does a good job on understanding and adhering to how the current file already is formatted.</p><h2 id=\"automatically-boost-code-quality\">Automatically Boost Code Quality</h2><p>In <strong>Eclipse</strong> I would setup save actions to automatically do things like:</p><ul><li>Remove unused variables</li><li>Organize imports, sorting and removing unused imports</li><li>Adding final keyword to immutable attributes and variables</li><li>Remove trailing white space</li></ul><p>In <strong>IntelliJ</strong> you can find these settings by simply searching in the settings menu (<em>File -&gt; Settings</em>).</p><figure class=\"kg-image-card\"><img src=\"/content/images/2018/08/intellij-imports.png\" class=\"kg-image\"><figcaption>IntelliJ - Settings search</figcaption></figure><p>This will organize the imports when you are working with a file. You can also batch this by marking a folder in the menu and press <strong>CTRL-ALT-O</strong>.</p><figure class=\"kg-image-card\"><img src=\"/content/images/2018/08/intellij-imports-folder.png\" class=\"kg-image\"><figcaption>IntelliJ - Batch optimize imports</figcaption></figure><h1 id=\"conclusions\">Conclusions</h1><p>I am missing some features in <strong>IntelliJ</strong> regarding automatically correcting things in the code. But that is easily solved with Maven or Gradle. I wrote about that <a href=\"https://bjurr.com/java-code-formatting-with-google-java-format/\">here</a>.</p>","comment_id":"5b858416d1c4a4085e025db0","plaintext":"Being a long time Eclipse  user I recently started using IntelliJ. Here are some\nnotes on how I use it for Java and Kotlin. I will probably update this post\ncontinuously.\n\nComparison\nHere are some of the topics that I thought were most interesting when doing the\nswitch.\n\nFree and Open Source\nI don't want to depend on software that is not free and open source. That, to\nme, feels like a trap and something I want to avoid. \n\nEclipse  is free [https://www.eclipse.org/downloads/]  and open source\n[https://github.com/eclipse].\n\nIntelliJ  has a community edition [https://www.jetbrains.com/idea/download/] \nthat is also free and open source\n[https://github.com/JetBrains/intellij-community]. This is the one I use.\n\nThis is totally fine for me. Less is more!\n\nSynchronize Settings\nI want to automatically have my IDE setup exactly how I want it and synchronize\nthat to all my installations. Avoiding the time consuming task of searching for\nsettings and clicking checkboxes.\n\nIn  Eclipse  I use Workspace Mechanics. The mechanics files are put under\nversion control so that all developers of a project will have changes applied\nimmediately when someone changes the settings.\n\nIn  IntelliJ  this is built in. In the menu, File -> Settings Repository  you\ncan add any git-repository. I just created a new repository on GitHub\n[https://github.com/tomasbjerre/intelij-settings]  and is now using that clone\nURL. To publish settings you do File -> Settings Repository  and click Merge.\n\ngit@github.com:tomasbjerre/intelij-settings.gitI have seen that some settings\nare not synchronized when using IntelliJ. I really miss is automatically\ndownload sources  and documentation  and most annoyingly is the option to \noptimize imports on the fly.\n\nIntellij - Download sources and documentationIntellij - Optimize imports on the\nflyOpening Several Projects In Same Window\nIn Eclipse  you would create a workspace and import projects in that workspace.\n\nIn IntelliJ  you create a project and add modules to it. A module can be a\nMaven, or Gradle, project. You do:\n\n * File -> New -> Project ...\n * Empty project\n * Name it anything you like\n * Finnish\n\nNow to add a Gradle project to it, you do:\n\n * File -> New -> Module From Existing Sources...\n * Select the build.gradle  file. If it were Maven you would select the pom.xml \n   file\n\nMaintaining a Code Standard\nIn  Eclipse  you can setup save actions that will apply the code standard\nwhenever a file is saved.\n\nIn  IntelliJ  I have not found any way of enforcing a code standard. It does a\ngood job on understanding and adhering to how the current file already is\nformatted.\n\nAutomatically Boost Code Quality\nIn Eclipse  I would setup save actions to automatically do things like:\n\n * Remove unused variables\n * Organize imports, sorting and removing unused imports\n * Adding final keyword to immutable attributes and variables\n * Remove trailing white space\n\nIn IntelliJ  you can find these settings by simply searching in the settings\nmenu (File -> Settings).\n\nIntelliJ - Settings searchThis will organize the imports when you are working\nwith a file. You can also batch this by marking a folder in the menu and press \nCTRL-ALT-O.\n\nIntelliJ - Batch optimize importsConclusions\nI am missing some features in IntelliJ  regarding automatically correcting\nthings in the code. But that is easily solved with Maven or Gradle. I wrote\nabout that here\n[https://bjurr.com/java-code-formatting-with-google-java-format/].","feature_image":"/content/images/2018/08/intellij.jpeg","featured":0,"page":0,"status":"published","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"author_id":"1","created_at":"2018-08-28T17:19:18.000Z","created_by":"1","updated_at":"2018-08-30T18:48:40.000Z","updated_by":"1","published_at":"2018-08-28T17:40:40.000Z","published_by":"1","custom_excerpt":null,"codeinjection_head":"","codeinjection_foot":"","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"custom_template":null}],"posts_authors":[{"id":"5b1ad9f6c706ac1a0fe204f0","post_id":"597b4433e521cb4fbd91868f","author_id":"1","sort_order":0},{"id":"5b1ad9f6c706ac1a0fe204f1","post_id":"597b4433e521cb4fbd918692","author_id":"1","sort_order":0},{"id":"5b1ad9f6c706ac1a0fe204f2","post_id":"597b4433e521cb4fbd918693","author_id":"1","sort_order":0},{"id":"5b1ad9f6c706ac1a0fe204f3","post_id":"597b4433e521cb4fbd918694","author_id":"1","sort_order":0},{"id":"5b1ad9f6c706ac1a0fe204f4","post_id":"597b4433e521cb4fbd918696","author_id":"1","sort_order":0},{"id":"5b1ad9f6c706ac1a0fe204f5","post_id":"597b4433e521cb4fbd918697","author_id":"1","sort_order":0},{"id":"5b1ad9f6c706ac1a0fe204f6","post_id":"597b4433e521cb4fbd918698","author_id":"1","sort_order":0},{"id":"5b1ad9f6c706ac1a0fe204f7","post_id":"597b4433e521cb4fbd918699","author_id":"1","sort_order":0},{"id":"5b1ad9f6c706ac1a0fe204f8","post_id":"597b4433e521cb4fbd91869b","author_id":"1","sort_order":0},{"id":"5b1ad9f6c706ac1a0fe204f9","post_id":"597b4433e521cb4fbd91869c","author_id":"1","sort_order":0},{"id":"5b1ad9f6c706ac1a0fe204fa","post_id":"597b4433e521cb4fbd91869e","author_id":"1","sort_order":0},{"id":"5b1ad9f6c706ac1a0fe204fb","post_id":"597b4433e521cb4fbd91869f","author_id":"1","sort_order":0},{"id":"5b1ad9f6c706ac1a0fe204fc","post_id":"597b4433e521cb4fbd9186a0","author_id":"1","sort_order":0},{"id":"5b1ad9f6c706ac1a0fe204fd","post_id":"597b4433e521cb4fbd9186a1","author_id":"1","sort_order":0},{"id":"5b1ad9f6c706ac1a0fe204fe","post_id":"597b4433e521cb4fbd9186a2","author_id":"1","sort_order":0},{"id":"5b1ad9f6c706ac1a0fe204ff","post_id":"597b4433e521cb4fbd9186a3","author_id":"1","sort_order":0},{"id":"5b1ad9f6c706ac1a0fe20500","post_id":"597b4433e521cb4fbd9186a4","author_id":"1","sort_order":0},{"id":"5b1ad9f6c706ac1a0fe20501","post_id":"597b4433e521cb4fbd9186a5","author_id":"1","sort_order":0},{"id":"5b1ad9f6c706ac1a0fe20502","post_id":"597b4433e521cb4fbd9186a6","author_id":"1","sort_order":0},{"id":"5b1ad9f6c706ac1a0fe20503","post_id":"597b4433e521cb4fbd9186a7","author_id":"1","sort_order":0},{"id":"5b1ad9f6c706ac1a0fe20504","post_id":"597b4433e521cb4fbd9186a8","author_id":"1","sort_order":0},{"id":"5b1ad9f6c706ac1a0fe20505","post_id":"597b64dc08a2db60d1f648ba","author_id":"1","sort_order":0},{"id":"5b1ad9f6c706ac1a0fe20506","post_id":"59e067ad8edbbd05ee0cef90","author_id":"1","sort_order":0},{"id":"5b1ad9f6c706ac1a0fe20507","post_id":"5a23da214b28b905d8304a37","author_id":"1","sort_order":0},{"id":"5b1ad9f6c706ac1a0fe20508","post_id":"5a755597c56a61057b219788","author_id":"1","sort_order":0},{"id":"5b1ad9f6c706ac1a0fe20509","post_id":"5ac3be89b907cf054a31895e","author_id":"1","sort_order":0},{"id":"5b7be89c06392206949fa8a3","post_id":"5b7be89c06392206949fa8a2","author_id":"1","sort_order":0},{"id":"5b858416d1c4a4085e025db1","post_id":"5b858416d1c4a4085e025db0","author_id":"1","sort_order":0}],"posts_tags":[{"id":"597b4433e521cb4fbd9186a9","post_id":"597b4433e521cb4fbd91868f","tag_id":"597b4432e521cb4fbd918664","sort_order":0},{"id":"597b4433e521cb4fbd9186ac","post_id":"597b4433e521cb4fbd918692","tag_id":"597b4433e521cb4fbd91866f","sort_order":0},{"id":"597b4433e521cb4fbd9186ad","post_id":"597b4433e521cb4fbd918693","tag_id":"597b4433e521cb4fbd91866f","sort_order":0},{"id":"597b4433e521cb4fbd9186ae","post_id":"597b4433e521cb4fbd918694","tag_id":"597b4433e521cb4fbd91866f","sort_order":0},{"id":"597b4433e521cb4fbd9186b0","post_id":"597b4433e521cb4fbd918696","tag_id":"597b4432e521cb4fbd91866a","sort_order":0},{"id":"597b4433e521cb4fbd9186b1","post_id":"597b4433e521cb4fbd918697","tag_id":"597b4432e521cb4fbd918669","sort_order":0},{"id":"597b4433e521cb4fbd9186b2","post_id":"597b4433e521cb4fbd918698","tag_id":"597b4433e521cb4fbd91866e","sort_order":0},{"id":"597b4433e521cb4fbd9186b3","post_id":"597b4433e521cb4fbd918699","tag_id":"597b4433e521cb4fbd91866e","sort_order":0},{"id":"597b4433e521cb4fbd9186b5","post_id":"597b4433e521cb4fbd91869e","tag_id":"597b4433e521cb4fbd918680","sort_order":0},{"id":"597b4433e521cb4fbd9186b6","post_id":"597b4433e521cb4fbd91869f","tag_id":"597b4433e521cb4fbd918683","sort_order":0},{"id":"597b4433e521cb4fbd9186b7","post_id":"597b4433e521cb4fbd9186a0","tag_id":"597b4433e521cb4fbd918686","sort_order":0},{"id":"597b4433e521cb4fbd9186b8","post_id":"597b4433e521cb4fbd9186a1","tag_id":"597b4433e521cb4fbd918681","sort_order":0},{"id":"597b4433e521cb4fbd9186b9","post_id":"597b4433e521cb4fbd9186a2","tag_id":"597b4433e521cb4fbd918688","sort_order":0},{"id":"597b4433e521cb4fbd9186ba","post_id":"597b4433e521cb4fbd9186a3","tag_id":"597b4433e521cb4fbd91866f","sort_order":0},{"id":"597b4433e521cb4fbd9186bb","post_id":"597b4433e521cb4fbd9186a4","tag_id":"597b4433e521cb4fbd918680","sort_order":0},{"id":"597b4433e521cb4fbd9186bc","post_id":"597b4433e521cb4fbd9186a8","tag_id":"597b4433e521cb4fbd918676","sort_order":0},{"id":"597b4433e521cb4fbd9186bd","post_id":"597b4433e521cb4fbd91868f","tag_id":"597b4432e521cb4fbd918665","sort_order":1},{"id":"597b4433e521cb4fbd9186bf","post_id":"597b4433e521cb4fbd918694","tag_id":"597b4433e521cb4fbd918671","sort_order":1},{"id":"597b4433e521cb4fbd9186c1","post_id":"597b4433e521cb4fbd918696","tag_id":"597b4433e521cb4fbd91866c","sort_order":1},{"id":"597b4433e521cb4fbd9186c2","post_id":"597b4433e521cb4fbd918697","tag_id":"597b4433e521cb4fbd91866e","sort_order":1},{"id":"597b4433e521cb4fbd9186c3","post_id":"597b4433e521cb4fbd918698","tag_id":"597b4433e521cb4fbd918675","sort_order":1},{"id":"597b4433e521cb4fbd9186c5","post_id":"597b4433e521cb4fbd91869e","tag_id":"597b4433e521cb4fbd918681","sort_order":1},{"id":"597b4433e521cb4fbd9186c6","post_id":"597b4433e521cb4fbd91869f","tag_id":"597b4433e521cb4fbd918689","sort_order":1},{"id":"597b4433e521cb4fbd9186c7","post_id":"597b4433e521cb4fbd9186a0","tag_id":"597b4432e521cb4fbd918664","sort_order":1},{"id":"597b4433e521cb4fbd9186c8","post_id":"597b4433e521cb4fbd9186a1","tag_id":"597b4433e521cb4fbd918680","sort_order":1},{"id":"597b4433e521cb4fbd9186c9","post_id":"597b4433e521cb4fbd9186a2","tag_id":"597b4433e521cb4fbd918686","sort_order":1},{"id":"597b4433e521cb4fbd9186ca","post_id":"597b4433e521cb4fbd9186a3","tag_id":"597b4433e521cb4fbd91868a","sort_order":1},{"id":"597b4433e521cb4fbd9186cb","post_id":"597b4433e521cb4fbd9186a4","tag_id":"597b4433e521cb4fbd918686","sort_order":1},{"id":"597b4433e521cb4fbd9186cc","post_id":"597b4433e521cb4fbd9186a8","tag_id":"597b4433e521cb4fbd91868c","sort_order":1},{"id":"597b4434e521cb4fbd9186cd","post_id":"597b4433e521cb4fbd91868f","tag_id":"597b4432e521cb4fbd918666","sort_order":2},{"id":"597b4434e521cb4fbd9186cf","post_id":"597b4433e521cb4fbd918694","tag_id":"597b4433e521cb4fbd91867c","sort_order":2},{"id":"597b4434e521cb4fbd9186d0","post_id":"597b4433e521cb4fbd918696","tag_id":"597b4433e521cb4fbd91866d","sort_order":2},{"id":"597b4434e521cb4fbd9186d1","post_id":"597b4433e521cb4fbd918697","tag_id":"597b4433e521cb4fbd918672","sort_order":2},{"id":"597b4434e521cb4fbd9186d3","post_id":"597b4433e521cb4fbd91869e","tag_id":"597b4433e521cb4fbd918682","sort_order":2},{"id":"597b4434e521cb4fbd9186d4","post_id":"597b4433e521cb4fbd9186a1","tag_id":"597b4433e521cb4fbd918683","sort_order":2},{"id":"597b4434e521cb4fbd9186d5","post_id":"597b4433e521cb4fbd9186a2","tag_id":"597b4433e521cb4fbd91868a","sort_order":2},{"id":"597b4434e521cb4fbd9186d6","post_id":"597b4433e521cb4fbd9186a4","tag_id":"597b4433e521cb4fbd918687","sort_order":2},{"id":"597b4434e521cb4fbd9186d7","post_id":"597b4433e521cb4fbd9186a8","tag_id":"597b4433e521cb4fbd91868d","sort_order":2},{"id":"597b4434e521cb4fbd9186d8","post_id":"597b4433e521cb4fbd91868f","tag_id":"597b4432e521cb4fbd918667","sort_order":3},{"id":"597b4434e521cb4fbd9186da","post_id":"597b4433e521cb4fbd918696","tag_id":"597b4433e521cb4fbd91867f","sort_order":3},{"id":"597b4434e521cb4fbd9186dc","post_id":"597b4433e521cb4fbd91869e","tag_id":"597b4433e521cb4fbd918683","sort_order":3},{"id":"597b4434e521cb4fbd9186dd","post_id":"597b4433e521cb4fbd9186a1","tag_id":"597b4433e521cb4fbd918685","sort_order":3},{"id":"597b4434e521cb4fbd9186de","post_id":"597b4433e521cb4fbd9186a2","tag_id":"597b4433e521cb4fbd91868b","sort_order":3},{"id":"597b4434e521cb4fbd9186df","post_id":"597b4433e521cb4fbd9186a4","tag_id":"597b4433e521cb4fbd918688","sort_order":3},{"id":"597b4434e521cb4fbd9186e0","post_id":"597b4433e521cb4fbd91868f","tag_id":"597b4432e521cb4fbd91866b","sort_order":4},{"id":"597b4434e521cb4fbd9186e2","post_id":"597b4433e521cb4fbd91869e","tag_id":"597b4433e521cb4fbd918684","sort_order":4},{"id":"597b4434e521cb4fbd9186e3","post_id":"597b4433e521cb4fbd9186a1","tag_id":"597b4433e521cb4fbd918687","sort_order":4},{"id":"597b4434e521cb4fbd9186e4","post_id":"597b4433e521cb4fbd9186a2","tag_id":"597b4433e521cb4fbd918680","sort_order":4},{"id":"597b4434e521cb4fbd9186e5","post_id":"597b4433e521cb4fbd9186a4","tag_id":"597b4433e521cb4fbd918681","sort_order":4},{"id":"597b4434e521cb4fbd9186e6","post_id":"597b4433e521cb4fbd9186a4","tag_id":"597b4433e521cb4fbd918689","sort_order":5},{"id":"597b696908a2db60d1f648bb","post_id":"597b64dc08a2db60d1f648ba","tag_id":"597b4432e521cb4fbd918664","sort_order":0},{"id":"597b696908a2db60d1f648bc","post_id":"597b64dc08a2db60d1f648ba","tag_id":"597b4432e521cb4fbd918665","sort_order":1},{"id":"597b696908a2db60d1f648be","post_id":"597b64dc08a2db60d1f648ba","tag_id":"597b696908a2db60d1f648bd","sort_order":2},{"id":"597b696908a2db60d1f648c0","post_id":"597b64dc08a2db60d1f648ba","tag_id":"597b696908a2db60d1f648bf","sort_order":3},{"id":"59e06c588edbbd05ee0cef92","post_id":"59e067ad8edbbd05ee0cef90","tag_id":"59e06c588edbbd05ee0cef91","sort_order":0},{"id":"59e06c588edbbd05ee0cef93","post_id":"59e067ad8edbbd05ee0cef90","tag_id":"597b4433e521cb4fbd918680","sort_order":1},{"id":"59e06c588edbbd05ee0cef95","post_id":"59e067ad8edbbd05ee0cef90","tag_id":"59e06c588edbbd05ee0cef94","sort_order":2},{"id":"5a3a309178ae32059caf0fc7","post_id":"5a23da214b28b905d8304a37","tag_id":"5a3a309178ae32059caf0fc6","sort_order":0},{"id":"5a3a309178ae32059caf0fc9","post_id":"5a23da214b28b905d8304a37","tag_id":"597b4433e521cb4fbd91866f","sort_order":1},{"id":"5a7557efc56a61057b21978b","post_id":"5a755597c56a61057b219788","tag_id":"597b4433e521cb4fbd918680","sort_order":0},{"id":"5a7557efc56a61057b21978d","post_id":"5a755597c56a61057b219788","tag_id":"5a7557efc56a61057b219789","sort_order":1},{"id":"5a7557efc56a61057b219790","post_id":"5a755597c56a61057b219788","tag_id":"5a7557efc56a61057b21978a","sort_order":2},{"id":"5a7557efc56a61057b219794","post_id":"5a755597c56a61057b219788","tag_id":"597b4433e521cb4fbd918681","sort_order":3},{"id":"5a912890c4446d055b89f2ec","post_id":"597b4433e521cb4fbd9186a7","tag_id":"597b4433e521cb4fbd91866f","sort_order":0},{"id":"5a912890c4446d055b89f2ee","post_id":"597b4433e521cb4fbd9186a7","tag_id":"5a7557efc56a61057b21978a","sort_order":1},{"id":"5a912890c4446d055b89f2f1","post_id":"597b4433e521cb4fbd9186a7","tag_id":"5a912890c4446d055b89f2eb","sort_order":2},{"id":"5a912890c4446d055b89f2f5","post_id":"597b4433e521cb4fbd9186a7","tag_id":"59e06c588edbbd05ee0cef94","sort_order":3},{"id":"5a912890c4446d055b89f2fa","post_id":"597b4433e521cb4fbd9186a7","tag_id":"5a3a309178ae32059caf0fc6","sort_order":4},{"id":"5a9128efc4446d055b89f2fc","post_id":"597b4433e521cb4fbd9186a6","tag_id":"5a9128efc4446d055b89f2fb","sort_order":0},{"id":"5a9128efc4446d055b89f2fe","post_id":"597b4433e521cb4fbd9186a6","tag_id":"597b4433e521cb4fbd918680","sort_order":1},{"id":"5a9128efc4446d055b89f301","post_id":"597b4433e521cb4fbd9186a6","tag_id":"5a7557efc56a61057b21978a","sort_order":2},{"id":"5a9128efc4446d055b89f305","post_id":"597b4433e521cb4fbd9186a6","tag_id":"597b4433e521cb4fbd918681","sort_order":3},{"id":"5a912b36c4446d055b89f306","post_id":"597b4433e521cb4fbd9186a5","tag_id":"597b4433e521cb4fbd918681","sort_order":0},{"id":"5a912b89c4446d055b89f307","post_id":"597b4433e521cb4fbd9186a4","tag_id":"5a7557efc56a61057b21978a","sort_order":6},{"id":"5a912c07c4446d055b89f308","post_id":"597b4433e521cb4fbd9186a2","tag_id":"5a7557efc56a61057b21978a","sort_order":5},{"id":"5a912c5ac4446d055b89f309","post_id":"597b4433e521cb4fbd9186a1","tag_id":"5a7557efc56a61057b21978a","sort_order":5},{"id":"5a912c88c4446d055b89f30b","post_id":"597b4433e521cb4fbd91869f","tag_id":"5a912c88c4446d055b89f30a","sort_order":2},{"id":"5a912c88c4446d055b89f30d","post_id":"597b4433e521cb4fbd91869f","tag_id":"5a7557efc56a61057b21978a","sort_order":3},{"id":"5a912c88c4446d055b89f310","post_id":"597b4433e521cb4fbd91869f","tag_id":"597b4433e521cb4fbd918681","sort_order":4},{"id":"5ac3bf30b907cf054a31895f","post_id":"5ac3be89b907cf054a31895e","tag_id":"597b4433e521cb4fbd918680","sort_order":0},{"id":"5ac3bf30b907cf054a318960","post_id":"5ac3be89b907cf054a31895e","tag_id":"5a7557efc56a61057b219789","sort_order":1},{"id":"5ac3bf30b907cf054a318961","post_id":"5ac3be89b907cf054a31895e","tag_id":"5a7557efc56a61057b21978a","sort_order":2},{"id":"5ac3bf30b907cf054a318962","post_id":"5ac3be89b907cf054a31895e","tag_id":"597b4433e521cb4fbd918681","sort_order":3},{"id":"5ac3bf30b907cf054a318963","post_id":"5ac3be89b907cf054a31895e","tag_id":"5a912890c4446d055b89f2eb","sort_order":4},{"id":"5ac3bf30b907cf054a318964","post_id":"5ac3be89b907cf054a31895e","tag_id":"5a9128efc4446d055b89f2fb","sort_order":5},{"id":"5ac3bf30b907cf054a318965","post_id":"5ac3be89b907cf054a31895e","tag_id":"597b4433e521cb4fbd918686","sort_order":6},{"id":"5ac3bf30b907cf054a318966","post_id":"5ac3be89b907cf054a31895e","tag_id":"597b4433e521cb4fbd918687","sort_order":7},{"id":"5ac3bf30b907cf054a318967","post_id":"5ac3be89b907cf054a31895e","tag_id":"597b4433e521cb4fbd918683","sort_order":8},{"id":"5b7beb9c06392206949fa8a5","post_id":"5b7be89c06392206949fa8a2","tag_id":"5b7beb9c06392206949fa8a4","sort_order":0},{"id":"5b7beb9c06392206949fa8a6","post_id":"5b7be89c06392206949fa8a2","tag_id":"597b4433e521cb4fbd91866f","sort_order":1},{"id":"5b858918d1c4a4085e025db5","post_id":"5b858416d1c4a4085e025db0","tag_id":"5b858918d1c4a4085e025db2","sort_order":0},{"id":"5b858918d1c4a4085e025db6","post_id":"5b858416d1c4a4085e025db0","tag_id":"597b4433e521cb4fbd91866f","sort_order":1},{"id":"5b858918d1c4a4085e025db7","post_id":"5b858416d1c4a4085e025db0","tag_id":"5b858918d1c4a4085e025db3","sort_order":2},{"id":"5b858918d1c4a4085e025db8","post_id":"5b858416d1c4a4085e025db0","tag_id":"5b858918d1c4a4085e025db4","sort_order":3}],"roles":[{"id":"597b43301ffc934f6c0277bc","name":"Administrator","description":"Administrators","created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277bd","name":"Editor","description":"Editors","created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277be","name":"Author","description":"Authors","created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"597b43301ffc934f6c0277bf","name":"Owner","description":"Blog Owner","created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"},{"id":"5a9845ce6b6eb71021b13f88","name":"Contributor","description":"Contributors","created_at":"2018-03-01T18:26:22.000Z","created_by":"1","updated_at":"2018-03-01T18:26:22.000Z","updated_by":"1"}],"roles_users":[{"id":"597b43311ffc934f6c0277f1","role_id":"597b43301ffc934f6c0277be","user_id":"5951f5fca366002ebd5dbef7"},{"id":"597b43311ffc934f6c02785b","role_id":"597b43301ffc934f6c0277bf","user_id":"1"}],"settings":[{"id":"597b4336e521cb4fbd918641","key":"db_hash","value":"f07e86ed-63bb-4c95-8c99-79ee6f39ff43","type":"core","created_at":"2017-07-28T13:59:18.000Z","created_by":"1","updated_at":"2017-07-28T13:59:18.000Z","updated_by":"1"},{"id":"597b4336e521cb4fbd918642","key":"next_update_check","value":"1540581116","type":"core","created_at":"2017-07-28T13:59:18.000Z","created_by":"1","updated_at":"2018-10-25T19:11:55.000Z","updated_by":"1"},{"id":"597b4336e521cb4fbd918645","key":"title","value":"Tomas Bjerre:s blog","type":"blog","created_at":"2014-10-04T13:54:29.000Z","created_by":"1","updated_at":"2017-07-30T06:51:18.000Z","updated_by":"1"},{"id":"597b4336e521cb4fbd918646","key":"description","value":"My blog on things I find interesting.","type":"blog","created_at":"2014-10-04T13:54:29.000Z","created_by":"1","updated_at":"2017-07-30T06:51:18.000Z","updated_by":"1"},{"id":"597b4336e521cb4fbd918647","key":"logo","value":"/content/images/2017/07/kna_crop_600.png","type":"blog","created_at":"2014-10-04T13:54:29.000Z","created_by":"1","updated_at":"2017-07-30T06:51:18.000Z","updated_by":"1"},{"id":"597b4336e521cb4fbd918648","key":"cover_image","value":"/content/images/2017/07/kna_crop.jpg","type":"blog","created_at":"2014-10-04T13:54:29.000Z","created_by":"1","updated_at":"2017-07-30T06:51:18.000Z","updated_by":"1"},{"id":"597b4336e521cb4fbd918649","key":"icon","value":"/content/images/2017/07/kna_crop_fyrt.png","type":"blog","created_at":"2017-07-28T13:59:18.000Z","created_by":"1","updated_at":"2017-07-30T06:51:18.000Z","updated_by":"1"},{"id":"597b4336e521cb4fbd91864a","key":"default_locale","value":"en","type":"blog","created_at":"2017-07-28T13:59:18.000Z","created_by":"1","updated_at":"2017-07-30T06:51:18.000Z","updated_by":"1"},{"id":"597b4336e521cb4fbd91864b","key":"active_timezone","value":"Europe/Amsterdam","type":"blog","created_at":"2016-09-10T13:47:09.000Z","created_by":"1","updated_at":"2017-07-30T06:51:18.000Z","updated_by":"1"},{"id":"597b4336e521cb4fbd91864c","key":"force_i18n","value":"true","type":"blog","created_at":"2017-07-28T13:59:18.000Z","created_by":"1","updated_at":"2017-07-30T06:51:18.000Z","updated_by":"1"},{"id":"597b4336e521cb4fbd91864e","key":"amp","value":"false","type":"blog","created_at":"2017-01-19T20:26:24.000Z","created_by":"1","updated_at":"2017-07-30T06:51:18.000Z","updated_by":"1"},{"id":"597b4336e521cb4fbd91864f","key":"ghost_head","value":"","type":"blog","created_at":"2015-10-05T19:01:28.000Z","created_by":"1","updated_at":"2017-07-30T06:51:18.000Z","updated_by":"1"},{"id":"597b4336e521cb4fbd918650","key":"ghost_foot","value":"<script>\n  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');\n\n  ga('create', 'UA-52248240-1', 'auto');\n  ga('send', 'pageview');\n\n</script>","type":"blog","created_at":"2015-10-05T19:01:28.000Z","created_by":"1","updated_at":"2017-07-30T06:51:18.000Z","updated_by":"1"},{"id":"597b4336e521cb4fbd918651","key":"facebook","value":"tomas.bjerre","type":"blog","created_at":"2016-09-10T13:47:09.000Z","created_by":"1","updated_at":"2017-07-30T06:51:18.000Z","updated_by":"1"},{"id":"597b4336e521cb4fbd918652","key":"twitter","value":"","type":"blog","created_at":"2016-09-10T13:47:09.000Z","created_by":"1","updated_at":"2017-07-30T06:51:18.000Z","updated_by":"1"},{"id":"597b4336e521cb4fbd918653","key":"labs","value":"{\"publicAPI\":true}","type":"blog","created_at":"2015-10-05T19:01:29.000Z","created_by":"1","updated_at":"2017-07-30T06:51:18.000Z","updated_by":"1"},{"id":"597b4336e521cb4fbd918654","key":"navigation","value":"[]","type":"blog","created_at":"2015-10-05T19:01:29.000Z","created_by":"1","updated_at":"2017-07-30T06:51:18.000Z","updated_by":"1"},{"id":"597b4336e521cb4fbd918655","key":"slack","value":"[{\"url\":\"\"}]","type":"blog","created_at":"2016-09-10T13:47:09.000Z","created_by":"1","updated_at":"2017-07-30T06:51:18.000Z","updated_by":"1"},{"id":"597b4336e521cb4fbd918656","key":"active_theme","value":"casper","type":"theme","created_at":"2017-07-28T13:59:18.000Z","created_by":"1","updated_at":"2017-07-28T13:59:18.000Z","updated_by":"1"},{"id":"597b4336e521cb4fbd918657","key":"active_apps","value":"[]","type":"app","created_at":"2017-07-28T13:59:18.000Z","created_by":"1","updated_at":"2017-07-28T13:59:18.000Z","updated_by":"1"},{"id":"597b4336e521cb4fbd918658","key":"installed_apps","value":"[]","type":"app","created_at":"2017-07-28T13:59:18.000Z","created_by":"1","updated_at":"2017-11-29T15:58:51.000Z","updated_by":"1"},{"id":"597b4336e521cb4fbd918659","key":"is_private","value":"false","type":"private","created_at":"2015-10-05T19:01:29.000Z","created_by":"1","updated_at":"2017-07-30T06:51:18.000Z","updated_by":"1"},{"id":"597b4336e521cb4fbd91865a","key":"password","value":"","type":"private","created_at":"2015-10-05T19:01:29.000Z","created_by":"1","updated_at":"2017-07-30T06:51:18.000Z","updated_by":"1"},{"id":"59a12a184060832d0a3ebaef","key":"unsplash","value":"","type":"blog","created_at":"2017-08-26T07:58:16.000Z","created_by":"1","updated_at":"2017-08-26T07:58:16.000Z","updated_by":"1"},{"id":"59e30f45a6f4d31287474009","key":"public_hash","value":"39254190745ce8652e6dcc96ddab1d","type":"private","created_at":"2017-10-15T07:33:25.000Z","created_by":"1","updated_at":"2017-10-15T07:33:25.000Z","updated_by":"1"},{"id":"5a9845d18441db108c7f4854","key":"notifications","value":"[{\"dismissible\":true,\"location\":\"bottom\",\"status\":\"alert\",\"id\":\"78f68f60-d612-11e8-8ba0-5d044c38da8a\",\"custom\":false,\"createdAt\":\"2018-10-22T14:52:26.000Z\",\"type\":\"info\",\"top\":false,\"message\":\"Ghost <a href=\\\"https://github.com/TryGhost/Ghost/releases\\\">2.3.0</a> has been released, <a href=\\\"https://docs.ghost.org/docs/upgrade\\\">click here</a> to upgrade.\",\"seen\":false,\"addedAt\":\"2018-10-25T19:11:56.016Z\"}]","type":"core","created_at":"2018-03-01T18:26:25.000Z","created_by":"1","updated_at":"2018-10-25T19:11:56.000Z","updated_by":"1"},{"id":"5bd215b876568b252315b9ae","key":"session_secret","value":"a6020f0afc349ed3090a5f4042d0980be486fba993a60fd95f8e7a9782578943","type":"core","created_at":"2018-10-25T19:12:56.000Z","created_by":"1","updated_at":"2018-10-25T19:12:56.000Z","updated_by":"1"}],"subscribers":[],"tags":[{"id":"597b4432e521cb4fbd918661","name":"Getting Started","slug":"getting-started","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:54:26.000Z","created_by":"1","updated_at":"2014-10-04T13:54:26.000Z","updated_by":"1"},{"id":"597b4432e521cb4fbd918662","name":"ghost","slug":"ghost-post","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2014-10-04T13:57:36.000Z","updated_by":"1"},{"id":"597b4432e521cb4fbd918663","name":"npm","slug":"npm","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2014-10-04T13:57:36.000Z","updated_by":"1"},{"id":"597b4432e521cb4fbd918664","name":"Ghost","slug":"ghost-post-2","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2018-05-18T19:09:18.000Z","updated_by":"1"},{"id":"597b4432e521cb4fbd918665","name":"Blog","slug":"blog-2","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2018-05-18T19:09:18.000Z","updated_by":"1"},{"id":"597b4432e521cb4fbd918666","name":"NodeJS","slug":"nodejs-2","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2014-10-04T13:57:36.000Z","updated_by":"1"},{"id":"597b4432e521cb4fbd918667","name":"NPM","slug":"npm-2","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2014-10-04T13:57:36.000Z","updated_by":"1"},{"id":"597b4432e521cb4fbd918668","name":"sipervisor","slug":"sipervisor","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2014-10-04T13:57:36.000Z","updated_by":"1"},{"id":"597b4432e521cb4fbd918669","name":"Linux","slug":"linux","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2017-12-20T06:23:49.000Z","updated_by":"1"},{"id":"597b4432e521cb4fbd91866a","name":"Owncloud","slug":"owncloud","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2014-10-04T13:57:36.000Z","updated_by":"1"},{"id":"597b4432e521cb4fbd91866b","name":"Supervisor","slug":"supervisor","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2014-10-04T13:57:36.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd91866c","name":"PHP","slug":"php","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2014-10-04T13:57:36.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd91866d","name":"OpenSSL","slug":"openssl","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2014-10-04T13:57:36.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd91866e","name":"Raspberry","slug":"raspberry","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2014-10-04T13:57:36.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd91866f","name":"Java","slug":"java","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2018-02-26T08:29:01.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd918670","name":"ByggarMonster","slug":"byggarmonster","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2017-12-20T06:22:41.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd918671","name":"HTMLUnitGenerator","slug":"htmlunitgenerator","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2014-10-04T13:57:36.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd918672","name":"ArchLinux","slug":"archlinux","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2014-10-04T13:57:36.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd918673","name":"Apache","slug":"apache","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2017-12-20T06:22:14.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd918674","name":"disk_cache","slug":"disk_cache","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2017-12-20T06:22:14.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd918675","name":"Surveillance","slug":"surveillance","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2014-10-04T13:57:36.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd918676","name":"Swedish","slug":"swedish","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2018-06-08T19:31:20.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd918677","name":"Ubuntu","slug":"ubuntu","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2017-12-20T06:23:49.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd918678","name":"TrueCrypt","slug":"truecrypt","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2017-12-20T06:23:49.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd918679","name":"VirtualBox","slug":"virtualbox","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2017-12-20T06:23:49.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd91867a","name":"Grails","slug":"grails","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2017-12-20T06:22:14.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd91867b","name":"Windows","slug":"windows","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2017-12-20T06:23:49.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd91867c","name":"HTMLUnit","slug":"htmlunit","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2014-10-04T13:57:36.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd91867d","name":"blog","slug":"blog","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2014-10-04T13:57:36.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd91867e","name":"nodejs","slug":"nodejs","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2014-10-04T13:57:36.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd91867f","name":"Lighttpd","slug":"lighttpd","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2014-10-04T13:57:36.000Z","created_by":"2","updated_at":"2014-10-04T13:57:36.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd918680","name":"Jenkins","slug":"jenkins","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2015-02-18T17:55:53.000Z","created_by":"1","updated_at":"2018-04-04T04:10:58.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd918681","name":"Git","slug":"git","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2015-02-18T17:55:53.000Z","created_by":"1","updated_at":"2018-04-04T04:10:58.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd918682","name":"Atlassian","slug":"atlassian","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2015-02-18T17:55:53.000Z","created_by":"1","updated_at":"2015-02-18T17:55:53.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd918683","name":"Stash","slug":"stash","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2015-02-18T17:55:53.000Z","created_by":"1","updated_at":"2018-04-04T04:10:58.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd918684","name":"Pull Request","slug":"pull-request","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2015-02-18T17:55:53.000Z","created_by":"1","updated_at":"2015-02-18T17:55:53.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd918685","name":"changelog","slug":"changelog","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2015-12-19T09:28:11.000Z","created_by":"1","updated_at":"2018-02-24T09:11:54.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd918686","name":"GitHub","slug":"github","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2016-09-11T07:01:02.000Z","created_by":"1","updated_at":"2018-04-04T04:10:58.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd918687","name":"Bitbucket Server","slug":"bitbucket-server","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2016-09-11T07:01:02.000Z","created_by":"1","updated_at":"2018-04-04T04:10:58.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd918688","name":"Static Code Analysis","slug":"static-code-analysis","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2016-09-11T07:01:02.000Z","created_by":"1","updated_at":"2018-02-24T09:10:31.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd918689","name":"Plugins","slug":"plugins","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2016-09-11T07:01:02.000Z","created_by":"1","updated_at":"2018-02-24T09:12:56.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd91868a","name":"Clean Code","slug":"clean-code","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2016-09-11T07:01:24.000Z","created_by":"1","updated_at":"2018-02-24T09:10:31.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd91868b","name":"Travis CI","slug":"travis-ci","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2016-09-11T07:02:08.000Z","created_by":"1","updated_at":"2018-02-24T09:10:31.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd91868c","name":"aktiebolag","slug":"aktiebolag","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-06-30T07:03:09.000Z","created_by":"1","updated_at":"2018-06-08T19:31:20.000Z","updated_by":"1"},{"id":"597b4433e521cb4fbd91868d","name":"bokfring","slug":"bokforing","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-06-30T07:03:09.000Z","created_by":"1","updated_at":"2018-06-08T19:31:20.000Z","updated_by":"1"},{"id":"597b696908a2db60d1f648bd","name":"cloudflare","slug":"cloudflare","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-07-28T16:42:17.000Z","created_by":"1","updated_at":"2018-05-18T19:09:18.000Z","updated_by":"1"},{"id":"597b696908a2db60d1f648bf","name":"buster","slug":"buster","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-07-28T16:42:17.000Z","created_by":"1","updated_at":"2018-05-18T19:09:18.000Z","updated_by":"1"},{"id":"59e06c588edbbd05ee0cef91","name":"fitnesse","slug":"fitnesse","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-10-13T07:33:44.000Z","created_by":"1","updated_at":"2018-02-24T09:03:08.000Z","updated_by":"1"},{"id":"59e06c588edbbd05ee0cef94","name":"maven","slug":"maven","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-10-13T07:33:44.000Z","created_by":"1","updated_at":"2018-02-26T08:29:01.000Z","updated_by":"1"},{"id":"5a3a309178ae32059caf0fc6","name":"Gradle","slug":"gradle","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-12-20T09:42:41.000Z","created_by":"1","updated_at":"2018-02-26T08:29:01.000Z","updated_by":"1"},{"id":"5a7557efc56a61057b219789","name":"pipeline","slug":"pipeline","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2018-02-03T06:34:23.000Z","created_by":"1","updated_at":"2018-04-04T04:10:58.000Z","updated_by":"1"},{"id":"5a7557efc56a61057b21978a","name":"continuous-integration","slug":"continuous-integration","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2018-02-03T06:34:23.000Z","created_by":"1","updated_at":"2018-04-04T04:10:58.000Z","updated_by":"1"},{"id":"5a912890c4446d055b89f2eb","name":"tools","slug":"tools","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2018-02-24T08:55:44.000Z","created_by":"1","updated_at":"2018-04-04T04:10:58.000Z","updated_by":"1"},{"id":"5a9128efc4446d055b89f2fb","name":"GitLab","slug":"gitlab","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2018-02-24T08:57:19.000Z","created_by":"1","updated_at":"2018-04-04T04:10:58.000Z","updated_by":"1"},{"id":"5a912c88c4446d055b89f30a","name":"Bitbucket-Server","slug":"bitbucket-server-2","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2018-02-24T09:12:40.000Z","created_by":"1","updated_at":"2018-02-24T09:12:56.000Z","updated_by":"1"},{"id":"5b7beb9c06392206949fa8a4","name":"kotlin","slug":"kotlin","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2018-08-21T10:38:20.000Z","created_by":"1","updated_at":"2018-08-21T10:38:20.000Z","updated_by":"1"},{"id":"5b858918d1c4a4085e025db2","name":"intellij","slug":"intellij","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2018-08-28T17:40:40.000Z","created_by":"1","updated_at":"2018-08-28T17:40:40.000Z","updated_by":"1"},{"id":"5b858918d1c4a4085e025db3","name":"eclipse","slug":"eclipse","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2018-08-28T17:40:40.000Z","created_by":"1","updated_at":"2018-08-28T17:40:40.000Z","updated_by":"1"},{"id":"5b858918d1c4a4085e025db4","name":"ide","slug":"ide","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2018-08-28T17:40:40.000Z","created_by":"1","updated_at":"2018-08-28T17:40:40.000Z","updated_by":"1"}],"users":[{"id":"1","name":"Tomas Bjerre","slug":"tomas","ghost_auth_access_token":null,"ghost_auth_id":null,"password":"$2a$10$iD8F/pG2N7EUGkS.NSNSYe8LbhbSUe2/GBcPdBAvPMs5Wac.kqvLW","email":"tomas.bjerre85@gmail.com","profile_image":"//www.gravatar.com/avatar/8b306fbe92f324ae9717c03ec7651116?s=250&d=mm&r=x","cover_image":null,"bio":null,"website":"http://tomasbjerreab.se/","location":"Sweden","facebook":"tomas.bjerre","twitter":null,"accessibility":null,"status":"active","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"tour":"[\"using-the-editor\",\"getting-started\",\"upload-a-theme\"]","last_seen":"2018-10-25T19:11:55.000Z","created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2018-10-25T19:11:55.000Z","updated_by":"1"},{"id":"5951f5fca366002ebd5dbef7","name":"Ghost","slug":"ghost","ghost_auth_access_token":null,"ghost_auth_id":null,"password":"$2a$10$uze1/90yOzDy279TMLotMuuIMDJFHmTsck15PWrbkk0EjYGBwZsf.","email":"ghost-author@example.com","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"accessibility":null,"status":"active","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"tour":null,"last_seen":null,"created_at":"2017-07-28T13:59:12.000Z","created_by":"1","updated_at":"2017-07-28T13:59:12.000Z","updated_by":"1"}],"webhooks":[]}}